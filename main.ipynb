{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Deep Learning-Based Compressed Sensing under IQ Imbalance For Channel Estimation of mmWave Phased Arrays\n",
    "Institution: TU Delft\n",
    "Faculty: Mechanical Engineering\n",
    "Authors: Tom Lijding and Daan van Haasteren\n",
    "\n",
    "### Python and Package Versions\n",
    "Python: 3.11.11\n",
    "Numpy: 2.2.1\n",
    "Scipy: 1.15.0\n",
    "Matplotlib: 3.10.0\n",
    "Pytorch: 2.5.1\n",
    "\n",
    "### Introduction\n",
    "This code demonstrates the use of a autoencoder based compressed sensing algorithm in channel estimation under IQ imbalance. We refer the reader to the file \"Data_Compression_Deep_Learning_based_CS_under_IQ_Imbalance.pdf\" for a full report and nice visuals!\n",
    "\n",
    "### Structure\n",
    "The code is structured as follows. First, the dataset is built upon which we train the neural networks. Next we create the neural networks i.e. build the custom layer \"ComplexLinearUnitary\" which functions as the encoding layer, and build different models for different varying parameters (SNR, IRR, Encoding Dimension)."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:35:11.008386Z",
     "start_time": "2025-04-10T14:35:11.004660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cmath\n",
    "import math\n",
    "plt.rcParams.update(plt.rcParamsDefault)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define our buildDataSet function here!"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:35:14.461083Z",
     "start_time": "2025-04-10T14:35:14.454582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def buildDataSet(max_amplitude, min_sparsity, max_sparsity, vector_size, data_set_size):\n",
    "    sparse_data = np.zeros((vector_size, data_set_size), dtype=float)  # Ensure float type\n",
    "    \n",
    "    # Iterate over the columns of the sparse_data matrix to define the data samples\n",
    "    for i in range(data_set_size):\n",
    "        sparsity = random.randint(min_sparsity, max_sparsity)\n",
    "        indices = random.sample(range(vector_size), sparsity)\n",
    "        amps = np.random.uniform(-max_amplitude, max_amplitude, sparsity)  # Use negative and positive values\n",
    "        sparse_data[indices, i] = amps\n",
    "    \n",
    "    # Define the DFT matrix and multiply our sparse_data vectors with it to find dense data\n",
    "    DFT = sp.linalg.dft(vector_size) / np.sqrt(vector_size)\n",
    "    dense_data = DFT @ sparse_data\n",
    "    \n",
    "    return dense_data, sparse_data\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build the dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:35:55.629292Z",
     "start_time": "2025-04-10T14:35:55.350791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_amplitude = 100\n",
    "min_sparsity = 10\n",
    "max_sparsity = 30\n",
    "vector_size = 100\n",
    "data_set_size = 10000\n",
    "dense_data, sparse_data = buildDataSet(max_amplitude,min_sparsity,max_sparsity,vector_size,data_set_size)\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test the dataset (optional)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:35:17.196433Z",
     "start_time": "2025-04-10T14:35:17.172299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DFT = sp.linalg.dft(vector_size)/np.sqrt(vector_size)\n",
    "iDFT = DFT.conj().T\n",
    "\n",
    "# Check if the iDFT of the dense data is in fact sparse\n",
    "print(iDFT@dense_data)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.42236390e-15+5.59858656e-13j -1.78101656e-13+1.16678011e-13j\n",
      "  -1.96207319e+01+4.47415950e-13j ... -2.66617990e-13-5.70777021e-14j\n",
      "  -3.01962516e-13+4.10117185e-13j -1.75987889e-13+1.37646140e-13j]\n",
      " [-5.76536696e+01-7.06345817e-14j -5.09761094e-14+5.50332059e-13j\n",
      "  -7.22462010e+00-5.66894773e-13j ... -3.36630425e-13-4.59112807e-14j\n",
      "   1.92974157e-13+3.80782684e-13j -1.19477162e-13-7.46097795e-13j]\n",
      " [-9.07277805e+01-1.92495524e-14j  3.88790302e-13-2.82147707e-13j\n",
      "  -2.00169755e-13+2.20476229e-13j ... -2.71859013e-13+1.87355447e-13j\n",
      "   1.54941355e-13+4.96672535e-14j -1.18193726e-13-1.30254032e-13j]\n",
      " ...\n",
      " [-8.86623889e+00+1.90558045e-13j  1.14481112e-13-2.86399803e-13j\n",
      "   1.63172946e-13-1.28146288e-13j ... -2.75127771e-13+7.04478073e-13j\n",
      "   5.26689803e-13-2.63594079e-14j  2.68939306e-13-3.27366672e-13j]\n",
      " [ 7.38063978e-13+3.33911980e-13j  1.41576990e-13+2.34875898e-14j\n",
      "  -2.00927326e-13-1.58520086e-13j ...  2.03568811e-13+2.25272065e-13j\n",
      "  -4.20844184e-14-3.22162963e-13j -3.69575424e-13+8.54264804e-14j]\n",
      " [-1.27357706e-13-5.48259956e-13j -2.32533731e-14-2.36795399e-13j\n",
      "  -3.17663636e-14-1.03392278e-13j ...  2.91876049e-13+2.26084695e-13j\n",
      "   1.72393283e-13+1.39569831e-13j -2.58662581e-13-4.71534923e-13j]]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "From the above results, we can see that our vectors are very sparse if we take the IDFT\n",
    "\n",
    "## Setting up the dataset for Pytorch"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:35:18.598132Z",
     "start_time": "2025-04-10T14:35:18.569301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.init as init\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(dense_data.shape)\n",
    "\n",
    "X = np.concatenate((dense_data.real,dense_data.imag)).T\n",
    "Y = np.concatenate((dense_data.real,dense_data.imag)).T\n",
    "\n",
    "X_tensor = torch.tensor(X,dtype=torch.float)\n",
    "Y_tensor = torch.tensor(Y,dtype=torch.float)\n",
    "dataset = TensorDataset(X_tensor,Y_tensor)\n",
    "\n",
    "dataloader = DataLoader(dataset,batch_size = 500,shuffle = True, )\n",
    "print(X_tensor.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10000)\n",
      "torch.Size([10000, 200])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setting up the Neural Networks"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:35:20.164879Z",
     "start_time": "2025-04-10T14:35:20.141740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def complex_xavier_init(tensor_real, tensor_imag, gain=1.0):\n",
    "    # Apply Xavier initialization (using uniform variant) to both real and imaginary parts\n",
    "    init.xavier_uniform_(tensor_real, gain=gain)\n",
    "    init.xavier_uniform_(tensor_imag, gain=gain)\n",
    "\n",
    "class ComplexLinearUnitary(nn.Module):\n",
    "    # This class serves as the encoder layer. We are restricted to values which are of the form e^jq where q are trainable parameters\n",
    "    # Notice that the input and output dimensions are half of what the actual vector size is! Because it is a complex value, our dimensions are twice as long\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(ComplexLinearUnitary,self).__init__()\n",
    "        # Here we create the q-values of our unitary matrix. These are the parameters we are training such that each entry of our complex matrix to encode our data is |F_ij| = 1\n",
    "        self.q_values = nn.Parameter(torch.randn(output_dim,input_dim))\n",
    "\n",
    "    def forward(self,x):   \n",
    "        # Compute unitary weights dynamically in each forward pass\n",
    "        W_real = torch.cos(self.q_values)\n",
    "        W_imag = torch.sin(self.q_values)\n",
    "        W_top = torch.cat([W_real, -W_imag], dim=1)  # [W_real, -W_imag]\n",
    "        W_bottom = torch.cat([W_imag, W_real], dim=1)  # [W_imag, W_real]\n",
    "        W_total = torch.cat([W_top, W_bottom], dim=0)  # Stack rows to form the full matrix \n",
    "        out = torch.matmul(x,W_total.T)\n",
    "        return out\n",
    "    \n",
    "class ComplexLinear(nn.Module):\n",
    "    # Notice that the input and output dimensions are half of what the actual vector size is! Because it is a complex value, our dimensions are twice as long. This gets fixed because we make the matrix\n",
    "    # W_total which multiplies [x_real;x_imag] and returns [y_real;y_imag]\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(ComplexLinear,self).__init__()\n",
    "        # Here we create the complex matrix W\n",
    "        #self.W_real = nn.Parameter(torch.randn(output_dim,input_dim))# eye(input_dim))\n",
    "        #self.W_imag = nn.Parameter(torch.randn(output_dim,input_dim)) #zeros((input_dim,output_dim)))\n",
    "\n",
    "        self.W_real = nn.Parameter(torch.empty(output_dim, input_dim))\n",
    "        self.W_imag = nn.Parameter(torch.empty(output_dim, input_dim))\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        # Initialize both the real and imaginary parts using Xavier initialization.\n",
    "        complex_xavier_init(self.W_real, self.W_imag)\n",
    "        \n",
    "    def forward(self,x):   \n",
    "        # Compute unitary weights dynamically in each forward pass\n",
    "        W_real = self.W_real\n",
    "        W_imag = self.W_imag\n",
    "        W_top = torch.cat([W_real, -W_imag], dim=1)  # [W_real, -W_imag]\n",
    "        W_bottom = torch.cat([W_imag, W_real], dim=1)  # [W_imag, W_real]\n",
    "        W_total = torch.cat([W_top, W_bottom], dim=0)  # Stack rows to form the full matrix \n",
    "        out = torch.matmul(x,W_total.T)\n",
    "        return out\n",
    "\n",
    "class FeedthroughEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(FeedthroughEncoder, self).__init__()\n",
    "        \"\"\" compression_factor = input_dim / encoding_dim\n",
    "        layer_size_factor = int(encoding_dim * compression_factor / 4) \"\"\"\n",
    "\n",
    "        self.encoder = ComplexLinear(input_dim,encoding_dim)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            ComplexLinear(encoding_dim,input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_out = self.encoder(x)\n",
    "        return self.decoder(encoder_out)\n",
    "\n",
    "\n",
    "class LearnedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim,hidden_dims):\n",
    "        super(LearnedAutoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = ComplexLinearUnitary(input_dim,encoding_dim)\n",
    "        layers = []\n",
    "        prev_dim = encoding_dim*2\n",
    "        for dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim,dim*2))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_dim = dim*2\n",
    "        self.decoder = nn.Sequential(\n",
    "            *layers,\n",
    "            nn.Linear(prev_dim,input_dim*2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_out = self.encoder(x)\n",
    "\n",
    "        return self.decoder(encoder_out)\n",
    "    \n",
    "class LearnedAutoencoderWithNoise(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim,hidden_dims,variance):\n",
    "        super(LearnedAutoencoderWithNoise, self).__init__()\n",
    "        self.variance = variance\n",
    "        self.encoder = ComplexLinearUnitary(input_dim,encoding_dim)\n",
    "        self.encoding_dim = encoding_dim\n",
    "        layers = []\n",
    "        prev_dim = encoding_dim*2\n",
    "        for dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim,dim*2))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_dim = dim*2\n",
    "        self.decoder = nn.Sequential(\n",
    "            *layers,\n",
    "            nn.Linear(prev_dim,input_dim*2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        encoder_out = self.encoder(x)\n",
    "        noise_np = np.random.normal(0,self.variance,size=self.encoding_dim*2)\n",
    "        noise = torch.tensor(noise_np,dtype=torch.float)\n",
    "        noisy_y = encoder_out + noise\n",
    "        return self.decoder(noisy_y)\n",
    "\n",
    "\n",
    "class LearnedAutoencoderWithIQImbalance(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim,hidden_dims,b, d,variance):\n",
    "        super(LearnedAutoencoderWithIQImbalance, self).__init__()\n",
    "        self.encoder = ComplexLinearUnitary(input_dim,encoding_dim)\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.variance = variance\n",
    "        self.r = torch.tensor(0.5*(1+b*np.exp(1j*d)), dtype=torch.complex64)\n",
    "        layers = []\n",
    "        prev_dim = encoding_dim*2\n",
    "        for dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim,dim*2))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_dim = dim*2\n",
    "        self.decoder = nn.Sequential(\n",
    "            *layers,\n",
    "            nn.Linear(prev_dim,input_dim*2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        encoder_out = self.encoder(x)\n",
    "        y_real = encoder_out[:, :self.encoding_dim]\n",
    "        y_imag = encoder_out[:, self.encoding_dim:]\n",
    "        y = torch.complex(y_real,y_imag)\n",
    "        yiq = self.r * y + (1-self.r.conj()) * (y.conj())\n",
    "        yiqr = yiq.real\n",
    "        yiqi = yiq.imag\n",
    "        yiqstack = torch.cat((yiqr,yiqi),dim=1)\n",
    "        noise_np = np.random.normal(0,self.variance,size=self.encoding_dim*2)\n",
    "        noise_tensor = torch.tensor(noise_np,dtype=torch.float)\n",
    "        y_iq_stack_noisy = yiqstack + noise_tensor\n",
    "        return self.decoder(y_iq_stack_noisy)\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Training the feedthrough model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the size of our \"measurement\" vector as encoding_dim. This needs to be larger than the sparsity of our matrix\n",
    "\n",
    "# encoding_dim = max_sparsity\n",
    "# encoding_dim = 100\n",
    "# vector_size = 100\n",
    "encoding_dim = vector_size\n",
    "# Initialize model\n",
    "feedthrough_model = FeedthroughEncoder(vector_size, encoding_dim)\n",
    "optimizer = torch.optim.Adam(feedthrough_model.parameters(), lr=1E-2, weight_decay=1E-6)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# def complex_mse_loss(input, target):\n",
    "#     return F.mse_loss(input, target)\n",
    "\n",
    "# Training loop\n",
    "losses = []\n",
    "for epoch in range(20):\n",
    "    for batch in dataloader:\n",
    "        inputs, targets = batch  # Unpack the tuple\n",
    "        optimizer.zero_grad()\n",
    "        output = feedthrough_model(inputs)\n",
    "        loss = loss_fn(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.6f}\")\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Train the AutoEncoder Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Training variables: Beta_momentum, beta_variance, learning_rate, encoding_dim, sparsity, weight_decay\n",
    "\n",
    "# Current Iteration: 1\n",
    "# Beta_momentum: 0.95\n",
    "# Beta_variance: 0.99\n",
    "# Learning_rate: 1E-3\n",
    "# weight_decay = 0\n",
    "# sparsity = 3-5\n",
    "\n",
    "encoding_dim = 50\n",
    "\n",
    "# Initialize model\n",
    "hidden_dims = np.array([60,80])\n",
    "learned_autoencoder_model = LearnedAutoencoder(vector_size,encoding_dim,hidden_dims)\n",
    "optimizer = torch.optim.Adam(learned_autoencoder_model.parameters(), lr=1E-3, betas=(0.9,0.999))\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# def complex_mse_loss(input, target):\n",
    "#     return F.mse_loss(input, target)\n",
    "\n",
    "# Training loop\n",
    "losses = []\n",
    "lowest_loss = float(\"inf\")\n",
    "for epoch in range(5000):\n",
    "    for batch in dataloader:\n",
    "        inputs, targets = batch  # Unpack the tuple\n",
    "        optimizer.zero_grad()\n",
    "        output = learned_autoencoder_model(inputs)\n",
    "        loss = loss_fn(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    if loss < lowest_loss:\n",
    "        lowest_loss = loss.item()\n",
    "        early_stopping_counter = 0\n",
    "        best_model = learned_autoencoder_model\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter > 100:\n",
    "            learned_autoencoder_model = best_model\n",
    "            print(f\"stopped early after {epoch+1} epochs, with a loss of: {lowest_loss}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {lowest_loss:.6f}\")\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Some conclusions that we have found so far:\n",
    "- Batch size must be minimally greater than 100. 500 seems to work well.\n",
    "- 2 hidden layers of size 50,70 leads to a loss of 0.3 MSE\n",
    "- Decreasing variance below 0.999 does not seem to have a positive effect\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train Noisy Models"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:54:01.348729Z",
     "start_time": "2025-04-10T14:36:06.881449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training variables: Beta_momentum, beta_variance, learning_rate, encoding_dim, sparsity, weight_decay\n",
    "\n",
    "# Current Iteration: 1\n",
    "# Beta_momentum: 0.9\n",
    "# Beta_variance: 0.999\n",
    "# Learning_rate: 1E-3\n",
    "# weight_decay = 0\n",
    "# sparsity = 3-5\n",
    "# variance = 1\n",
    "noisy_models = []\n",
    "noisy_losses = []\n",
    "\n",
    "# We define our signal to noise ratio as ranging from 0 to 20 dB\n",
    "db_list = [2,5,8,11,14,17,20]\n",
    "dataloader, signal_variance = Generate_Dataloader(max_amplitude,min_sparsity,max_sparsity,vector_size,data_set_size)\n",
    "SNR = {}\n",
    "\n",
    "# Then define the absolute values of the SNR ratio\n",
    "for db_ratio in db_list:\n",
    "    SNR[db_ratio] = 10**(db_ratio/10)\n",
    "\n",
    "for db,abs in SNR.items():\n",
    "    encoding_dim = 50\n",
    "    variance = signal_variance/abs\n",
    "    # Initialize model\n",
    "    hidden_dims = np.array([60,80])\n",
    "    noisy_autoencoder_model = LearnedAutoencoderWithNoise(vector_size,encoding_dim,hidden_dims,variance)\n",
    "    optimizer = torch.optim.Adam(noisy_autoencoder_model.parameters(), lr=1E-3, betas=(0.9,0.999))\n",
    "    loss_fn = nn.MSELoss()\n",
    "# def complex_mse_loss(input, target):\n",
    "#     return F.mse_loss(input, target)\n",
    "    # Training loop\n",
    "    losses = []\n",
    "    lowest_loss = float(\"inf\")\n",
    "    for epoch in range(10000):\n",
    "        for batch in dataloader:\n",
    "            inputs, targets = batch  # Unpack the tuple\n",
    "            optimizer.zero_grad()\n",
    "            output = noisy_autoencoder_model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        if loss.item() < lowest_loss:\n",
    "            lowest_loss = loss.item()\n",
    "            early_stopping_counter = 0\n",
    "            best_model = noisy_autoencoder_model\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter > 100:\n",
    "                noisy_autoencoder_model = best_model\n",
    "                print(f\"Stopped early after {epoch+1} epochs, with loss {lowest_loss:.6f}\")\n",
    "                break\n",
    "\n",
    "        print(f\"SNR Ratio: {db}, Epoch {epoch+1}, Loss: {loss.item():.6f}\")\n",
    "    noisy_models.append(best_model)\n",
    "    noisy_losses.append(lowest_loss)\n",
    "\n",
    "# plt.plot(losses)\n",
    "# plt.show()(noisy_losses\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR Ratio: 2, Epoch 1, Loss: 380.523987\n",
      "SNR Ratio: 2, Epoch 2, Loss: 344.328766\n",
      "SNR Ratio: 2, Epoch 3, Loss: 338.364807\n",
      "SNR Ratio: 2, Epoch 4, Loss: 335.327332\n",
      "SNR Ratio: 2, Epoch 5, Loss: 335.813202\n",
      "SNR Ratio: 2, Epoch 6, Loss: 327.324707\n",
      "SNR Ratio: 2, Epoch 7, Loss: 337.990845\n",
      "SNR Ratio: 2, Epoch 8, Loss: 332.402710\n",
      "SNR Ratio: 2, Epoch 9, Loss: 338.335205\n",
      "SNR Ratio: 2, Epoch 10, Loss: 330.727051\n",
      "SNR Ratio: 2, Epoch 11, Loss: 339.765747\n",
      "SNR Ratio: 2, Epoch 12, Loss: 328.184753\n",
      "SNR Ratio: 2, Epoch 13, Loss: 329.413635\n",
      "SNR Ratio: 2, Epoch 14, Loss: 331.271606\n",
      "SNR Ratio: 2, Epoch 15, Loss: 335.002808\n",
      "SNR Ratio: 2, Epoch 16, Loss: 328.249695\n",
      "SNR Ratio: 2, Epoch 17, Loss: 333.738342\n",
      "SNR Ratio: 2, Epoch 18, Loss: 327.551666\n",
      "SNR Ratio: 2, Epoch 19, Loss: 334.903687\n",
      "SNR Ratio: 2, Epoch 20, Loss: 323.854065\n",
      "SNR Ratio: 2, Epoch 21, Loss: 326.332367\n",
      "SNR Ratio: 2, Epoch 22, Loss: 333.337006\n",
      "SNR Ratio: 2, Epoch 23, Loss: 330.342590\n",
      "SNR Ratio: 2, Epoch 24, Loss: 341.089325\n",
      "SNR Ratio: 2, Epoch 25, Loss: 322.654724\n",
      "SNR Ratio: 2, Epoch 26, Loss: 328.916870\n",
      "SNR Ratio: 2, Epoch 27, Loss: 327.997314\n",
      "SNR Ratio: 2, Epoch 28, Loss: 329.934235\n",
      "SNR Ratio: 2, Epoch 29, Loss: 328.442566\n",
      "SNR Ratio: 2, Epoch 30, Loss: 330.826752\n",
      "SNR Ratio: 2, Epoch 31, Loss: 330.825165\n",
      "SNR Ratio: 2, Epoch 32, Loss: 323.968842\n",
      "SNR Ratio: 2, Epoch 33, Loss: 331.739960\n",
      "SNR Ratio: 2, Epoch 34, Loss: 310.947388\n",
      "SNR Ratio: 2, Epoch 35, Loss: 321.354065\n",
      "SNR Ratio: 2, Epoch 36, Loss: 320.425507\n",
      "SNR Ratio: 2, Epoch 37, Loss: 314.435852\n",
      "SNR Ratio: 2, Epoch 38, Loss: 321.695923\n",
      "SNR Ratio: 2, Epoch 39, Loss: 320.148346\n",
      "SNR Ratio: 2, Epoch 40, Loss: 316.468048\n",
      "SNR Ratio: 2, Epoch 41, Loss: 311.064545\n",
      "SNR Ratio: 2, Epoch 42, Loss: 319.414520\n",
      "SNR Ratio: 2, Epoch 43, Loss: 319.510834\n",
      "SNR Ratio: 2, Epoch 44, Loss: 333.241547\n",
      "SNR Ratio: 2, Epoch 45, Loss: 339.993866\n",
      "SNR Ratio: 2, Epoch 46, Loss: 320.253662\n",
      "SNR Ratio: 2, Epoch 47, Loss: 321.668335\n",
      "SNR Ratio: 2, Epoch 48, Loss: 319.068573\n",
      "SNR Ratio: 2, Epoch 49, Loss: 313.051666\n",
      "SNR Ratio: 2, Epoch 50, Loss: 317.072479\n",
      "SNR Ratio: 2, Epoch 51, Loss: 331.973907\n",
      "SNR Ratio: 2, Epoch 52, Loss: 303.383392\n",
      "SNR Ratio: 2, Epoch 53, Loss: 313.634277\n",
      "SNR Ratio: 2, Epoch 54, Loss: 303.126251\n",
      "SNR Ratio: 2, Epoch 55, Loss: 310.780182\n",
      "SNR Ratio: 2, Epoch 56, Loss: 328.428986\n",
      "SNR Ratio: 2, Epoch 57, Loss: 298.558624\n",
      "SNR Ratio: 2, Epoch 58, Loss: 308.707764\n",
      "SNR Ratio: 2, Epoch 59, Loss: 311.319733\n",
      "SNR Ratio: 2, Epoch 60, Loss: 308.956665\n",
      "SNR Ratio: 2, Epoch 61, Loss: 307.384094\n",
      "SNR Ratio: 2, Epoch 62, Loss: 319.770050\n",
      "SNR Ratio: 2, Epoch 63, Loss: 303.053833\n",
      "SNR Ratio: 2, Epoch 64, Loss: 307.928680\n",
      "SNR Ratio: 2, Epoch 65, Loss: 323.212250\n",
      "SNR Ratio: 2, Epoch 66, Loss: 298.739319\n",
      "SNR Ratio: 2, Epoch 67, Loss: 304.757904\n",
      "SNR Ratio: 2, Epoch 68, Loss: 284.171631\n",
      "SNR Ratio: 2, Epoch 69, Loss: 296.633606\n",
      "SNR Ratio: 2, Epoch 70, Loss: 292.766144\n",
      "SNR Ratio: 2, Epoch 71, Loss: 290.791931\n",
      "SNR Ratio: 2, Epoch 72, Loss: 294.462006\n",
      "SNR Ratio: 2, Epoch 73, Loss: 316.505646\n",
      "SNR Ratio: 2, Epoch 74, Loss: 288.644745\n",
      "SNR Ratio: 2, Epoch 75, Loss: 285.262390\n",
      "SNR Ratio: 2, Epoch 76, Loss: 283.930481\n",
      "SNR Ratio: 2, Epoch 77, Loss: 304.373596\n",
      "SNR Ratio: 2, Epoch 78, Loss: 304.993805\n",
      "SNR Ratio: 2, Epoch 79, Loss: 292.064392\n",
      "SNR Ratio: 2, Epoch 80, Loss: 296.992279\n",
      "SNR Ratio: 2, Epoch 81, Loss: 300.117065\n",
      "SNR Ratio: 2, Epoch 82, Loss: 308.126434\n",
      "SNR Ratio: 2, Epoch 83, Loss: 296.753174\n",
      "SNR Ratio: 2, Epoch 84, Loss: 308.880768\n",
      "SNR Ratio: 2, Epoch 85, Loss: 299.302277\n",
      "SNR Ratio: 2, Epoch 86, Loss: 296.115784\n",
      "SNR Ratio: 2, Epoch 87, Loss: 285.432617\n",
      "SNR Ratio: 2, Epoch 88, Loss: 290.648743\n",
      "SNR Ratio: 2, Epoch 89, Loss: 301.340271\n",
      "SNR Ratio: 2, Epoch 90, Loss: 301.329010\n",
      "SNR Ratio: 2, Epoch 91, Loss: 297.026764\n",
      "SNR Ratio: 2, Epoch 92, Loss: 290.377533\n",
      "SNR Ratio: 2, Epoch 93, Loss: 295.851868\n",
      "SNR Ratio: 2, Epoch 94, Loss: 289.312836\n",
      "SNR Ratio: 2, Epoch 95, Loss: 306.910675\n",
      "SNR Ratio: 2, Epoch 96, Loss: 281.133911\n",
      "SNR Ratio: 2, Epoch 97, Loss: 294.784241\n",
      "SNR Ratio: 2, Epoch 98, Loss: 311.210632\n",
      "SNR Ratio: 2, Epoch 99, Loss: 280.323090\n",
      "SNR Ratio: 2, Epoch 100, Loss: 289.939453\n",
      "SNR Ratio: 2, Epoch 101, Loss: 305.842438\n",
      "SNR Ratio: 2, Epoch 102, Loss: 288.154175\n",
      "SNR Ratio: 2, Epoch 103, Loss: 300.911346\n",
      "SNR Ratio: 2, Epoch 104, Loss: 295.244324\n",
      "SNR Ratio: 2, Epoch 105, Loss: 295.185028\n",
      "SNR Ratio: 2, Epoch 106, Loss: 284.989288\n",
      "SNR Ratio: 2, Epoch 107, Loss: 282.118927\n",
      "SNR Ratio: 2, Epoch 108, Loss: 284.224426\n",
      "SNR Ratio: 2, Epoch 109, Loss: 290.241974\n",
      "SNR Ratio: 2, Epoch 110, Loss: 288.311707\n",
      "SNR Ratio: 2, Epoch 111, Loss: 289.036530\n",
      "SNR Ratio: 2, Epoch 112, Loss: 287.980988\n",
      "SNR Ratio: 2, Epoch 113, Loss: 305.489532\n",
      "SNR Ratio: 2, Epoch 114, Loss: 282.203918\n",
      "SNR Ratio: 2, Epoch 115, Loss: 280.259613\n",
      "SNR Ratio: 2, Epoch 116, Loss: 272.964417\n",
      "SNR Ratio: 2, Epoch 117, Loss: 279.995026\n",
      "SNR Ratio: 2, Epoch 118, Loss: 293.877472\n",
      "SNR Ratio: 2, Epoch 119, Loss: 294.028168\n",
      "SNR Ratio: 2, Epoch 120, Loss: 272.964844\n",
      "SNR Ratio: 2, Epoch 121, Loss: 299.456543\n",
      "SNR Ratio: 2, Epoch 122, Loss: 270.603607\n",
      "SNR Ratio: 2, Epoch 123, Loss: 299.065247\n",
      "SNR Ratio: 2, Epoch 124, Loss: 286.230347\n",
      "SNR Ratio: 2, Epoch 125, Loss: 279.998871\n",
      "SNR Ratio: 2, Epoch 126, Loss: 281.050995\n",
      "SNR Ratio: 2, Epoch 127, Loss: 277.437195\n",
      "SNR Ratio: 2, Epoch 128, Loss: 282.573730\n",
      "SNR Ratio: 2, Epoch 129, Loss: 279.198639\n",
      "SNR Ratio: 2, Epoch 130, Loss: 285.432770\n",
      "SNR Ratio: 2, Epoch 131, Loss: 265.660400\n",
      "SNR Ratio: 2, Epoch 132, Loss: 277.246338\n",
      "SNR Ratio: 2, Epoch 133, Loss: 289.868591\n",
      "SNR Ratio: 2, Epoch 134, Loss: 299.688873\n",
      "SNR Ratio: 2, Epoch 135, Loss: 286.392334\n",
      "SNR Ratio: 2, Epoch 136, Loss: 287.472046\n",
      "SNR Ratio: 2, Epoch 137, Loss: 287.166443\n",
      "SNR Ratio: 2, Epoch 138, Loss: 289.520294\n",
      "SNR Ratio: 2, Epoch 139, Loss: 281.671295\n",
      "SNR Ratio: 2, Epoch 140, Loss: 285.288940\n",
      "SNR Ratio: 2, Epoch 141, Loss: 284.076416\n",
      "SNR Ratio: 2, Epoch 142, Loss: 271.157410\n",
      "SNR Ratio: 2, Epoch 143, Loss: 286.064148\n",
      "SNR Ratio: 2, Epoch 144, Loss: 279.123016\n",
      "SNR Ratio: 2, Epoch 145, Loss: 272.093781\n",
      "SNR Ratio: 2, Epoch 146, Loss: 278.026184\n",
      "SNR Ratio: 2, Epoch 147, Loss: 276.902924\n",
      "SNR Ratio: 2, Epoch 148, Loss: 290.806732\n",
      "SNR Ratio: 2, Epoch 149, Loss: 287.142517\n",
      "SNR Ratio: 2, Epoch 150, Loss: 271.862793\n",
      "SNR Ratio: 2, Epoch 151, Loss: 281.705750\n",
      "SNR Ratio: 2, Epoch 152, Loss: 267.130524\n",
      "SNR Ratio: 2, Epoch 153, Loss: 281.545380\n",
      "SNR Ratio: 2, Epoch 154, Loss: 292.032349\n",
      "SNR Ratio: 2, Epoch 155, Loss: 273.388275\n",
      "SNR Ratio: 2, Epoch 156, Loss: 275.684357\n",
      "SNR Ratio: 2, Epoch 157, Loss: 272.144684\n",
      "SNR Ratio: 2, Epoch 158, Loss: 285.633270\n",
      "SNR Ratio: 2, Epoch 159, Loss: 271.173187\n",
      "SNR Ratio: 2, Epoch 160, Loss: 276.609467\n",
      "SNR Ratio: 2, Epoch 161, Loss: 278.131622\n",
      "SNR Ratio: 2, Epoch 162, Loss: 297.274231\n",
      "SNR Ratio: 2, Epoch 163, Loss: 256.410583\n",
      "SNR Ratio: 2, Epoch 164, Loss: 286.579010\n",
      "SNR Ratio: 2, Epoch 165, Loss: 271.474945\n",
      "SNR Ratio: 2, Epoch 166, Loss: 274.954773\n",
      "SNR Ratio: 2, Epoch 167, Loss: 273.127808\n",
      "SNR Ratio: 2, Epoch 168, Loss: 272.309540\n",
      "SNR Ratio: 2, Epoch 169, Loss: 268.319519\n",
      "SNR Ratio: 2, Epoch 170, Loss: 278.339478\n",
      "SNR Ratio: 2, Epoch 171, Loss: 284.077026\n",
      "SNR Ratio: 2, Epoch 172, Loss: 278.087891\n",
      "SNR Ratio: 2, Epoch 173, Loss: 280.893036\n",
      "SNR Ratio: 2, Epoch 174, Loss: 291.898071\n",
      "SNR Ratio: 2, Epoch 175, Loss: 274.316986\n",
      "SNR Ratio: 2, Epoch 176, Loss: 278.348511\n",
      "SNR Ratio: 2, Epoch 177, Loss: 285.106720\n",
      "SNR Ratio: 2, Epoch 178, Loss: 283.970062\n",
      "SNR Ratio: 2, Epoch 179, Loss: 280.539124\n",
      "SNR Ratio: 2, Epoch 180, Loss: 268.495148\n",
      "SNR Ratio: 2, Epoch 181, Loss: 266.445953\n",
      "SNR Ratio: 2, Epoch 182, Loss: 264.143005\n",
      "SNR Ratio: 2, Epoch 183, Loss: 294.812164\n",
      "SNR Ratio: 2, Epoch 184, Loss: 273.588867\n",
      "SNR Ratio: 2, Epoch 185, Loss: 293.268707\n",
      "SNR Ratio: 2, Epoch 186, Loss: 283.123413\n",
      "SNR Ratio: 2, Epoch 187, Loss: 266.178894\n",
      "SNR Ratio: 2, Epoch 188, Loss: 270.428680\n",
      "SNR Ratio: 2, Epoch 189, Loss: 267.200470\n",
      "SNR Ratio: 2, Epoch 190, Loss: 279.279846\n",
      "SNR Ratio: 2, Epoch 191, Loss: 273.655121\n",
      "SNR Ratio: 2, Epoch 192, Loss: 277.273346\n",
      "SNR Ratio: 2, Epoch 193, Loss: 269.784332\n",
      "SNR Ratio: 2, Epoch 194, Loss: 265.962708\n",
      "SNR Ratio: 2, Epoch 195, Loss: 273.248322\n",
      "SNR Ratio: 2, Epoch 196, Loss: 276.218872\n",
      "SNR Ratio: 2, Epoch 197, Loss: 277.681610\n",
      "SNR Ratio: 2, Epoch 198, Loss: 265.226593\n",
      "SNR Ratio: 2, Epoch 199, Loss: 283.578186\n",
      "SNR Ratio: 2, Epoch 200, Loss: 266.257935\n",
      "SNR Ratio: 2, Epoch 201, Loss: 280.990479\n",
      "SNR Ratio: 2, Epoch 202, Loss: 273.327606\n",
      "SNR Ratio: 2, Epoch 203, Loss: 281.375244\n",
      "SNR Ratio: 2, Epoch 204, Loss: 265.091278\n",
      "SNR Ratio: 2, Epoch 205, Loss: 263.844116\n",
      "SNR Ratio: 2, Epoch 206, Loss: 271.971954\n",
      "SNR Ratio: 2, Epoch 207, Loss: 268.469482\n",
      "SNR Ratio: 2, Epoch 208, Loss: 272.713348\n",
      "SNR Ratio: 2, Epoch 209, Loss: 273.541779\n",
      "SNR Ratio: 2, Epoch 210, Loss: 267.397125\n",
      "SNR Ratio: 2, Epoch 211, Loss: 270.370605\n",
      "SNR Ratio: 2, Epoch 212, Loss: 262.358612\n",
      "SNR Ratio: 2, Epoch 213, Loss: 280.119110\n",
      "SNR Ratio: 2, Epoch 214, Loss: 270.164246\n",
      "SNR Ratio: 2, Epoch 215, Loss: 260.566925\n",
      "SNR Ratio: 2, Epoch 216, Loss: 273.311554\n",
      "SNR Ratio: 2, Epoch 217, Loss: 267.685211\n",
      "SNR Ratio: 2, Epoch 218, Loss: 276.121155\n",
      "SNR Ratio: 2, Epoch 219, Loss: 279.217010\n",
      "SNR Ratio: 2, Epoch 220, Loss: 276.008209\n",
      "SNR Ratio: 2, Epoch 221, Loss: 287.175690\n",
      "SNR Ratio: 2, Epoch 222, Loss: 260.293915\n",
      "SNR Ratio: 2, Epoch 223, Loss: 276.013794\n",
      "SNR Ratio: 2, Epoch 224, Loss: 277.954834\n",
      "SNR Ratio: 2, Epoch 225, Loss: 275.256866\n",
      "SNR Ratio: 2, Epoch 226, Loss: 279.098114\n",
      "SNR Ratio: 2, Epoch 227, Loss: 285.918610\n",
      "SNR Ratio: 2, Epoch 228, Loss: 279.295746\n",
      "SNR Ratio: 2, Epoch 229, Loss: 265.767303\n",
      "SNR Ratio: 2, Epoch 230, Loss: 268.110413\n",
      "SNR Ratio: 2, Epoch 231, Loss: 263.316833\n",
      "SNR Ratio: 2, Epoch 232, Loss: 271.971039\n",
      "SNR Ratio: 2, Epoch 233, Loss: 257.099091\n",
      "SNR Ratio: 2, Epoch 234, Loss: 288.326569\n",
      "SNR Ratio: 2, Epoch 235, Loss: 268.383362\n",
      "SNR Ratio: 2, Epoch 236, Loss: 278.355469\n",
      "SNR Ratio: 2, Epoch 237, Loss: 264.593933\n",
      "SNR Ratio: 2, Epoch 238, Loss: 270.534210\n",
      "SNR Ratio: 2, Epoch 239, Loss: 270.344604\n",
      "SNR Ratio: 2, Epoch 240, Loss: 264.885925\n",
      "SNR Ratio: 2, Epoch 241, Loss: 287.746643\n",
      "SNR Ratio: 2, Epoch 242, Loss: 268.431213\n",
      "SNR Ratio: 2, Epoch 243, Loss: 268.515289\n",
      "SNR Ratio: 2, Epoch 244, Loss: 290.043732\n",
      "SNR Ratio: 2, Epoch 245, Loss: 268.548187\n",
      "SNR Ratio: 2, Epoch 246, Loss: 257.778076\n",
      "SNR Ratio: 2, Epoch 247, Loss: 273.085175\n",
      "SNR Ratio: 2, Epoch 248, Loss: 263.701691\n",
      "SNR Ratio: 2, Epoch 249, Loss: 266.210388\n",
      "SNR Ratio: 2, Epoch 250, Loss: 284.465912\n",
      "SNR Ratio: 2, Epoch 251, Loss: 268.707703\n",
      "SNR Ratio: 2, Epoch 252, Loss: 260.843018\n",
      "SNR Ratio: 2, Epoch 253, Loss: 269.465332\n",
      "SNR Ratio: 2, Epoch 254, Loss: 266.984955\n",
      "SNR Ratio: 2, Epoch 255, Loss: 282.350586\n",
      "SNR Ratio: 2, Epoch 256, Loss: 252.965424\n",
      "SNR Ratio: 2, Epoch 257, Loss: 271.606476\n",
      "SNR Ratio: 2, Epoch 258, Loss: 269.633545\n",
      "SNR Ratio: 2, Epoch 259, Loss: 254.698563\n",
      "SNR Ratio: 2, Epoch 260, Loss: 264.561768\n",
      "SNR Ratio: 2, Epoch 261, Loss: 279.701721\n",
      "SNR Ratio: 2, Epoch 262, Loss: 291.536591\n",
      "SNR Ratio: 2, Epoch 263, Loss: 287.559174\n",
      "SNR Ratio: 2, Epoch 264, Loss: 267.234528\n",
      "SNR Ratio: 2, Epoch 265, Loss: 272.827789\n",
      "SNR Ratio: 2, Epoch 266, Loss: 269.158875\n",
      "SNR Ratio: 2, Epoch 267, Loss: 267.814819\n",
      "SNR Ratio: 2, Epoch 268, Loss: 267.441925\n",
      "SNR Ratio: 2, Epoch 269, Loss: 275.255066\n",
      "SNR Ratio: 2, Epoch 270, Loss: 262.299896\n",
      "SNR Ratio: 2, Epoch 271, Loss: 268.038208\n",
      "SNR Ratio: 2, Epoch 272, Loss: 252.210480\n",
      "SNR Ratio: 2, Epoch 273, Loss: 261.213593\n",
      "SNR Ratio: 2, Epoch 274, Loss: 269.704285\n",
      "SNR Ratio: 2, Epoch 275, Loss: 263.070496\n",
      "SNR Ratio: 2, Epoch 276, Loss: 260.037811\n",
      "SNR Ratio: 2, Epoch 277, Loss: 281.790649\n",
      "SNR Ratio: 2, Epoch 278, Loss: 270.790894\n",
      "SNR Ratio: 2, Epoch 279, Loss: 271.154327\n",
      "SNR Ratio: 2, Epoch 280, Loss: 258.867981\n",
      "SNR Ratio: 2, Epoch 281, Loss: 254.445023\n",
      "SNR Ratio: 2, Epoch 282, Loss: 270.879700\n",
      "SNR Ratio: 2, Epoch 283, Loss: 286.059326\n",
      "SNR Ratio: 2, Epoch 284, Loss: 266.922424\n",
      "SNR Ratio: 2, Epoch 285, Loss: 260.953552\n",
      "SNR Ratio: 2, Epoch 286, Loss: 266.217407\n",
      "SNR Ratio: 2, Epoch 287, Loss: 280.316925\n",
      "SNR Ratio: 2, Epoch 288, Loss: 257.384155\n",
      "SNR Ratio: 2, Epoch 289, Loss: 272.700592\n",
      "SNR Ratio: 2, Epoch 290, Loss: 270.706268\n",
      "SNR Ratio: 2, Epoch 291, Loss: 252.204697\n",
      "SNR Ratio: 2, Epoch 292, Loss: 253.478516\n",
      "SNR Ratio: 2, Epoch 293, Loss: 264.362213\n",
      "SNR Ratio: 2, Epoch 294, Loss: 268.084778\n",
      "SNR Ratio: 2, Epoch 295, Loss: 257.294891\n",
      "SNR Ratio: 2, Epoch 296, Loss: 254.886398\n",
      "SNR Ratio: 2, Epoch 297, Loss: 266.033630\n",
      "SNR Ratio: 2, Epoch 298, Loss: 269.725067\n",
      "SNR Ratio: 2, Epoch 299, Loss: 254.648117\n",
      "SNR Ratio: 2, Epoch 300, Loss: 271.061096\n",
      "SNR Ratio: 2, Epoch 301, Loss: 277.469635\n",
      "SNR Ratio: 2, Epoch 302, Loss: 262.619934\n",
      "SNR Ratio: 2, Epoch 303, Loss: 263.150055\n",
      "SNR Ratio: 2, Epoch 304, Loss: 250.615463\n",
      "SNR Ratio: 2, Epoch 305, Loss: 258.719666\n",
      "SNR Ratio: 2, Epoch 306, Loss: 271.789459\n",
      "SNR Ratio: 2, Epoch 307, Loss: 267.973267\n",
      "SNR Ratio: 2, Epoch 308, Loss: 254.253464\n",
      "SNR Ratio: 2, Epoch 309, Loss: 275.269470\n",
      "SNR Ratio: 2, Epoch 310, Loss: 252.468338\n",
      "SNR Ratio: 2, Epoch 311, Loss: 252.440155\n",
      "SNR Ratio: 2, Epoch 312, Loss: 281.510315\n",
      "SNR Ratio: 2, Epoch 313, Loss: 258.897644\n",
      "SNR Ratio: 2, Epoch 314, Loss: 252.343887\n",
      "SNR Ratio: 2, Epoch 315, Loss: 255.131744\n",
      "SNR Ratio: 2, Epoch 316, Loss: 259.568207\n",
      "SNR Ratio: 2, Epoch 317, Loss: 260.626862\n",
      "SNR Ratio: 2, Epoch 318, Loss: 261.638885\n",
      "SNR Ratio: 2, Epoch 319, Loss: 257.488495\n",
      "SNR Ratio: 2, Epoch 320, Loss: 263.975067\n",
      "SNR Ratio: 2, Epoch 321, Loss: 277.407684\n",
      "SNR Ratio: 2, Epoch 322, Loss: 259.444153\n",
      "SNR Ratio: 2, Epoch 323, Loss: 251.447220\n",
      "SNR Ratio: 2, Epoch 324, Loss: 259.914673\n",
      "SNR Ratio: 2, Epoch 325, Loss: 272.478973\n",
      "SNR Ratio: 2, Epoch 326, Loss: 267.726990\n",
      "SNR Ratio: 2, Epoch 327, Loss: 259.990967\n",
      "SNR Ratio: 2, Epoch 328, Loss: 257.655914\n",
      "SNR Ratio: 2, Epoch 329, Loss: 260.710022\n",
      "SNR Ratio: 2, Epoch 330, Loss: 279.947845\n",
      "SNR Ratio: 2, Epoch 331, Loss: 262.702454\n",
      "SNR Ratio: 2, Epoch 332, Loss: 256.024506\n",
      "SNR Ratio: 2, Epoch 333, Loss: 257.656952\n",
      "SNR Ratio: 2, Epoch 334, Loss: 280.030518\n",
      "SNR Ratio: 2, Epoch 335, Loss: 273.131256\n",
      "SNR Ratio: 2, Epoch 336, Loss: 254.864319\n",
      "SNR Ratio: 2, Epoch 337, Loss: 263.352631\n",
      "SNR Ratio: 2, Epoch 338, Loss: 267.058563\n",
      "SNR Ratio: 2, Epoch 339, Loss: 264.799805\n",
      "SNR Ratio: 2, Epoch 340, Loss: 274.861237\n",
      "SNR Ratio: 2, Epoch 341, Loss: 257.999634\n",
      "SNR Ratio: 2, Epoch 342, Loss: 259.431152\n",
      "SNR Ratio: 2, Epoch 343, Loss: 258.034271\n",
      "SNR Ratio: 2, Epoch 344, Loss: 266.344452\n",
      "SNR Ratio: 2, Epoch 345, Loss: 254.431534\n",
      "SNR Ratio: 2, Epoch 346, Loss: 271.719910\n",
      "SNR Ratio: 2, Epoch 347, Loss: 261.982452\n",
      "SNR Ratio: 2, Epoch 348, Loss: 262.644653\n",
      "SNR Ratio: 2, Epoch 349, Loss: 261.951752\n",
      "SNR Ratio: 2, Epoch 350, Loss: 262.749634\n",
      "SNR Ratio: 2, Epoch 351, Loss: 273.195068\n",
      "SNR Ratio: 2, Epoch 352, Loss: 270.479675\n",
      "SNR Ratio: 2, Epoch 353, Loss: 275.811554\n",
      "SNR Ratio: 2, Epoch 354, Loss: 254.105621\n",
      "SNR Ratio: 2, Epoch 355, Loss: 261.419952\n",
      "SNR Ratio: 2, Epoch 356, Loss: 279.211884\n",
      "SNR Ratio: 2, Epoch 357, Loss: 254.832718\n",
      "SNR Ratio: 2, Epoch 358, Loss: 267.089386\n",
      "SNR Ratio: 2, Epoch 359, Loss: 257.580078\n",
      "SNR Ratio: 2, Epoch 360, Loss: 261.005768\n",
      "SNR Ratio: 2, Epoch 361, Loss: 259.684967\n",
      "SNR Ratio: 2, Epoch 362, Loss: 262.935150\n",
      "SNR Ratio: 2, Epoch 363, Loss: 263.327606\n",
      "SNR Ratio: 2, Epoch 364, Loss: 265.820312\n",
      "SNR Ratio: 2, Epoch 365, Loss: 273.079071\n",
      "SNR Ratio: 2, Epoch 366, Loss: 275.444977\n",
      "SNR Ratio: 2, Epoch 367, Loss: 251.725662\n",
      "SNR Ratio: 2, Epoch 368, Loss: 263.836975\n",
      "SNR Ratio: 2, Epoch 369, Loss: 268.535522\n",
      "SNR Ratio: 2, Epoch 370, Loss: 258.905579\n",
      "SNR Ratio: 2, Epoch 371, Loss: 274.446747\n",
      "SNR Ratio: 2, Epoch 372, Loss: 261.482361\n",
      "SNR Ratio: 2, Epoch 373, Loss: 252.122299\n",
      "SNR Ratio: 2, Epoch 374, Loss: 267.732788\n",
      "SNR Ratio: 2, Epoch 375, Loss: 238.440582\n",
      "SNR Ratio: 2, Epoch 376, Loss: 261.550629\n",
      "SNR Ratio: 2, Epoch 377, Loss: 257.947571\n",
      "SNR Ratio: 2, Epoch 378, Loss: 270.754242\n",
      "SNR Ratio: 2, Epoch 379, Loss: 256.111938\n",
      "SNR Ratio: 2, Epoch 380, Loss: 264.186523\n",
      "SNR Ratio: 2, Epoch 381, Loss: 271.643677\n",
      "SNR Ratio: 2, Epoch 382, Loss: 276.139313\n",
      "SNR Ratio: 2, Epoch 383, Loss: 258.458954\n",
      "SNR Ratio: 2, Epoch 384, Loss: 255.386734\n",
      "SNR Ratio: 2, Epoch 385, Loss: 261.696259\n",
      "SNR Ratio: 2, Epoch 386, Loss: 250.429245\n",
      "SNR Ratio: 2, Epoch 387, Loss: 268.493073\n",
      "SNR Ratio: 2, Epoch 388, Loss: 264.577454\n",
      "SNR Ratio: 2, Epoch 389, Loss: 265.156006\n",
      "SNR Ratio: 2, Epoch 390, Loss: 260.607880\n",
      "SNR Ratio: 2, Epoch 391, Loss: 263.378235\n",
      "SNR Ratio: 2, Epoch 392, Loss: 264.444611\n",
      "SNR Ratio: 2, Epoch 393, Loss: 251.101898\n",
      "SNR Ratio: 2, Epoch 394, Loss: 255.345322\n",
      "SNR Ratio: 2, Epoch 395, Loss: 251.426559\n",
      "SNR Ratio: 2, Epoch 396, Loss: 261.625275\n",
      "SNR Ratio: 2, Epoch 397, Loss: 264.953918\n",
      "SNR Ratio: 2, Epoch 398, Loss: 263.298218\n",
      "SNR Ratio: 2, Epoch 399, Loss: 252.370316\n",
      "SNR Ratio: 2, Epoch 400, Loss: 268.154877\n",
      "SNR Ratio: 2, Epoch 401, Loss: 261.157898\n",
      "SNR Ratio: 2, Epoch 402, Loss: 275.596497\n",
      "SNR Ratio: 2, Epoch 403, Loss: 261.510284\n",
      "SNR Ratio: 2, Epoch 404, Loss: 252.497101\n",
      "SNR Ratio: 2, Epoch 405, Loss: 276.335724\n",
      "SNR Ratio: 2, Epoch 406, Loss: 275.347382\n",
      "SNR Ratio: 2, Epoch 407, Loss: 264.816895\n",
      "SNR Ratio: 2, Epoch 408, Loss: 260.870850\n",
      "SNR Ratio: 2, Epoch 409, Loss: 258.127747\n",
      "SNR Ratio: 2, Epoch 410, Loss: 265.871552\n",
      "SNR Ratio: 2, Epoch 411, Loss: 280.496826\n",
      "SNR Ratio: 2, Epoch 412, Loss: 266.052216\n",
      "SNR Ratio: 2, Epoch 413, Loss: 263.355591\n",
      "SNR Ratio: 2, Epoch 414, Loss: 281.666290\n",
      "SNR Ratio: 2, Epoch 415, Loss: 262.042480\n",
      "SNR Ratio: 2, Epoch 416, Loss: 267.484711\n",
      "SNR Ratio: 2, Epoch 417, Loss: 274.308167\n",
      "SNR Ratio: 2, Epoch 418, Loss: 253.613159\n",
      "SNR Ratio: 2, Epoch 419, Loss: 273.763123\n",
      "SNR Ratio: 2, Epoch 420, Loss: 261.112610\n",
      "SNR Ratio: 2, Epoch 421, Loss: 250.043594\n",
      "SNR Ratio: 2, Epoch 422, Loss: 270.156372\n",
      "SNR Ratio: 2, Epoch 423, Loss: 256.023224\n",
      "SNR Ratio: 2, Epoch 424, Loss: 267.900269\n",
      "SNR Ratio: 2, Epoch 425, Loss: 243.916779\n",
      "SNR Ratio: 2, Epoch 426, Loss: 260.237518\n",
      "SNR Ratio: 2, Epoch 427, Loss: 265.306091\n",
      "SNR Ratio: 2, Epoch 428, Loss: 247.966797\n",
      "SNR Ratio: 2, Epoch 429, Loss: 261.333313\n",
      "SNR Ratio: 2, Epoch 430, Loss: 262.326538\n",
      "SNR Ratio: 2, Epoch 431, Loss: 278.789307\n",
      "SNR Ratio: 2, Epoch 432, Loss: 268.100891\n",
      "SNR Ratio: 2, Epoch 433, Loss: 257.302032\n",
      "SNR Ratio: 2, Epoch 434, Loss: 287.066193\n",
      "SNR Ratio: 2, Epoch 435, Loss: 274.101532\n",
      "SNR Ratio: 2, Epoch 436, Loss: 247.278763\n",
      "SNR Ratio: 2, Epoch 437, Loss: 249.502167\n",
      "SNR Ratio: 2, Epoch 438, Loss: 263.856506\n",
      "SNR Ratio: 2, Epoch 439, Loss: 267.962006\n",
      "SNR Ratio: 2, Epoch 440, Loss: 265.113251\n",
      "SNR Ratio: 2, Epoch 441, Loss: 272.300110\n",
      "SNR Ratio: 2, Epoch 442, Loss: 262.687653\n",
      "SNR Ratio: 2, Epoch 443, Loss: 259.841095\n",
      "SNR Ratio: 2, Epoch 444, Loss: 253.687241\n",
      "SNR Ratio: 2, Epoch 445, Loss: 269.474060\n",
      "SNR Ratio: 2, Epoch 446, Loss: 259.168427\n",
      "SNR Ratio: 2, Epoch 447, Loss: 258.636597\n",
      "SNR Ratio: 2, Epoch 448, Loss: 263.867371\n",
      "SNR Ratio: 2, Epoch 449, Loss: 269.284973\n",
      "SNR Ratio: 2, Epoch 450, Loss: 251.794098\n",
      "SNR Ratio: 2, Epoch 451, Loss: 254.143402\n",
      "SNR Ratio: 2, Epoch 452, Loss: 269.304047\n",
      "SNR Ratio: 2, Epoch 453, Loss: 262.468933\n",
      "SNR Ratio: 2, Epoch 454, Loss: 273.917969\n",
      "SNR Ratio: 2, Epoch 455, Loss: 259.994019\n",
      "SNR Ratio: 2, Epoch 456, Loss: 261.171387\n",
      "SNR Ratio: 2, Epoch 457, Loss: 255.159515\n",
      "SNR Ratio: 2, Epoch 458, Loss: 265.113525\n",
      "SNR Ratio: 2, Epoch 459, Loss: 259.938293\n",
      "SNR Ratio: 2, Epoch 460, Loss: 258.885681\n",
      "SNR Ratio: 2, Epoch 461, Loss: 259.304565\n",
      "SNR Ratio: 2, Epoch 462, Loss: 261.687195\n",
      "SNR Ratio: 2, Epoch 463, Loss: 249.985794\n",
      "SNR Ratio: 2, Epoch 464, Loss: 255.039520\n",
      "SNR Ratio: 2, Epoch 465, Loss: 258.373230\n",
      "SNR Ratio: 2, Epoch 466, Loss: 246.128860\n",
      "SNR Ratio: 2, Epoch 467, Loss: 259.944885\n",
      "SNR Ratio: 2, Epoch 468, Loss: 262.325958\n",
      "SNR Ratio: 2, Epoch 469, Loss: 264.533447\n",
      "SNR Ratio: 2, Epoch 470, Loss: 253.415833\n",
      "SNR Ratio: 2, Epoch 471, Loss: 266.464294\n",
      "SNR Ratio: 2, Epoch 472, Loss: 258.966583\n",
      "SNR Ratio: 2, Epoch 473, Loss: 271.502563\n",
      "SNR Ratio: 2, Epoch 474, Loss: 257.340179\n",
      "SNR Ratio: 2, Epoch 475, Loss: 264.728729\n",
      "Stopped early after 476 epochs, with loss 238.440582\n",
      "SNR Ratio: 5, Epoch 1, Loss: 349.870728\n",
      "SNR Ratio: 5, Epoch 2, Loss: 338.907349\n",
      "SNR Ratio: 5, Epoch 3, Loss: 332.707397\n",
      "SNR Ratio: 5, Epoch 4, Loss: 335.273438\n",
      "SNR Ratio: 5, Epoch 5, Loss: 330.890930\n",
      "SNR Ratio: 5, Epoch 6, Loss: 327.227570\n",
      "SNR Ratio: 5, Epoch 7, Loss: 323.245911\n",
      "SNR Ratio: 5, Epoch 8, Loss: 318.639801\n",
      "SNR Ratio: 5, Epoch 9, Loss: 308.359406\n",
      "SNR Ratio: 5, Epoch 10, Loss: 304.944946\n",
      "SNR Ratio: 5, Epoch 11, Loss: 289.826111\n",
      "SNR Ratio: 5, Epoch 12, Loss: 297.096985\n",
      "SNR Ratio: 5, Epoch 13, Loss: 292.123047\n",
      "SNR Ratio: 5, Epoch 14, Loss: 280.335571\n",
      "SNR Ratio: 5, Epoch 15, Loss: 286.974426\n",
      "SNR Ratio: 5, Epoch 16, Loss: 280.498871\n",
      "SNR Ratio: 5, Epoch 17, Loss: 268.199799\n",
      "SNR Ratio: 5, Epoch 18, Loss: 273.782471\n",
      "SNR Ratio: 5, Epoch 19, Loss: 270.263153\n",
      "SNR Ratio: 5, Epoch 20, Loss: 264.273438\n",
      "SNR Ratio: 5, Epoch 21, Loss: 254.411606\n",
      "SNR Ratio: 5, Epoch 22, Loss: 261.371155\n",
      "SNR Ratio: 5, Epoch 23, Loss: 253.479721\n",
      "SNR Ratio: 5, Epoch 24, Loss: 254.575058\n",
      "SNR Ratio: 5, Epoch 25, Loss: 251.984238\n",
      "SNR Ratio: 5, Epoch 26, Loss: 240.510742\n",
      "SNR Ratio: 5, Epoch 27, Loss: 232.031143\n",
      "SNR Ratio: 5, Epoch 28, Loss: 237.503998\n",
      "SNR Ratio: 5, Epoch 29, Loss: 258.399231\n",
      "SNR Ratio: 5, Epoch 30, Loss: 244.824844\n",
      "SNR Ratio: 5, Epoch 31, Loss: 233.875534\n",
      "SNR Ratio: 5, Epoch 32, Loss: 246.755920\n",
      "SNR Ratio: 5, Epoch 33, Loss: 238.272675\n",
      "SNR Ratio: 5, Epoch 34, Loss: 237.653778\n",
      "SNR Ratio: 5, Epoch 35, Loss: 234.517075\n",
      "SNR Ratio: 5, Epoch 36, Loss: 239.346313\n",
      "SNR Ratio: 5, Epoch 37, Loss: 232.574356\n",
      "SNR Ratio: 5, Epoch 38, Loss: 230.067902\n",
      "SNR Ratio: 5, Epoch 39, Loss: 239.077972\n",
      "SNR Ratio: 5, Epoch 40, Loss: 228.352600\n",
      "SNR Ratio: 5, Epoch 41, Loss: 236.443237\n",
      "SNR Ratio: 5, Epoch 42, Loss: 234.986557\n",
      "SNR Ratio: 5, Epoch 43, Loss: 236.127594\n",
      "SNR Ratio: 5, Epoch 44, Loss: 230.031555\n",
      "SNR Ratio: 5, Epoch 45, Loss: 242.067200\n",
      "SNR Ratio: 5, Epoch 46, Loss: 233.529022\n",
      "SNR Ratio: 5, Epoch 47, Loss: 231.848022\n",
      "SNR Ratio: 5, Epoch 48, Loss: 222.469360\n",
      "SNR Ratio: 5, Epoch 49, Loss: 211.812439\n",
      "SNR Ratio: 5, Epoch 50, Loss: 221.947739\n",
      "SNR Ratio: 5, Epoch 51, Loss: 237.088715\n",
      "SNR Ratio: 5, Epoch 52, Loss: 234.290375\n",
      "SNR Ratio: 5, Epoch 53, Loss: 218.611313\n",
      "SNR Ratio: 5, Epoch 54, Loss: 213.711502\n",
      "SNR Ratio: 5, Epoch 55, Loss: 217.152557\n",
      "SNR Ratio: 5, Epoch 56, Loss: 233.438065\n",
      "SNR Ratio: 5, Epoch 57, Loss: 224.532776\n",
      "SNR Ratio: 5, Epoch 58, Loss: 220.882553\n",
      "SNR Ratio: 5, Epoch 59, Loss: 215.862473\n",
      "SNR Ratio: 5, Epoch 60, Loss: 218.212479\n",
      "SNR Ratio: 5, Epoch 61, Loss: 217.990326\n",
      "SNR Ratio: 5, Epoch 62, Loss: 218.577835\n",
      "SNR Ratio: 5, Epoch 63, Loss: 224.128662\n",
      "SNR Ratio: 5, Epoch 64, Loss: 227.179977\n",
      "SNR Ratio: 5, Epoch 65, Loss: 218.774307\n",
      "SNR Ratio: 5, Epoch 66, Loss: 218.085037\n",
      "SNR Ratio: 5, Epoch 67, Loss: 210.988861\n",
      "SNR Ratio: 5, Epoch 68, Loss: 220.715485\n",
      "SNR Ratio: 5, Epoch 69, Loss: 204.870041\n",
      "SNR Ratio: 5, Epoch 70, Loss: 203.153397\n",
      "SNR Ratio: 5, Epoch 71, Loss: 227.227264\n",
      "SNR Ratio: 5, Epoch 72, Loss: 212.585419\n",
      "SNR Ratio: 5, Epoch 73, Loss: 203.981644\n",
      "SNR Ratio: 5, Epoch 74, Loss: 199.459473\n",
      "SNR Ratio: 5, Epoch 75, Loss: 205.581421\n",
      "SNR Ratio: 5, Epoch 76, Loss: 200.801254\n",
      "SNR Ratio: 5, Epoch 77, Loss: 222.265686\n",
      "SNR Ratio: 5, Epoch 78, Loss: 188.378555\n",
      "SNR Ratio: 5, Epoch 79, Loss: 206.057983\n",
      "SNR Ratio: 5, Epoch 80, Loss: 206.128983\n",
      "SNR Ratio: 5, Epoch 81, Loss: 208.070633\n",
      "SNR Ratio: 5, Epoch 82, Loss: 210.097153\n",
      "SNR Ratio: 5, Epoch 83, Loss: 202.095993\n",
      "SNR Ratio: 5, Epoch 84, Loss: 221.284836\n",
      "SNR Ratio: 5, Epoch 85, Loss: 203.348160\n",
      "SNR Ratio: 5, Epoch 86, Loss: 203.250565\n",
      "SNR Ratio: 5, Epoch 87, Loss: 203.345779\n",
      "SNR Ratio: 5, Epoch 88, Loss: 207.047882\n",
      "SNR Ratio: 5, Epoch 89, Loss: 205.175140\n",
      "SNR Ratio: 5, Epoch 90, Loss: 211.496323\n",
      "SNR Ratio: 5, Epoch 91, Loss: 212.115646\n",
      "SNR Ratio: 5, Epoch 92, Loss: 212.927155\n",
      "SNR Ratio: 5, Epoch 93, Loss: 197.848267\n",
      "SNR Ratio: 5, Epoch 94, Loss: 219.713882\n",
      "SNR Ratio: 5, Epoch 95, Loss: 200.144638\n",
      "SNR Ratio: 5, Epoch 96, Loss: 201.751480\n",
      "SNR Ratio: 5, Epoch 97, Loss: 193.897980\n",
      "SNR Ratio: 5, Epoch 98, Loss: 208.228622\n",
      "SNR Ratio: 5, Epoch 99, Loss: 202.605042\n",
      "SNR Ratio: 5, Epoch 100, Loss: 205.395584\n",
      "SNR Ratio: 5, Epoch 101, Loss: 213.207077\n",
      "SNR Ratio: 5, Epoch 102, Loss: 193.020798\n",
      "SNR Ratio: 5, Epoch 103, Loss: 200.620758\n",
      "SNR Ratio: 5, Epoch 104, Loss: 200.946945\n",
      "SNR Ratio: 5, Epoch 105, Loss: 200.853455\n",
      "SNR Ratio: 5, Epoch 106, Loss: 202.410995\n",
      "SNR Ratio: 5, Epoch 107, Loss: 197.035782\n",
      "SNR Ratio: 5, Epoch 108, Loss: 187.360245\n",
      "SNR Ratio: 5, Epoch 109, Loss: 209.193481\n",
      "SNR Ratio: 5, Epoch 110, Loss: 204.985336\n",
      "SNR Ratio: 5, Epoch 111, Loss: 200.267242\n",
      "SNR Ratio: 5, Epoch 112, Loss: 203.104721\n",
      "SNR Ratio: 5, Epoch 113, Loss: 191.490265\n",
      "SNR Ratio: 5, Epoch 114, Loss: 202.416840\n",
      "SNR Ratio: 5, Epoch 115, Loss: 201.895538\n",
      "SNR Ratio: 5, Epoch 116, Loss: 202.050873\n",
      "SNR Ratio: 5, Epoch 117, Loss: 201.339844\n",
      "SNR Ratio: 5, Epoch 118, Loss: 195.900284\n",
      "SNR Ratio: 5, Epoch 119, Loss: 200.744125\n",
      "SNR Ratio: 5, Epoch 120, Loss: 185.156113\n",
      "SNR Ratio: 5, Epoch 121, Loss: 192.082245\n",
      "SNR Ratio: 5, Epoch 122, Loss: 193.545822\n",
      "SNR Ratio: 5, Epoch 123, Loss: 201.462814\n",
      "SNR Ratio: 5, Epoch 124, Loss: 203.391907\n",
      "SNR Ratio: 5, Epoch 125, Loss: 197.497360\n",
      "SNR Ratio: 5, Epoch 126, Loss: 181.539841\n",
      "SNR Ratio: 5, Epoch 127, Loss: 191.514038\n",
      "SNR Ratio: 5, Epoch 128, Loss: 201.960098\n",
      "SNR Ratio: 5, Epoch 129, Loss: 204.514160\n",
      "SNR Ratio: 5, Epoch 130, Loss: 198.893600\n",
      "SNR Ratio: 5, Epoch 131, Loss: 188.383575\n",
      "SNR Ratio: 5, Epoch 132, Loss: 185.915405\n",
      "SNR Ratio: 5, Epoch 133, Loss: 189.653625\n",
      "SNR Ratio: 5, Epoch 134, Loss: 187.360992\n",
      "SNR Ratio: 5, Epoch 135, Loss: 206.466385\n",
      "SNR Ratio: 5, Epoch 136, Loss: 194.400360\n",
      "SNR Ratio: 5, Epoch 137, Loss: 185.329483\n",
      "SNR Ratio: 5, Epoch 138, Loss: 198.774399\n",
      "SNR Ratio: 5, Epoch 139, Loss: 195.994965\n",
      "SNR Ratio: 5, Epoch 140, Loss: 198.968475\n",
      "SNR Ratio: 5, Epoch 141, Loss: 187.537506\n",
      "SNR Ratio: 5, Epoch 142, Loss: 186.385193\n",
      "SNR Ratio: 5, Epoch 143, Loss: 187.040405\n",
      "SNR Ratio: 5, Epoch 144, Loss: 199.255783\n",
      "SNR Ratio: 5, Epoch 145, Loss: 196.695084\n",
      "SNR Ratio: 5, Epoch 146, Loss: 185.070862\n",
      "SNR Ratio: 5, Epoch 147, Loss: 190.673004\n",
      "SNR Ratio: 5, Epoch 148, Loss: 197.088516\n",
      "SNR Ratio: 5, Epoch 149, Loss: 186.730438\n",
      "SNR Ratio: 5, Epoch 150, Loss: 183.337204\n",
      "SNR Ratio: 5, Epoch 151, Loss: 206.980804\n",
      "SNR Ratio: 5, Epoch 152, Loss: 185.555634\n",
      "SNR Ratio: 5, Epoch 153, Loss: 191.434418\n",
      "SNR Ratio: 5, Epoch 154, Loss: 205.771484\n",
      "SNR Ratio: 5, Epoch 155, Loss: 188.305801\n",
      "SNR Ratio: 5, Epoch 156, Loss: 178.212006\n",
      "SNR Ratio: 5, Epoch 157, Loss: 184.796417\n",
      "SNR Ratio: 5, Epoch 158, Loss: 188.296097\n",
      "SNR Ratio: 5, Epoch 159, Loss: 191.562485\n",
      "SNR Ratio: 5, Epoch 160, Loss: 173.665604\n",
      "SNR Ratio: 5, Epoch 161, Loss: 177.400162\n",
      "SNR Ratio: 5, Epoch 162, Loss: 181.721252\n",
      "SNR Ratio: 5, Epoch 163, Loss: 193.327896\n",
      "SNR Ratio: 5, Epoch 164, Loss: 177.394333\n",
      "SNR Ratio: 5, Epoch 165, Loss: 175.702896\n",
      "SNR Ratio: 5, Epoch 166, Loss: 191.449432\n",
      "SNR Ratio: 5, Epoch 167, Loss: 182.443420\n",
      "SNR Ratio: 5, Epoch 168, Loss: 173.574097\n",
      "SNR Ratio: 5, Epoch 169, Loss: 188.655914\n",
      "SNR Ratio: 5, Epoch 170, Loss: 184.281082\n",
      "SNR Ratio: 5, Epoch 171, Loss: 191.407486\n",
      "SNR Ratio: 5, Epoch 172, Loss: 177.351364\n",
      "SNR Ratio: 5, Epoch 173, Loss: 170.150681\n",
      "SNR Ratio: 5, Epoch 174, Loss: 178.946457\n",
      "SNR Ratio: 5, Epoch 175, Loss: 166.485687\n",
      "SNR Ratio: 5, Epoch 176, Loss: 169.390472\n",
      "SNR Ratio: 5, Epoch 177, Loss: 179.523926\n",
      "SNR Ratio: 5, Epoch 178, Loss: 187.982758\n",
      "SNR Ratio: 5, Epoch 179, Loss: 189.453659\n",
      "SNR Ratio: 5, Epoch 180, Loss: 183.692062\n",
      "SNR Ratio: 5, Epoch 181, Loss: 182.584122\n",
      "SNR Ratio: 5, Epoch 182, Loss: 172.047119\n",
      "SNR Ratio: 5, Epoch 183, Loss: 180.231567\n",
      "SNR Ratio: 5, Epoch 184, Loss: 182.899323\n",
      "SNR Ratio: 5, Epoch 185, Loss: 174.594788\n",
      "SNR Ratio: 5, Epoch 186, Loss: 190.114197\n",
      "SNR Ratio: 5, Epoch 187, Loss: 175.266998\n",
      "SNR Ratio: 5, Epoch 188, Loss: 183.408096\n",
      "SNR Ratio: 5, Epoch 189, Loss: 182.187454\n",
      "SNR Ratio: 5, Epoch 190, Loss: 177.715927\n",
      "SNR Ratio: 5, Epoch 191, Loss: 167.944382\n",
      "SNR Ratio: 5, Epoch 192, Loss: 182.173599\n",
      "SNR Ratio: 5, Epoch 193, Loss: 165.604202\n",
      "SNR Ratio: 5, Epoch 194, Loss: 178.968018\n",
      "SNR Ratio: 5, Epoch 195, Loss: 176.329620\n",
      "SNR Ratio: 5, Epoch 196, Loss: 185.084122\n",
      "SNR Ratio: 5, Epoch 197, Loss: 192.147247\n",
      "SNR Ratio: 5, Epoch 198, Loss: 187.694565\n",
      "SNR Ratio: 5, Epoch 199, Loss: 168.612503\n",
      "SNR Ratio: 5, Epoch 200, Loss: 178.972595\n",
      "SNR Ratio: 5, Epoch 201, Loss: 171.753784\n",
      "SNR Ratio: 5, Epoch 202, Loss: 180.174515\n",
      "SNR Ratio: 5, Epoch 203, Loss: 192.645020\n",
      "SNR Ratio: 5, Epoch 204, Loss: 156.491562\n",
      "SNR Ratio: 5, Epoch 205, Loss: 180.530273\n",
      "SNR Ratio: 5, Epoch 206, Loss: 189.360687\n",
      "SNR Ratio: 5, Epoch 207, Loss: 183.336258\n",
      "SNR Ratio: 5, Epoch 208, Loss: 175.234161\n",
      "SNR Ratio: 5, Epoch 209, Loss: 186.507523\n",
      "SNR Ratio: 5, Epoch 210, Loss: 165.650681\n",
      "SNR Ratio: 5, Epoch 211, Loss: 155.742157\n",
      "SNR Ratio: 5, Epoch 212, Loss: 170.645294\n",
      "SNR Ratio: 5, Epoch 213, Loss: 179.270844\n",
      "SNR Ratio: 5, Epoch 214, Loss: 174.614822\n",
      "SNR Ratio: 5, Epoch 215, Loss: 180.602524\n",
      "SNR Ratio: 5, Epoch 216, Loss: 174.123444\n",
      "SNR Ratio: 5, Epoch 217, Loss: 182.293793\n",
      "SNR Ratio: 5, Epoch 218, Loss: 169.845596\n",
      "SNR Ratio: 5, Epoch 219, Loss: 177.351425\n",
      "SNR Ratio: 5, Epoch 220, Loss: 176.230682\n",
      "SNR Ratio: 5, Epoch 221, Loss: 179.048233\n",
      "SNR Ratio: 5, Epoch 222, Loss: 171.043594\n",
      "SNR Ratio: 5, Epoch 223, Loss: 178.320816\n",
      "SNR Ratio: 5, Epoch 224, Loss: 161.234818\n",
      "SNR Ratio: 5, Epoch 225, Loss: 175.597702\n",
      "SNR Ratio: 5, Epoch 226, Loss: 194.039444\n",
      "SNR Ratio: 5, Epoch 227, Loss: 166.848312\n",
      "SNR Ratio: 5, Epoch 228, Loss: 185.445587\n",
      "SNR Ratio: 5, Epoch 229, Loss: 168.706787\n",
      "SNR Ratio: 5, Epoch 230, Loss: 165.377533\n",
      "SNR Ratio: 5, Epoch 231, Loss: 172.974899\n",
      "SNR Ratio: 5, Epoch 232, Loss: 165.041885\n",
      "SNR Ratio: 5, Epoch 233, Loss: 181.531036\n",
      "SNR Ratio: 5, Epoch 234, Loss: 169.853836\n",
      "SNR Ratio: 5, Epoch 235, Loss: 173.635468\n",
      "SNR Ratio: 5, Epoch 236, Loss: 174.529526\n",
      "SNR Ratio: 5, Epoch 237, Loss: 182.000885\n",
      "SNR Ratio: 5, Epoch 238, Loss: 176.254120\n",
      "SNR Ratio: 5, Epoch 239, Loss: 184.251480\n",
      "SNR Ratio: 5, Epoch 240, Loss: 176.545258\n",
      "SNR Ratio: 5, Epoch 241, Loss: 176.858444\n",
      "SNR Ratio: 5, Epoch 242, Loss: 157.102203\n",
      "SNR Ratio: 5, Epoch 243, Loss: 163.604691\n",
      "SNR Ratio: 5, Epoch 244, Loss: 165.452667\n",
      "SNR Ratio: 5, Epoch 245, Loss: 186.946136\n",
      "SNR Ratio: 5, Epoch 246, Loss: 165.288147\n",
      "SNR Ratio: 5, Epoch 247, Loss: 185.383499\n",
      "SNR Ratio: 5, Epoch 248, Loss: 174.337204\n",
      "SNR Ratio: 5, Epoch 249, Loss: 193.675598\n",
      "SNR Ratio: 5, Epoch 250, Loss: 159.618103\n",
      "SNR Ratio: 5, Epoch 251, Loss: 176.926025\n",
      "SNR Ratio: 5, Epoch 252, Loss: 155.903046\n",
      "SNR Ratio: 5, Epoch 253, Loss: 175.098007\n",
      "SNR Ratio: 5, Epoch 254, Loss: 161.898987\n",
      "SNR Ratio: 5, Epoch 255, Loss: 153.259354\n",
      "SNR Ratio: 5, Epoch 256, Loss: 168.732040\n",
      "SNR Ratio: 5, Epoch 257, Loss: 165.763336\n",
      "SNR Ratio: 5, Epoch 258, Loss: 156.822037\n",
      "SNR Ratio: 5, Epoch 259, Loss: 170.887802\n",
      "SNR Ratio: 5, Epoch 260, Loss: 171.112839\n",
      "SNR Ratio: 5, Epoch 261, Loss: 157.646194\n",
      "SNR Ratio: 5, Epoch 262, Loss: 168.536087\n",
      "SNR Ratio: 5, Epoch 263, Loss: 168.694382\n",
      "SNR Ratio: 5, Epoch 264, Loss: 163.021881\n",
      "SNR Ratio: 5, Epoch 265, Loss: 159.068405\n",
      "SNR Ratio: 5, Epoch 266, Loss: 165.480057\n",
      "SNR Ratio: 5, Epoch 267, Loss: 181.267380\n",
      "SNR Ratio: 5, Epoch 268, Loss: 169.859344\n",
      "SNR Ratio: 5, Epoch 269, Loss: 166.058228\n",
      "SNR Ratio: 5, Epoch 270, Loss: 160.554047\n",
      "SNR Ratio: 5, Epoch 271, Loss: 175.778885\n",
      "SNR Ratio: 5, Epoch 272, Loss: 181.036713\n",
      "SNR Ratio: 5, Epoch 273, Loss: 166.544403\n",
      "SNR Ratio: 5, Epoch 274, Loss: 174.088165\n",
      "SNR Ratio: 5, Epoch 275, Loss: 168.830215\n",
      "SNR Ratio: 5, Epoch 276, Loss: 160.507126\n",
      "SNR Ratio: 5, Epoch 277, Loss: 157.972107\n",
      "SNR Ratio: 5, Epoch 278, Loss: 173.655502\n",
      "SNR Ratio: 5, Epoch 279, Loss: 152.803284\n",
      "SNR Ratio: 5, Epoch 280, Loss: 163.171158\n",
      "SNR Ratio: 5, Epoch 281, Loss: 152.700180\n",
      "SNR Ratio: 5, Epoch 282, Loss: 156.823593\n",
      "SNR Ratio: 5, Epoch 283, Loss: 166.663788\n",
      "SNR Ratio: 5, Epoch 284, Loss: 155.412521\n",
      "SNR Ratio: 5, Epoch 285, Loss: 163.302094\n",
      "SNR Ratio: 5, Epoch 286, Loss: 160.792862\n",
      "SNR Ratio: 5, Epoch 287, Loss: 157.457016\n",
      "SNR Ratio: 5, Epoch 288, Loss: 158.931778\n",
      "SNR Ratio: 5, Epoch 289, Loss: 179.166962\n",
      "SNR Ratio: 5, Epoch 290, Loss: 170.621063\n",
      "SNR Ratio: 5, Epoch 291, Loss: 166.714935\n",
      "SNR Ratio: 5, Epoch 292, Loss: 153.730515\n",
      "SNR Ratio: 5, Epoch 293, Loss: 170.359634\n",
      "SNR Ratio: 5, Epoch 294, Loss: 147.686356\n",
      "SNR Ratio: 5, Epoch 295, Loss: 150.849014\n",
      "SNR Ratio: 5, Epoch 296, Loss: 178.858322\n",
      "SNR Ratio: 5, Epoch 297, Loss: 162.528152\n",
      "SNR Ratio: 5, Epoch 298, Loss: 171.738586\n",
      "SNR Ratio: 5, Epoch 299, Loss: 152.891327\n",
      "SNR Ratio: 5, Epoch 300, Loss: 153.162659\n",
      "SNR Ratio: 5, Epoch 301, Loss: 148.890228\n",
      "SNR Ratio: 5, Epoch 302, Loss: 175.574036\n",
      "SNR Ratio: 5, Epoch 303, Loss: 160.509018\n",
      "SNR Ratio: 5, Epoch 304, Loss: 167.803513\n",
      "SNR Ratio: 5, Epoch 305, Loss: 161.282303\n",
      "SNR Ratio: 5, Epoch 306, Loss: 149.177673\n",
      "SNR Ratio: 5, Epoch 307, Loss: 163.363144\n",
      "SNR Ratio: 5, Epoch 308, Loss: 162.397995\n",
      "SNR Ratio: 5, Epoch 309, Loss: 154.598038\n",
      "SNR Ratio: 5, Epoch 310, Loss: 162.497528\n",
      "SNR Ratio: 5, Epoch 311, Loss: 159.624023\n",
      "SNR Ratio: 5, Epoch 312, Loss: 162.655838\n",
      "SNR Ratio: 5, Epoch 313, Loss: 144.646378\n",
      "SNR Ratio: 5, Epoch 314, Loss: 158.405807\n",
      "SNR Ratio: 5, Epoch 315, Loss: 154.226212\n",
      "SNR Ratio: 5, Epoch 316, Loss: 155.389725\n",
      "SNR Ratio: 5, Epoch 317, Loss: 165.991364\n",
      "SNR Ratio: 5, Epoch 318, Loss: 157.103287\n",
      "SNR Ratio: 5, Epoch 319, Loss: 169.039001\n",
      "SNR Ratio: 5, Epoch 320, Loss: 167.719147\n",
      "SNR Ratio: 5, Epoch 321, Loss: 163.582443\n",
      "SNR Ratio: 5, Epoch 322, Loss: 152.482162\n",
      "SNR Ratio: 5, Epoch 323, Loss: 159.884903\n",
      "SNR Ratio: 5, Epoch 324, Loss: 158.941742\n",
      "SNR Ratio: 5, Epoch 325, Loss: 151.103958\n",
      "SNR Ratio: 5, Epoch 326, Loss: 173.288895\n",
      "SNR Ratio: 5, Epoch 327, Loss: 164.267273\n",
      "SNR Ratio: 5, Epoch 328, Loss: 152.200638\n",
      "SNR Ratio: 5, Epoch 329, Loss: 154.595535\n",
      "SNR Ratio: 5, Epoch 330, Loss: 149.888214\n",
      "SNR Ratio: 5, Epoch 331, Loss: 151.990616\n",
      "SNR Ratio: 5, Epoch 332, Loss: 159.899445\n",
      "SNR Ratio: 5, Epoch 333, Loss: 150.553406\n",
      "SNR Ratio: 5, Epoch 334, Loss: 156.903809\n",
      "SNR Ratio: 5, Epoch 335, Loss: 144.891541\n",
      "SNR Ratio: 5, Epoch 336, Loss: 145.480255\n",
      "SNR Ratio: 5, Epoch 337, Loss: 143.756744\n",
      "SNR Ratio: 5, Epoch 338, Loss: 150.205887\n",
      "SNR Ratio: 5, Epoch 339, Loss: 153.101974\n",
      "SNR Ratio: 5, Epoch 340, Loss: 170.734238\n",
      "SNR Ratio: 5, Epoch 341, Loss: 153.686905\n",
      "SNR Ratio: 5, Epoch 342, Loss: 148.891998\n",
      "SNR Ratio: 5, Epoch 343, Loss: 173.627243\n",
      "SNR Ratio: 5, Epoch 344, Loss: 156.322937\n",
      "SNR Ratio: 5, Epoch 345, Loss: 167.312698\n",
      "SNR Ratio: 5, Epoch 346, Loss: 157.923782\n",
      "SNR Ratio: 5, Epoch 347, Loss: 159.624084\n",
      "SNR Ratio: 5, Epoch 348, Loss: 144.086700\n",
      "SNR Ratio: 5, Epoch 349, Loss: 161.967255\n",
      "SNR Ratio: 5, Epoch 350, Loss: 157.585953\n",
      "SNR Ratio: 5, Epoch 351, Loss: 152.423798\n",
      "SNR Ratio: 5, Epoch 352, Loss: 159.917847\n",
      "SNR Ratio: 5, Epoch 353, Loss: 158.775864\n",
      "SNR Ratio: 5, Epoch 354, Loss: 166.513336\n",
      "SNR Ratio: 5, Epoch 355, Loss: 158.650879\n",
      "SNR Ratio: 5, Epoch 356, Loss: 150.892242\n",
      "SNR Ratio: 5, Epoch 357, Loss: 154.128479\n",
      "SNR Ratio: 5, Epoch 358, Loss: 155.669128\n",
      "SNR Ratio: 5, Epoch 359, Loss: 160.349915\n",
      "SNR Ratio: 5, Epoch 360, Loss: 161.622116\n",
      "SNR Ratio: 5, Epoch 361, Loss: 176.158356\n",
      "SNR Ratio: 5, Epoch 362, Loss: 145.897354\n",
      "SNR Ratio: 5, Epoch 363, Loss: 152.639893\n",
      "SNR Ratio: 5, Epoch 364, Loss: 145.718643\n",
      "SNR Ratio: 5, Epoch 365, Loss: 156.545319\n",
      "SNR Ratio: 5, Epoch 366, Loss: 170.083847\n",
      "SNR Ratio: 5, Epoch 367, Loss: 150.830460\n",
      "SNR Ratio: 5, Epoch 368, Loss: 151.213623\n",
      "SNR Ratio: 5, Epoch 369, Loss: 144.609650\n",
      "SNR Ratio: 5, Epoch 370, Loss: 158.092926\n",
      "SNR Ratio: 5, Epoch 371, Loss: 149.089081\n",
      "SNR Ratio: 5, Epoch 372, Loss: 171.935959\n",
      "SNR Ratio: 5, Epoch 373, Loss: 162.603882\n",
      "SNR Ratio: 5, Epoch 374, Loss: 159.997665\n",
      "SNR Ratio: 5, Epoch 375, Loss: 153.816422\n",
      "SNR Ratio: 5, Epoch 376, Loss: 146.103500\n",
      "SNR Ratio: 5, Epoch 377, Loss: 146.952881\n",
      "SNR Ratio: 5, Epoch 378, Loss: 145.693436\n",
      "SNR Ratio: 5, Epoch 379, Loss: 153.096603\n",
      "SNR Ratio: 5, Epoch 380, Loss: 159.376419\n",
      "SNR Ratio: 5, Epoch 381, Loss: 135.698517\n",
      "SNR Ratio: 5, Epoch 382, Loss: 152.586395\n",
      "SNR Ratio: 5, Epoch 383, Loss: 152.370590\n",
      "SNR Ratio: 5, Epoch 384, Loss: 149.646332\n",
      "SNR Ratio: 5, Epoch 385, Loss: 144.722214\n",
      "SNR Ratio: 5, Epoch 386, Loss: 155.509903\n",
      "SNR Ratio: 5, Epoch 387, Loss: 165.872940\n",
      "SNR Ratio: 5, Epoch 388, Loss: 153.651886\n",
      "SNR Ratio: 5, Epoch 389, Loss: 165.736603\n",
      "SNR Ratio: 5, Epoch 390, Loss: 151.741974\n",
      "SNR Ratio: 5, Epoch 391, Loss: 155.497787\n",
      "SNR Ratio: 5, Epoch 392, Loss: 152.085648\n",
      "SNR Ratio: 5, Epoch 393, Loss: 159.959076\n",
      "SNR Ratio: 5, Epoch 394, Loss: 174.785324\n",
      "SNR Ratio: 5, Epoch 395, Loss: 146.617432\n",
      "SNR Ratio: 5, Epoch 396, Loss: 139.376999\n",
      "SNR Ratio: 5, Epoch 397, Loss: 139.168335\n",
      "SNR Ratio: 5, Epoch 398, Loss: 148.872345\n",
      "SNR Ratio: 5, Epoch 399, Loss: 146.088531\n",
      "SNR Ratio: 5, Epoch 400, Loss: 154.492615\n",
      "SNR Ratio: 5, Epoch 401, Loss: 151.909790\n",
      "SNR Ratio: 5, Epoch 402, Loss: 151.909683\n",
      "SNR Ratio: 5, Epoch 403, Loss: 146.529587\n",
      "SNR Ratio: 5, Epoch 404, Loss: 164.334396\n",
      "SNR Ratio: 5, Epoch 405, Loss: 152.498123\n",
      "SNR Ratio: 5, Epoch 406, Loss: 140.183716\n",
      "SNR Ratio: 5, Epoch 407, Loss: 156.565994\n",
      "SNR Ratio: 5, Epoch 408, Loss: 161.180923\n",
      "SNR Ratio: 5, Epoch 409, Loss: 155.197220\n",
      "SNR Ratio: 5, Epoch 410, Loss: 147.994141\n",
      "SNR Ratio: 5, Epoch 411, Loss: 158.246933\n",
      "SNR Ratio: 5, Epoch 412, Loss: 156.111877\n",
      "SNR Ratio: 5, Epoch 413, Loss: 142.892426\n",
      "SNR Ratio: 5, Epoch 414, Loss: 158.704407\n",
      "SNR Ratio: 5, Epoch 415, Loss: 166.859894\n",
      "SNR Ratio: 5, Epoch 416, Loss: 147.921997\n",
      "SNR Ratio: 5, Epoch 417, Loss: 149.977066\n",
      "SNR Ratio: 5, Epoch 418, Loss: 155.565659\n",
      "SNR Ratio: 5, Epoch 419, Loss: 160.555954\n",
      "SNR Ratio: 5, Epoch 420, Loss: 149.577133\n",
      "SNR Ratio: 5, Epoch 421, Loss: 146.285324\n",
      "SNR Ratio: 5, Epoch 422, Loss: 148.621719\n",
      "SNR Ratio: 5, Epoch 423, Loss: 152.761581\n",
      "SNR Ratio: 5, Epoch 424, Loss: 153.376022\n",
      "SNR Ratio: 5, Epoch 425, Loss: 152.052246\n",
      "SNR Ratio: 5, Epoch 426, Loss: 138.958374\n",
      "SNR Ratio: 5, Epoch 427, Loss: 152.503494\n",
      "SNR Ratio: 5, Epoch 428, Loss: 163.340256\n",
      "SNR Ratio: 5, Epoch 429, Loss: 159.292404\n",
      "SNR Ratio: 5, Epoch 430, Loss: 149.896301\n",
      "SNR Ratio: 5, Epoch 431, Loss: 135.476944\n",
      "SNR Ratio: 5, Epoch 432, Loss: 152.581055\n",
      "SNR Ratio: 5, Epoch 433, Loss: 155.295135\n",
      "SNR Ratio: 5, Epoch 434, Loss: 139.177658\n",
      "SNR Ratio: 5, Epoch 435, Loss: 147.772919\n",
      "SNR Ratio: 5, Epoch 436, Loss: 142.495056\n",
      "SNR Ratio: 5, Epoch 437, Loss: 150.841568\n",
      "SNR Ratio: 5, Epoch 438, Loss: 157.492706\n",
      "SNR Ratio: 5, Epoch 439, Loss: 162.230865\n",
      "SNR Ratio: 5, Epoch 440, Loss: 144.090485\n",
      "SNR Ratio: 5, Epoch 441, Loss: 138.700394\n",
      "SNR Ratio: 5, Epoch 442, Loss: 138.651505\n",
      "SNR Ratio: 5, Epoch 443, Loss: 141.613342\n",
      "SNR Ratio: 5, Epoch 444, Loss: 158.618454\n",
      "SNR Ratio: 5, Epoch 445, Loss: 144.561981\n",
      "SNR Ratio: 5, Epoch 446, Loss: 144.146973\n",
      "SNR Ratio: 5, Epoch 447, Loss: 158.045288\n",
      "SNR Ratio: 5, Epoch 448, Loss: 138.354599\n",
      "SNR Ratio: 5, Epoch 449, Loss: 154.181885\n",
      "SNR Ratio: 5, Epoch 450, Loss: 145.639084\n",
      "SNR Ratio: 5, Epoch 451, Loss: 157.265533\n",
      "SNR Ratio: 5, Epoch 452, Loss: 142.191605\n",
      "SNR Ratio: 5, Epoch 453, Loss: 142.305725\n",
      "SNR Ratio: 5, Epoch 454, Loss: 142.418396\n",
      "SNR Ratio: 5, Epoch 455, Loss: 159.988693\n",
      "SNR Ratio: 5, Epoch 456, Loss: 143.000305\n",
      "SNR Ratio: 5, Epoch 457, Loss: 160.358215\n",
      "SNR Ratio: 5, Epoch 458, Loss: 145.946381\n",
      "SNR Ratio: 5, Epoch 459, Loss: 148.729370\n",
      "SNR Ratio: 5, Epoch 460, Loss: 147.718597\n",
      "SNR Ratio: 5, Epoch 461, Loss: 164.408447\n",
      "SNR Ratio: 5, Epoch 462, Loss: 160.877258\n",
      "SNR Ratio: 5, Epoch 463, Loss: 162.351456\n",
      "SNR Ratio: 5, Epoch 464, Loss: 153.475693\n",
      "SNR Ratio: 5, Epoch 465, Loss: 148.906891\n",
      "SNR Ratio: 5, Epoch 466, Loss: 158.736237\n",
      "SNR Ratio: 5, Epoch 467, Loss: 149.094879\n",
      "SNR Ratio: 5, Epoch 468, Loss: 141.533951\n",
      "SNR Ratio: 5, Epoch 469, Loss: 155.684708\n",
      "SNR Ratio: 5, Epoch 470, Loss: 147.197678\n",
      "SNR Ratio: 5, Epoch 471, Loss: 142.334503\n",
      "SNR Ratio: 5, Epoch 472, Loss: 157.530640\n",
      "SNR Ratio: 5, Epoch 473, Loss: 161.694229\n",
      "SNR Ratio: 5, Epoch 474, Loss: 148.748825\n",
      "SNR Ratio: 5, Epoch 475, Loss: 153.080521\n",
      "SNR Ratio: 5, Epoch 476, Loss: 154.240097\n",
      "SNR Ratio: 5, Epoch 477, Loss: 149.779221\n",
      "SNR Ratio: 5, Epoch 478, Loss: 150.958893\n",
      "SNR Ratio: 5, Epoch 479, Loss: 149.238297\n",
      "SNR Ratio: 5, Epoch 480, Loss: 163.507156\n",
      "SNR Ratio: 5, Epoch 481, Loss: 153.398087\n",
      "SNR Ratio: 5, Epoch 482, Loss: 143.521622\n",
      "SNR Ratio: 5, Epoch 483, Loss: 164.082367\n",
      "SNR Ratio: 5, Epoch 484, Loss: 152.822327\n",
      "SNR Ratio: 5, Epoch 485, Loss: 159.723724\n",
      "SNR Ratio: 5, Epoch 486, Loss: 166.681015\n",
      "SNR Ratio: 5, Epoch 487, Loss: 133.105438\n",
      "SNR Ratio: 5, Epoch 488, Loss: 139.206390\n",
      "SNR Ratio: 5, Epoch 489, Loss: 156.398560\n",
      "SNR Ratio: 5, Epoch 490, Loss: 166.605408\n",
      "SNR Ratio: 5, Epoch 491, Loss: 154.752609\n",
      "SNR Ratio: 5, Epoch 492, Loss: 131.876617\n",
      "SNR Ratio: 5, Epoch 493, Loss: 155.810059\n",
      "SNR Ratio: 5, Epoch 494, Loss: 159.220413\n",
      "SNR Ratio: 5, Epoch 495, Loss: 149.756821\n",
      "SNR Ratio: 5, Epoch 496, Loss: 154.854248\n",
      "SNR Ratio: 5, Epoch 497, Loss: 151.515549\n",
      "SNR Ratio: 5, Epoch 498, Loss: 156.659805\n",
      "SNR Ratio: 5, Epoch 499, Loss: 166.913940\n",
      "SNR Ratio: 5, Epoch 500, Loss: 134.319763\n",
      "SNR Ratio: 5, Epoch 501, Loss: 158.277466\n",
      "SNR Ratio: 5, Epoch 502, Loss: 157.669235\n",
      "SNR Ratio: 5, Epoch 503, Loss: 145.346542\n",
      "SNR Ratio: 5, Epoch 504, Loss: 153.812500\n",
      "SNR Ratio: 5, Epoch 505, Loss: 149.882965\n",
      "SNR Ratio: 5, Epoch 506, Loss: 150.220718\n",
      "SNR Ratio: 5, Epoch 507, Loss: 149.824463\n",
      "SNR Ratio: 5, Epoch 508, Loss: 142.645050\n",
      "SNR Ratio: 5, Epoch 509, Loss: 146.066467\n",
      "SNR Ratio: 5, Epoch 510, Loss: 156.454926\n",
      "SNR Ratio: 5, Epoch 511, Loss: 148.964539\n",
      "SNR Ratio: 5, Epoch 512, Loss: 153.406982\n",
      "SNR Ratio: 5, Epoch 513, Loss: 155.273407\n",
      "SNR Ratio: 5, Epoch 514, Loss: 136.543594\n",
      "SNR Ratio: 5, Epoch 515, Loss: 147.098053\n",
      "SNR Ratio: 5, Epoch 516, Loss: 134.906433\n",
      "SNR Ratio: 5, Epoch 517, Loss: 145.921814\n",
      "SNR Ratio: 5, Epoch 518, Loss: 154.682724\n",
      "SNR Ratio: 5, Epoch 519, Loss: 164.840073\n",
      "SNR Ratio: 5, Epoch 520, Loss: 152.442627\n",
      "SNR Ratio: 5, Epoch 521, Loss: 144.248260\n",
      "SNR Ratio: 5, Epoch 522, Loss: 154.257812\n",
      "SNR Ratio: 5, Epoch 523, Loss: 138.173340\n",
      "SNR Ratio: 5, Epoch 524, Loss: 147.884918\n",
      "SNR Ratio: 5, Epoch 525, Loss: 133.372955\n",
      "SNR Ratio: 5, Epoch 526, Loss: 144.213623\n",
      "SNR Ratio: 5, Epoch 527, Loss: 131.843979\n",
      "SNR Ratio: 5, Epoch 528, Loss: 148.760315\n",
      "SNR Ratio: 5, Epoch 529, Loss: 143.021683\n",
      "SNR Ratio: 5, Epoch 530, Loss: 135.708755\n",
      "SNR Ratio: 5, Epoch 531, Loss: 148.572357\n",
      "SNR Ratio: 5, Epoch 532, Loss: 148.567078\n",
      "SNR Ratio: 5, Epoch 533, Loss: 148.482025\n",
      "SNR Ratio: 5, Epoch 534, Loss: 157.881470\n",
      "SNR Ratio: 5, Epoch 535, Loss: 141.207443\n",
      "SNR Ratio: 5, Epoch 536, Loss: 156.771027\n",
      "SNR Ratio: 5, Epoch 537, Loss: 152.144241\n",
      "SNR Ratio: 5, Epoch 538, Loss: 148.579224\n",
      "SNR Ratio: 5, Epoch 539, Loss: 147.690918\n",
      "SNR Ratio: 5, Epoch 540, Loss: 146.695847\n",
      "SNR Ratio: 5, Epoch 541, Loss: 150.811523\n",
      "SNR Ratio: 5, Epoch 542, Loss: 142.093674\n",
      "SNR Ratio: 5, Epoch 543, Loss: 144.369308\n",
      "SNR Ratio: 5, Epoch 544, Loss: 127.081871\n",
      "SNR Ratio: 5, Epoch 545, Loss: 151.479462\n",
      "SNR Ratio: 5, Epoch 546, Loss: 142.489456\n",
      "SNR Ratio: 5, Epoch 547, Loss: 150.862823\n",
      "SNR Ratio: 5, Epoch 548, Loss: 138.121399\n",
      "SNR Ratio: 5, Epoch 549, Loss: 133.413208\n",
      "SNR Ratio: 5, Epoch 550, Loss: 154.414062\n",
      "SNR Ratio: 5, Epoch 551, Loss: 133.675995\n",
      "SNR Ratio: 5, Epoch 552, Loss: 139.293137\n",
      "SNR Ratio: 5, Epoch 553, Loss: 143.620911\n",
      "SNR Ratio: 5, Epoch 554, Loss: 140.224686\n",
      "SNR Ratio: 5, Epoch 555, Loss: 145.971176\n",
      "SNR Ratio: 5, Epoch 556, Loss: 145.913101\n",
      "SNR Ratio: 5, Epoch 557, Loss: 145.692352\n",
      "SNR Ratio: 5, Epoch 558, Loss: 144.304764\n",
      "SNR Ratio: 5, Epoch 559, Loss: 125.009064\n",
      "SNR Ratio: 5, Epoch 560, Loss: 137.989334\n",
      "SNR Ratio: 5, Epoch 561, Loss: 151.257355\n",
      "SNR Ratio: 5, Epoch 562, Loss: 152.812485\n",
      "SNR Ratio: 5, Epoch 563, Loss: 134.044205\n",
      "SNR Ratio: 5, Epoch 564, Loss: 131.497528\n",
      "SNR Ratio: 5, Epoch 565, Loss: 143.627930\n",
      "SNR Ratio: 5, Epoch 566, Loss: 146.128128\n",
      "SNR Ratio: 5, Epoch 567, Loss: 145.017242\n",
      "SNR Ratio: 5, Epoch 568, Loss: 139.139465\n",
      "SNR Ratio: 5, Epoch 569, Loss: 130.547745\n",
      "SNR Ratio: 5, Epoch 570, Loss: 154.525284\n",
      "SNR Ratio: 5, Epoch 571, Loss: 142.691544\n",
      "SNR Ratio: 5, Epoch 572, Loss: 152.578781\n",
      "SNR Ratio: 5, Epoch 573, Loss: 149.389740\n",
      "SNR Ratio: 5, Epoch 574, Loss: 151.112595\n",
      "SNR Ratio: 5, Epoch 575, Loss: 144.159500\n",
      "SNR Ratio: 5, Epoch 576, Loss: 164.202866\n",
      "SNR Ratio: 5, Epoch 577, Loss: 145.643875\n",
      "SNR Ratio: 5, Epoch 578, Loss: 142.211624\n",
      "SNR Ratio: 5, Epoch 579, Loss: 144.507660\n",
      "SNR Ratio: 5, Epoch 580, Loss: 168.735397\n",
      "SNR Ratio: 5, Epoch 581, Loss: 143.897919\n",
      "SNR Ratio: 5, Epoch 582, Loss: 143.676270\n",
      "SNR Ratio: 5, Epoch 583, Loss: 152.781464\n",
      "SNR Ratio: 5, Epoch 584, Loss: 143.817245\n",
      "SNR Ratio: 5, Epoch 585, Loss: 154.754807\n",
      "SNR Ratio: 5, Epoch 586, Loss: 139.920578\n",
      "SNR Ratio: 5, Epoch 587, Loss: 130.356064\n",
      "SNR Ratio: 5, Epoch 588, Loss: 143.442947\n",
      "SNR Ratio: 5, Epoch 589, Loss: 133.529312\n",
      "SNR Ratio: 5, Epoch 590, Loss: 143.028244\n",
      "SNR Ratio: 5, Epoch 591, Loss: 141.862686\n",
      "SNR Ratio: 5, Epoch 592, Loss: 160.898499\n",
      "SNR Ratio: 5, Epoch 593, Loss: 150.383743\n",
      "SNR Ratio: 5, Epoch 594, Loss: 150.003403\n",
      "SNR Ratio: 5, Epoch 595, Loss: 134.732193\n",
      "SNR Ratio: 5, Epoch 596, Loss: 132.765823\n",
      "SNR Ratio: 5, Epoch 597, Loss: 138.662582\n",
      "SNR Ratio: 5, Epoch 598, Loss: 136.630447\n",
      "SNR Ratio: 5, Epoch 599, Loss: 149.379379\n",
      "SNR Ratio: 5, Epoch 600, Loss: 144.967621\n",
      "SNR Ratio: 5, Epoch 601, Loss: 145.662384\n",
      "SNR Ratio: 5, Epoch 602, Loss: 136.526657\n",
      "SNR Ratio: 5, Epoch 603, Loss: 139.475266\n",
      "SNR Ratio: 5, Epoch 604, Loss: 147.586761\n",
      "SNR Ratio: 5, Epoch 605, Loss: 166.041626\n",
      "SNR Ratio: 5, Epoch 606, Loss: 135.776459\n",
      "SNR Ratio: 5, Epoch 607, Loss: 165.447601\n",
      "SNR Ratio: 5, Epoch 608, Loss: 144.478500\n",
      "SNR Ratio: 5, Epoch 609, Loss: 146.932617\n",
      "SNR Ratio: 5, Epoch 610, Loss: 131.712097\n",
      "SNR Ratio: 5, Epoch 611, Loss: 147.445755\n",
      "SNR Ratio: 5, Epoch 612, Loss: 141.272537\n",
      "SNR Ratio: 5, Epoch 613, Loss: 146.911285\n",
      "SNR Ratio: 5, Epoch 614, Loss: 150.991592\n",
      "SNR Ratio: 5, Epoch 615, Loss: 151.804703\n",
      "SNR Ratio: 5, Epoch 616, Loss: 139.656174\n",
      "SNR Ratio: 5, Epoch 617, Loss: 138.461990\n",
      "SNR Ratio: 5, Epoch 618, Loss: 144.707031\n",
      "SNR Ratio: 5, Epoch 619, Loss: 145.975235\n",
      "SNR Ratio: 5, Epoch 620, Loss: 143.732758\n",
      "SNR Ratio: 5, Epoch 621, Loss: 127.311989\n",
      "SNR Ratio: 5, Epoch 622, Loss: 134.009995\n",
      "SNR Ratio: 5, Epoch 623, Loss: 144.573822\n",
      "SNR Ratio: 5, Epoch 624, Loss: 157.271591\n",
      "SNR Ratio: 5, Epoch 625, Loss: 138.152740\n",
      "SNR Ratio: 5, Epoch 626, Loss: 136.771027\n",
      "SNR Ratio: 5, Epoch 627, Loss: 154.509476\n",
      "SNR Ratio: 5, Epoch 628, Loss: 150.531769\n",
      "SNR Ratio: 5, Epoch 629, Loss: 143.310257\n",
      "SNR Ratio: 5, Epoch 630, Loss: 142.454346\n",
      "SNR Ratio: 5, Epoch 631, Loss: 150.251617\n",
      "SNR Ratio: 5, Epoch 632, Loss: 135.700974\n",
      "SNR Ratio: 5, Epoch 633, Loss: 148.348038\n",
      "SNR Ratio: 5, Epoch 634, Loss: 131.353439\n",
      "SNR Ratio: 5, Epoch 635, Loss: 143.989853\n",
      "SNR Ratio: 5, Epoch 636, Loss: 154.992691\n",
      "SNR Ratio: 5, Epoch 637, Loss: 141.929901\n",
      "SNR Ratio: 5, Epoch 638, Loss: 134.882233\n",
      "SNR Ratio: 5, Epoch 639, Loss: 143.790054\n",
      "SNR Ratio: 5, Epoch 640, Loss: 134.894226\n",
      "SNR Ratio: 5, Epoch 641, Loss: 136.454163\n",
      "SNR Ratio: 5, Epoch 642, Loss: 139.142838\n",
      "SNR Ratio: 5, Epoch 643, Loss: 147.516876\n",
      "SNR Ratio: 5, Epoch 644, Loss: 140.926895\n",
      "SNR Ratio: 5, Epoch 645, Loss: 144.130661\n",
      "SNR Ratio: 5, Epoch 646, Loss: 145.509933\n",
      "SNR Ratio: 5, Epoch 647, Loss: 132.103561\n",
      "SNR Ratio: 5, Epoch 648, Loss: 135.543304\n",
      "SNR Ratio: 5, Epoch 649, Loss: 137.238617\n",
      "SNR Ratio: 5, Epoch 650, Loss: 150.351334\n",
      "SNR Ratio: 5, Epoch 651, Loss: 131.047821\n",
      "SNR Ratio: 5, Epoch 652, Loss: 127.321381\n",
      "SNR Ratio: 5, Epoch 653, Loss: 132.906097\n",
      "SNR Ratio: 5, Epoch 654, Loss: 138.430283\n",
      "SNR Ratio: 5, Epoch 655, Loss: 139.134567\n",
      "SNR Ratio: 5, Epoch 656, Loss: 137.346298\n",
      "SNR Ratio: 5, Epoch 657, Loss: 140.360214\n",
      "SNR Ratio: 5, Epoch 658, Loss: 136.607285\n",
      "SNR Ratio: 5, Epoch 659, Loss: 144.702927\n",
      "Stopped early after 660 epochs, with loss 125.009064\n",
      "SNR Ratio: 8, Epoch 1, Loss: 327.470734\n",
      "SNR Ratio: 8, Epoch 2, Loss: 324.588409\n",
      "SNR Ratio: 8, Epoch 3, Loss: 326.271637\n",
      "SNR Ratio: 8, Epoch 4, Loss: 307.717712\n",
      "SNR Ratio: 8, Epoch 5, Loss: 289.368073\n",
      "SNR Ratio: 8, Epoch 6, Loss: 273.129028\n",
      "SNR Ratio: 8, Epoch 7, Loss: 251.485184\n",
      "SNR Ratio: 8, Epoch 8, Loss: 254.432693\n",
      "SNR Ratio: 8, Epoch 9, Loss: 238.042694\n",
      "SNR Ratio: 8, Epoch 10, Loss: 225.503876\n",
      "SNR Ratio: 8, Epoch 11, Loss: 219.564316\n",
      "SNR Ratio: 8, Epoch 12, Loss: 211.478043\n",
      "SNR Ratio: 8, Epoch 13, Loss: 207.212173\n",
      "SNR Ratio: 8, Epoch 14, Loss: 198.630081\n",
      "SNR Ratio: 8, Epoch 15, Loss: 195.164719\n",
      "SNR Ratio: 8, Epoch 16, Loss: 198.420822\n",
      "SNR Ratio: 8, Epoch 17, Loss: 189.693573\n",
      "SNR Ratio: 8, Epoch 18, Loss: 177.160233\n",
      "SNR Ratio: 8, Epoch 19, Loss: 190.445358\n",
      "SNR Ratio: 8, Epoch 20, Loss: 186.492905\n",
      "SNR Ratio: 8, Epoch 21, Loss: 181.760284\n",
      "SNR Ratio: 8, Epoch 22, Loss: 178.134445\n",
      "SNR Ratio: 8, Epoch 23, Loss: 184.272522\n",
      "SNR Ratio: 8, Epoch 24, Loss: 179.417557\n",
      "SNR Ratio: 8, Epoch 25, Loss: 166.453033\n",
      "SNR Ratio: 8, Epoch 26, Loss: 182.342026\n",
      "SNR Ratio: 8, Epoch 27, Loss: 173.742004\n",
      "SNR Ratio: 8, Epoch 28, Loss: 170.595596\n",
      "SNR Ratio: 8, Epoch 29, Loss: 180.024796\n",
      "SNR Ratio: 8, Epoch 30, Loss: 171.338318\n",
      "SNR Ratio: 8, Epoch 31, Loss: 171.708176\n",
      "SNR Ratio: 8, Epoch 32, Loss: 168.512161\n",
      "SNR Ratio: 8, Epoch 33, Loss: 167.796143\n",
      "SNR Ratio: 8, Epoch 34, Loss: 169.930405\n",
      "SNR Ratio: 8, Epoch 35, Loss: 163.882294\n",
      "SNR Ratio: 8, Epoch 36, Loss: 166.837479\n",
      "SNR Ratio: 8, Epoch 37, Loss: 158.625656\n",
      "SNR Ratio: 8, Epoch 38, Loss: 155.063629\n",
      "SNR Ratio: 8, Epoch 39, Loss: 150.931335\n",
      "SNR Ratio: 8, Epoch 40, Loss: 161.239227\n",
      "SNR Ratio: 8, Epoch 41, Loss: 154.681396\n",
      "SNR Ratio: 8, Epoch 42, Loss: 166.287384\n",
      "SNR Ratio: 8, Epoch 43, Loss: 157.932343\n",
      "SNR Ratio: 8, Epoch 44, Loss: 156.758957\n",
      "SNR Ratio: 8, Epoch 45, Loss: 156.347626\n",
      "SNR Ratio: 8, Epoch 46, Loss: 149.688919\n",
      "SNR Ratio: 8, Epoch 47, Loss: 147.392441\n",
      "SNR Ratio: 8, Epoch 48, Loss: 139.618607\n",
      "SNR Ratio: 8, Epoch 49, Loss: 150.472183\n",
      "SNR Ratio: 8, Epoch 50, Loss: 151.464706\n",
      "SNR Ratio: 8, Epoch 51, Loss: 146.898544\n",
      "SNR Ratio: 8, Epoch 52, Loss: 145.897583\n",
      "SNR Ratio: 8, Epoch 53, Loss: 152.347076\n",
      "SNR Ratio: 8, Epoch 54, Loss: 162.239456\n",
      "SNR Ratio: 8, Epoch 55, Loss: 148.533417\n",
      "SNR Ratio: 8, Epoch 56, Loss: 151.526215\n",
      "SNR Ratio: 8, Epoch 57, Loss: 150.473450\n",
      "SNR Ratio: 8, Epoch 58, Loss: 147.655777\n",
      "SNR Ratio: 8, Epoch 59, Loss: 146.160751\n",
      "SNR Ratio: 8, Epoch 60, Loss: 139.381775\n",
      "SNR Ratio: 8, Epoch 61, Loss: 153.400757\n",
      "SNR Ratio: 8, Epoch 62, Loss: 147.186401\n",
      "SNR Ratio: 8, Epoch 63, Loss: 155.018005\n",
      "SNR Ratio: 8, Epoch 64, Loss: 133.304535\n",
      "SNR Ratio: 8, Epoch 65, Loss: 135.654938\n",
      "SNR Ratio: 8, Epoch 66, Loss: 144.143524\n",
      "SNR Ratio: 8, Epoch 67, Loss: 147.220261\n",
      "SNR Ratio: 8, Epoch 68, Loss: 142.586807\n",
      "SNR Ratio: 8, Epoch 69, Loss: 138.387375\n",
      "SNR Ratio: 8, Epoch 70, Loss: 144.533951\n",
      "SNR Ratio: 8, Epoch 71, Loss: 134.484344\n",
      "SNR Ratio: 8, Epoch 72, Loss: 142.993698\n",
      "SNR Ratio: 8, Epoch 73, Loss: 148.912018\n",
      "SNR Ratio: 8, Epoch 74, Loss: 134.630280\n",
      "SNR Ratio: 8, Epoch 75, Loss: 136.170135\n",
      "SNR Ratio: 8, Epoch 76, Loss: 142.395584\n",
      "SNR Ratio: 8, Epoch 77, Loss: 149.074600\n",
      "SNR Ratio: 8, Epoch 78, Loss: 135.200455\n",
      "SNR Ratio: 8, Epoch 79, Loss: 133.984756\n",
      "SNR Ratio: 8, Epoch 80, Loss: 139.579819\n",
      "SNR Ratio: 8, Epoch 81, Loss: 140.581833\n",
      "SNR Ratio: 8, Epoch 82, Loss: 135.841248\n",
      "SNR Ratio: 8, Epoch 83, Loss: 136.682724\n",
      "SNR Ratio: 8, Epoch 84, Loss: 139.887039\n",
      "SNR Ratio: 8, Epoch 85, Loss: 136.625854\n",
      "SNR Ratio: 8, Epoch 86, Loss: 133.720993\n",
      "SNR Ratio: 8, Epoch 87, Loss: 135.628036\n",
      "SNR Ratio: 8, Epoch 88, Loss: 137.460709\n",
      "SNR Ratio: 8, Epoch 89, Loss: 136.070404\n",
      "SNR Ratio: 8, Epoch 90, Loss: 136.222534\n",
      "SNR Ratio: 8, Epoch 91, Loss: 138.527893\n",
      "SNR Ratio: 8, Epoch 92, Loss: 134.975983\n",
      "SNR Ratio: 8, Epoch 93, Loss: 128.116486\n",
      "SNR Ratio: 8, Epoch 94, Loss: 130.455978\n",
      "SNR Ratio: 8, Epoch 95, Loss: 132.675766\n",
      "SNR Ratio: 8, Epoch 96, Loss: 125.356621\n",
      "SNR Ratio: 8, Epoch 97, Loss: 127.760323\n",
      "SNR Ratio: 8, Epoch 98, Loss: 131.479691\n",
      "SNR Ratio: 8, Epoch 99, Loss: 125.015678\n",
      "SNR Ratio: 8, Epoch 100, Loss: 137.360657\n",
      "SNR Ratio: 8, Epoch 101, Loss: 127.466599\n",
      "SNR Ratio: 8, Epoch 102, Loss: 129.734619\n",
      "SNR Ratio: 8, Epoch 103, Loss: 130.957718\n",
      "SNR Ratio: 8, Epoch 104, Loss: 133.396744\n",
      "SNR Ratio: 8, Epoch 105, Loss: 129.357834\n",
      "SNR Ratio: 8, Epoch 106, Loss: 129.559586\n",
      "SNR Ratio: 8, Epoch 107, Loss: 126.706284\n",
      "SNR Ratio: 8, Epoch 108, Loss: 130.478455\n",
      "SNR Ratio: 8, Epoch 109, Loss: 129.187927\n",
      "SNR Ratio: 8, Epoch 110, Loss: 122.091904\n",
      "SNR Ratio: 8, Epoch 111, Loss: 129.060562\n",
      "SNR Ratio: 8, Epoch 112, Loss: 119.400551\n",
      "SNR Ratio: 8, Epoch 113, Loss: 129.712234\n",
      "SNR Ratio: 8, Epoch 114, Loss: 128.831985\n",
      "SNR Ratio: 8, Epoch 115, Loss: 131.831696\n",
      "SNR Ratio: 8, Epoch 116, Loss: 127.311180\n",
      "SNR Ratio: 8, Epoch 117, Loss: 126.665932\n",
      "SNR Ratio: 8, Epoch 118, Loss: 136.573929\n",
      "SNR Ratio: 8, Epoch 119, Loss: 128.815979\n",
      "SNR Ratio: 8, Epoch 120, Loss: 129.995682\n",
      "SNR Ratio: 8, Epoch 121, Loss: 118.429420\n",
      "SNR Ratio: 8, Epoch 122, Loss: 120.431282\n",
      "SNR Ratio: 8, Epoch 123, Loss: 118.975182\n",
      "SNR Ratio: 8, Epoch 124, Loss: 123.981651\n",
      "SNR Ratio: 8, Epoch 125, Loss: 120.293243\n",
      "SNR Ratio: 8, Epoch 126, Loss: 128.022842\n",
      "SNR Ratio: 8, Epoch 127, Loss: 120.179657\n",
      "SNR Ratio: 8, Epoch 128, Loss: 127.403679\n",
      "SNR Ratio: 8, Epoch 129, Loss: 112.887558\n",
      "SNR Ratio: 8, Epoch 130, Loss: 120.469238\n",
      "SNR Ratio: 8, Epoch 131, Loss: 133.127396\n",
      "SNR Ratio: 8, Epoch 132, Loss: 117.189087\n",
      "SNR Ratio: 8, Epoch 133, Loss: 114.822479\n",
      "SNR Ratio: 8, Epoch 134, Loss: 122.857971\n",
      "SNR Ratio: 8, Epoch 135, Loss: 120.378242\n",
      "SNR Ratio: 8, Epoch 136, Loss: 123.263939\n",
      "SNR Ratio: 8, Epoch 137, Loss: 117.954536\n",
      "SNR Ratio: 8, Epoch 138, Loss: 125.793266\n",
      "SNR Ratio: 8, Epoch 139, Loss: 124.604042\n",
      "SNR Ratio: 8, Epoch 140, Loss: 115.083557\n",
      "SNR Ratio: 8, Epoch 141, Loss: 121.069931\n",
      "SNR Ratio: 8, Epoch 142, Loss: 123.226143\n",
      "SNR Ratio: 8, Epoch 143, Loss: 110.867409\n",
      "SNR Ratio: 8, Epoch 144, Loss: 125.353348\n",
      "SNR Ratio: 8, Epoch 145, Loss: 121.175461\n",
      "SNR Ratio: 8, Epoch 146, Loss: 115.654320\n",
      "SNR Ratio: 8, Epoch 147, Loss: 119.793266\n",
      "SNR Ratio: 8, Epoch 148, Loss: 122.584671\n",
      "SNR Ratio: 8, Epoch 149, Loss: 117.162178\n",
      "SNR Ratio: 8, Epoch 150, Loss: 119.048981\n",
      "SNR Ratio: 8, Epoch 151, Loss: 126.389000\n",
      "SNR Ratio: 8, Epoch 152, Loss: 121.042290\n",
      "SNR Ratio: 8, Epoch 153, Loss: 123.089737\n",
      "SNR Ratio: 8, Epoch 154, Loss: 117.231148\n",
      "SNR Ratio: 8, Epoch 155, Loss: 113.549606\n",
      "SNR Ratio: 8, Epoch 156, Loss: 121.692719\n",
      "SNR Ratio: 8, Epoch 157, Loss: 110.697678\n",
      "SNR Ratio: 8, Epoch 158, Loss: 120.276917\n",
      "SNR Ratio: 8, Epoch 159, Loss: 116.668922\n",
      "SNR Ratio: 8, Epoch 160, Loss: 113.773758\n",
      "SNR Ratio: 8, Epoch 161, Loss: 120.004799\n",
      "SNR Ratio: 8, Epoch 162, Loss: 112.189217\n",
      "SNR Ratio: 8, Epoch 163, Loss: 119.084763\n",
      "SNR Ratio: 8, Epoch 164, Loss: 114.068069\n",
      "SNR Ratio: 8, Epoch 165, Loss: 115.495468\n",
      "SNR Ratio: 8, Epoch 166, Loss: 119.870522\n",
      "SNR Ratio: 8, Epoch 167, Loss: 111.027634\n",
      "SNR Ratio: 8, Epoch 168, Loss: 122.270714\n",
      "SNR Ratio: 8, Epoch 169, Loss: 116.908211\n",
      "SNR Ratio: 8, Epoch 170, Loss: 112.547531\n",
      "SNR Ratio: 8, Epoch 171, Loss: 119.533600\n",
      "SNR Ratio: 8, Epoch 172, Loss: 123.010941\n",
      "SNR Ratio: 8, Epoch 173, Loss: 112.544380\n",
      "SNR Ratio: 8, Epoch 174, Loss: 125.399681\n",
      "SNR Ratio: 8, Epoch 175, Loss: 105.135323\n",
      "SNR Ratio: 8, Epoch 176, Loss: 113.453377\n",
      "SNR Ratio: 8, Epoch 177, Loss: 108.848740\n",
      "SNR Ratio: 8, Epoch 178, Loss: 106.250839\n",
      "SNR Ratio: 8, Epoch 179, Loss: 113.745979\n",
      "SNR Ratio: 8, Epoch 180, Loss: 111.331062\n",
      "SNR Ratio: 8, Epoch 181, Loss: 119.782806\n",
      "SNR Ratio: 8, Epoch 182, Loss: 112.755180\n",
      "SNR Ratio: 8, Epoch 183, Loss: 115.219009\n",
      "SNR Ratio: 8, Epoch 184, Loss: 113.124100\n",
      "SNR Ratio: 8, Epoch 185, Loss: 106.314697\n",
      "SNR Ratio: 8, Epoch 186, Loss: 110.533386\n",
      "SNR Ratio: 8, Epoch 187, Loss: 108.762337\n",
      "SNR Ratio: 8, Epoch 188, Loss: 108.757408\n",
      "SNR Ratio: 8, Epoch 189, Loss: 107.431702\n",
      "SNR Ratio: 8, Epoch 190, Loss: 103.936089\n",
      "SNR Ratio: 8, Epoch 191, Loss: 118.316109\n",
      "SNR Ratio: 8, Epoch 192, Loss: 108.790840\n",
      "SNR Ratio: 8, Epoch 193, Loss: 108.103661\n",
      "SNR Ratio: 8, Epoch 194, Loss: 110.280220\n",
      "SNR Ratio: 8, Epoch 195, Loss: 117.081779\n",
      "SNR Ratio: 8, Epoch 196, Loss: 106.069077\n",
      "SNR Ratio: 8, Epoch 197, Loss: 111.735252\n",
      "SNR Ratio: 8, Epoch 198, Loss: 101.549858\n",
      "SNR Ratio: 8, Epoch 199, Loss: 110.959122\n",
      "SNR Ratio: 8, Epoch 200, Loss: 105.281471\n",
      "SNR Ratio: 8, Epoch 201, Loss: 101.742577\n",
      "SNR Ratio: 8, Epoch 202, Loss: 108.086052\n",
      "SNR Ratio: 8, Epoch 203, Loss: 109.096321\n",
      "SNR Ratio: 8, Epoch 204, Loss: 106.770203\n",
      "SNR Ratio: 8, Epoch 205, Loss: 107.587891\n",
      "SNR Ratio: 8, Epoch 206, Loss: 107.219658\n",
      "SNR Ratio: 8, Epoch 207, Loss: 111.621750\n",
      "SNR Ratio: 8, Epoch 208, Loss: 106.382782\n",
      "SNR Ratio: 8, Epoch 209, Loss: 113.177544\n",
      "SNR Ratio: 8, Epoch 210, Loss: 110.379112\n",
      "SNR Ratio: 8, Epoch 211, Loss: 104.629333\n",
      "SNR Ratio: 8, Epoch 212, Loss: 112.461189\n",
      "SNR Ratio: 8, Epoch 213, Loss: 101.837379\n",
      "SNR Ratio: 8, Epoch 214, Loss: 107.516830\n",
      "SNR Ratio: 8, Epoch 215, Loss: 112.272697\n",
      "SNR Ratio: 8, Epoch 216, Loss: 107.013290\n",
      "SNR Ratio: 8, Epoch 217, Loss: 110.055992\n",
      "SNR Ratio: 8, Epoch 218, Loss: 108.057152\n",
      "SNR Ratio: 8, Epoch 219, Loss: 112.044884\n",
      "SNR Ratio: 8, Epoch 220, Loss: 108.502960\n",
      "SNR Ratio: 8, Epoch 221, Loss: 99.938339\n",
      "SNR Ratio: 8, Epoch 222, Loss: 108.031342\n",
      "SNR Ratio: 8, Epoch 223, Loss: 99.650078\n",
      "SNR Ratio: 8, Epoch 224, Loss: 98.679817\n",
      "SNR Ratio: 8, Epoch 225, Loss: 98.567169\n",
      "SNR Ratio: 8, Epoch 226, Loss: 104.700073\n",
      "SNR Ratio: 8, Epoch 227, Loss: 104.540863\n",
      "SNR Ratio: 8, Epoch 228, Loss: 110.903732\n",
      "SNR Ratio: 8, Epoch 229, Loss: 109.326218\n",
      "SNR Ratio: 8, Epoch 230, Loss: 104.417229\n",
      "SNR Ratio: 8, Epoch 231, Loss: 95.058617\n",
      "SNR Ratio: 8, Epoch 232, Loss: 108.311996\n",
      "SNR Ratio: 8, Epoch 233, Loss: 103.851440\n",
      "SNR Ratio: 8, Epoch 234, Loss: 112.964653\n",
      "SNR Ratio: 8, Epoch 235, Loss: 103.279778\n",
      "SNR Ratio: 8, Epoch 236, Loss: 105.421379\n",
      "SNR Ratio: 8, Epoch 237, Loss: 97.978256\n",
      "SNR Ratio: 8, Epoch 238, Loss: 102.852058\n",
      "SNR Ratio: 8, Epoch 239, Loss: 103.624779\n",
      "SNR Ratio: 8, Epoch 240, Loss: 104.024323\n",
      "SNR Ratio: 8, Epoch 241, Loss: 104.665901\n",
      "SNR Ratio: 8, Epoch 242, Loss: 110.145210\n",
      "SNR Ratio: 8, Epoch 243, Loss: 103.043877\n",
      "SNR Ratio: 8, Epoch 244, Loss: 98.162422\n",
      "SNR Ratio: 8, Epoch 245, Loss: 99.593361\n",
      "SNR Ratio: 8, Epoch 246, Loss: 100.944397\n",
      "SNR Ratio: 8, Epoch 247, Loss: 108.381783\n",
      "SNR Ratio: 8, Epoch 248, Loss: 97.490662\n",
      "SNR Ratio: 8, Epoch 249, Loss: 94.950363\n",
      "SNR Ratio: 8, Epoch 250, Loss: 107.649918\n",
      "SNR Ratio: 8, Epoch 251, Loss: 101.234627\n",
      "SNR Ratio: 8, Epoch 252, Loss: 98.343887\n",
      "SNR Ratio: 8, Epoch 253, Loss: 96.980598\n",
      "SNR Ratio: 8, Epoch 254, Loss: 95.576477\n",
      "SNR Ratio: 8, Epoch 255, Loss: 89.974068\n",
      "SNR Ratio: 8, Epoch 256, Loss: 97.698143\n",
      "SNR Ratio: 8, Epoch 257, Loss: 108.438499\n",
      "SNR Ratio: 8, Epoch 258, Loss: 106.246307\n",
      "SNR Ratio: 8, Epoch 259, Loss: 102.640701\n",
      "SNR Ratio: 8, Epoch 260, Loss: 91.209633\n",
      "SNR Ratio: 8, Epoch 261, Loss: 98.055092\n",
      "SNR Ratio: 8, Epoch 262, Loss: 100.822678\n",
      "SNR Ratio: 8, Epoch 263, Loss: 101.917351\n",
      "SNR Ratio: 8, Epoch 264, Loss: 105.022888\n",
      "SNR Ratio: 8, Epoch 265, Loss: 99.052994\n",
      "SNR Ratio: 8, Epoch 266, Loss: 103.649033\n",
      "SNR Ratio: 8, Epoch 267, Loss: 102.228432\n",
      "SNR Ratio: 8, Epoch 268, Loss: 105.351547\n",
      "SNR Ratio: 8, Epoch 269, Loss: 101.037903\n",
      "SNR Ratio: 8, Epoch 270, Loss: 94.163254\n",
      "SNR Ratio: 8, Epoch 271, Loss: 92.711418\n",
      "SNR Ratio: 8, Epoch 272, Loss: 101.460838\n",
      "SNR Ratio: 8, Epoch 273, Loss: 100.603844\n",
      "SNR Ratio: 8, Epoch 274, Loss: 99.767807\n",
      "SNR Ratio: 8, Epoch 275, Loss: 101.277763\n",
      "SNR Ratio: 8, Epoch 276, Loss: 92.678284\n",
      "SNR Ratio: 8, Epoch 277, Loss: 96.896088\n",
      "SNR Ratio: 8, Epoch 278, Loss: 102.006821\n",
      "SNR Ratio: 8, Epoch 279, Loss: 102.205040\n",
      "SNR Ratio: 8, Epoch 280, Loss: 101.791443\n",
      "SNR Ratio: 8, Epoch 281, Loss: 103.380302\n",
      "SNR Ratio: 8, Epoch 282, Loss: 96.817421\n",
      "SNR Ratio: 8, Epoch 283, Loss: 95.054916\n",
      "SNR Ratio: 8, Epoch 284, Loss: 95.376923\n",
      "SNR Ratio: 8, Epoch 285, Loss: 96.442940\n",
      "SNR Ratio: 8, Epoch 286, Loss: 99.915237\n",
      "SNR Ratio: 8, Epoch 287, Loss: 93.639030\n",
      "SNR Ratio: 8, Epoch 288, Loss: 98.389847\n",
      "SNR Ratio: 8, Epoch 289, Loss: 94.642120\n",
      "SNR Ratio: 8, Epoch 290, Loss: 101.876343\n",
      "SNR Ratio: 8, Epoch 291, Loss: 93.285568\n",
      "SNR Ratio: 8, Epoch 292, Loss: 103.011719\n",
      "SNR Ratio: 8, Epoch 293, Loss: 96.276962\n",
      "SNR Ratio: 8, Epoch 294, Loss: 94.930588\n",
      "SNR Ratio: 8, Epoch 295, Loss: 99.139664\n",
      "SNR Ratio: 8, Epoch 296, Loss: 98.042969\n",
      "SNR Ratio: 8, Epoch 297, Loss: 96.034767\n",
      "SNR Ratio: 8, Epoch 298, Loss: 101.393044\n",
      "SNR Ratio: 8, Epoch 299, Loss: 96.940750\n",
      "SNR Ratio: 8, Epoch 300, Loss: 92.662331\n",
      "SNR Ratio: 8, Epoch 301, Loss: 95.561012\n",
      "SNR Ratio: 8, Epoch 302, Loss: 92.536301\n",
      "SNR Ratio: 8, Epoch 303, Loss: 99.025993\n",
      "SNR Ratio: 8, Epoch 304, Loss: 95.267181\n",
      "SNR Ratio: 8, Epoch 305, Loss: 89.430023\n",
      "SNR Ratio: 8, Epoch 306, Loss: 97.535973\n",
      "SNR Ratio: 8, Epoch 307, Loss: 96.468063\n",
      "SNR Ratio: 8, Epoch 308, Loss: 93.250999\n",
      "SNR Ratio: 8, Epoch 309, Loss: 92.879799\n",
      "SNR Ratio: 8, Epoch 310, Loss: 95.346161\n",
      "SNR Ratio: 8, Epoch 311, Loss: 99.666222\n",
      "SNR Ratio: 8, Epoch 312, Loss: 89.444672\n",
      "SNR Ratio: 8, Epoch 313, Loss: 87.454826\n",
      "SNR Ratio: 8, Epoch 314, Loss: 97.423531\n",
      "SNR Ratio: 8, Epoch 315, Loss: 95.662460\n",
      "SNR Ratio: 8, Epoch 316, Loss: 100.124092\n",
      "SNR Ratio: 8, Epoch 317, Loss: 94.547661\n",
      "SNR Ratio: 8, Epoch 318, Loss: 93.702103\n",
      "SNR Ratio: 8, Epoch 319, Loss: 93.264702\n",
      "SNR Ratio: 8, Epoch 320, Loss: 98.339417\n",
      "SNR Ratio: 8, Epoch 321, Loss: 95.129669\n",
      "SNR Ratio: 8, Epoch 322, Loss: 97.346199\n",
      "SNR Ratio: 8, Epoch 323, Loss: 98.981117\n",
      "SNR Ratio: 8, Epoch 324, Loss: 93.202538\n",
      "SNR Ratio: 8, Epoch 325, Loss: 89.006310\n",
      "SNR Ratio: 8, Epoch 326, Loss: 98.993782\n",
      "SNR Ratio: 8, Epoch 327, Loss: 94.899223\n",
      "SNR Ratio: 8, Epoch 328, Loss: 99.347137\n",
      "SNR Ratio: 8, Epoch 329, Loss: 92.901550\n",
      "SNR Ratio: 8, Epoch 330, Loss: 92.137299\n",
      "SNR Ratio: 8, Epoch 331, Loss: 94.659103\n",
      "SNR Ratio: 8, Epoch 332, Loss: 90.374527\n",
      "SNR Ratio: 8, Epoch 333, Loss: 98.863518\n",
      "SNR Ratio: 8, Epoch 334, Loss: 96.794456\n",
      "SNR Ratio: 8, Epoch 335, Loss: 89.040222\n",
      "SNR Ratio: 8, Epoch 336, Loss: 91.871719\n",
      "SNR Ratio: 8, Epoch 337, Loss: 96.260178\n",
      "SNR Ratio: 8, Epoch 338, Loss: 102.885361\n",
      "SNR Ratio: 8, Epoch 339, Loss: 100.378578\n",
      "SNR Ratio: 8, Epoch 340, Loss: 95.771271\n",
      "SNR Ratio: 8, Epoch 341, Loss: 92.936432\n",
      "SNR Ratio: 8, Epoch 342, Loss: 92.691467\n",
      "SNR Ratio: 8, Epoch 343, Loss: 97.407097\n",
      "SNR Ratio: 8, Epoch 344, Loss: 99.085640\n",
      "SNR Ratio: 8, Epoch 345, Loss: 88.927559\n",
      "SNR Ratio: 8, Epoch 346, Loss: 98.065826\n",
      "SNR Ratio: 8, Epoch 347, Loss: 94.775322\n",
      "SNR Ratio: 8, Epoch 348, Loss: 93.538467\n",
      "SNR Ratio: 8, Epoch 349, Loss: 90.542252\n",
      "SNR Ratio: 8, Epoch 350, Loss: 88.979912\n",
      "SNR Ratio: 8, Epoch 351, Loss: 93.358887\n",
      "SNR Ratio: 8, Epoch 352, Loss: 95.843407\n",
      "SNR Ratio: 8, Epoch 353, Loss: 89.274689\n",
      "SNR Ratio: 8, Epoch 354, Loss: 98.905197\n",
      "SNR Ratio: 8, Epoch 355, Loss: 95.256653\n",
      "SNR Ratio: 8, Epoch 356, Loss: 95.310349\n",
      "SNR Ratio: 8, Epoch 357, Loss: 93.600052\n",
      "SNR Ratio: 8, Epoch 358, Loss: 88.984962\n",
      "SNR Ratio: 8, Epoch 359, Loss: 93.830841\n",
      "SNR Ratio: 8, Epoch 360, Loss: 87.658508\n",
      "SNR Ratio: 8, Epoch 361, Loss: 85.641060\n",
      "SNR Ratio: 8, Epoch 362, Loss: 82.189552\n",
      "SNR Ratio: 8, Epoch 363, Loss: 97.356422\n",
      "SNR Ratio: 8, Epoch 364, Loss: 99.673340\n",
      "SNR Ratio: 8, Epoch 365, Loss: 100.177261\n",
      "SNR Ratio: 8, Epoch 366, Loss: 90.473877\n",
      "SNR Ratio: 8, Epoch 367, Loss: 98.243736\n",
      "SNR Ratio: 8, Epoch 368, Loss: 85.898140\n",
      "SNR Ratio: 8, Epoch 369, Loss: 92.456741\n",
      "SNR Ratio: 8, Epoch 370, Loss: 93.637230\n",
      "SNR Ratio: 8, Epoch 371, Loss: 94.212822\n",
      "SNR Ratio: 8, Epoch 372, Loss: 88.529221\n",
      "SNR Ratio: 8, Epoch 373, Loss: 87.870308\n",
      "SNR Ratio: 8, Epoch 374, Loss: 95.399307\n",
      "SNR Ratio: 8, Epoch 375, Loss: 87.344421\n",
      "SNR Ratio: 8, Epoch 376, Loss: 90.143356\n",
      "SNR Ratio: 8, Epoch 377, Loss: 88.067993\n",
      "SNR Ratio: 8, Epoch 378, Loss: 90.881081\n",
      "SNR Ratio: 8, Epoch 379, Loss: 94.155746\n",
      "SNR Ratio: 8, Epoch 380, Loss: 97.297241\n",
      "SNR Ratio: 8, Epoch 381, Loss: 85.748482\n",
      "SNR Ratio: 8, Epoch 382, Loss: 88.071136\n",
      "SNR Ratio: 8, Epoch 383, Loss: 93.117699\n",
      "SNR Ratio: 8, Epoch 384, Loss: 100.699181\n",
      "SNR Ratio: 8, Epoch 385, Loss: 89.145767\n",
      "SNR Ratio: 8, Epoch 386, Loss: 98.029442\n",
      "SNR Ratio: 8, Epoch 387, Loss: 96.693077\n",
      "SNR Ratio: 8, Epoch 388, Loss: 89.089920\n",
      "SNR Ratio: 8, Epoch 389, Loss: 95.029732\n",
      "SNR Ratio: 8, Epoch 390, Loss: 91.826981\n",
      "SNR Ratio: 8, Epoch 391, Loss: 92.913277\n",
      "SNR Ratio: 8, Epoch 392, Loss: 95.641960\n",
      "SNR Ratio: 8, Epoch 393, Loss: 85.919518\n",
      "SNR Ratio: 8, Epoch 394, Loss: 95.402283\n",
      "SNR Ratio: 8, Epoch 395, Loss: 82.734360\n",
      "SNR Ratio: 8, Epoch 396, Loss: 81.166672\n",
      "SNR Ratio: 8, Epoch 397, Loss: 93.241470\n",
      "SNR Ratio: 8, Epoch 398, Loss: 95.397438\n",
      "SNR Ratio: 8, Epoch 399, Loss: 91.182350\n",
      "SNR Ratio: 8, Epoch 400, Loss: 98.666740\n",
      "SNR Ratio: 8, Epoch 401, Loss: 92.931870\n",
      "SNR Ratio: 8, Epoch 402, Loss: 85.308823\n",
      "SNR Ratio: 8, Epoch 403, Loss: 90.206467\n",
      "SNR Ratio: 8, Epoch 404, Loss: 89.094681\n",
      "SNR Ratio: 8, Epoch 405, Loss: 95.552261\n",
      "SNR Ratio: 8, Epoch 406, Loss: 88.523170\n",
      "SNR Ratio: 8, Epoch 407, Loss: 84.435120\n",
      "SNR Ratio: 8, Epoch 408, Loss: 92.443581\n",
      "SNR Ratio: 8, Epoch 409, Loss: 82.280296\n",
      "SNR Ratio: 8, Epoch 410, Loss: 87.093643\n",
      "SNR Ratio: 8, Epoch 411, Loss: 87.689140\n",
      "SNR Ratio: 8, Epoch 412, Loss: 93.971771\n",
      "SNR Ratio: 8, Epoch 413, Loss: 89.536400\n",
      "SNR Ratio: 8, Epoch 414, Loss: 88.257347\n",
      "SNR Ratio: 8, Epoch 415, Loss: 90.177361\n",
      "SNR Ratio: 8, Epoch 416, Loss: 90.870399\n",
      "SNR Ratio: 8, Epoch 417, Loss: 82.392647\n",
      "SNR Ratio: 8, Epoch 418, Loss: 88.911339\n",
      "SNR Ratio: 8, Epoch 419, Loss: 93.642937\n",
      "SNR Ratio: 8, Epoch 420, Loss: 91.165390\n",
      "SNR Ratio: 8, Epoch 421, Loss: 89.758293\n",
      "SNR Ratio: 8, Epoch 422, Loss: 88.140282\n",
      "SNR Ratio: 8, Epoch 423, Loss: 91.863274\n",
      "SNR Ratio: 8, Epoch 424, Loss: 95.171913\n",
      "SNR Ratio: 8, Epoch 425, Loss: 86.457062\n",
      "SNR Ratio: 8, Epoch 426, Loss: 87.978592\n",
      "SNR Ratio: 8, Epoch 427, Loss: 93.329498\n",
      "SNR Ratio: 8, Epoch 428, Loss: 89.696533\n",
      "SNR Ratio: 8, Epoch 429, Loss: 90.008240\n",
      "SNR Ratio: 8, Epoch 430, Loss: 88.956459\n",
      "SNR Ratio: 8, Epoch 431, Loss: 81.400505\n",
      "SNR Ratio: 8, Epoch 432, Loss: 88.230919\n",
      "SNR Ratio: 8, Epoch 433, Loss: 88.405441\n",
      "SNR Ratio: 8, Epoch 434, Loss: 89.281128\n",
      "SNR Ratio: 8, Epoch 435, Loss: 88.476501\n",
      "SNR Ratio: 8, Epoch 436, Loss: 89.186394\n",
      "SNR Ratio: 8, Epoch 437, Loss: 87.198151\n",
      "SNR Ratio: 8, Epoch 438, Loss: 89.567657\n",
      "SNR Ratio: 8, Epoch 439, Loss: 90.216827\n",
      "SNR Ratio: 8, Epoch 440, Loss: 88.116699\n",
      "SNR Ratio: 8, Epoch 441, Loss: 80.017738\n",
      "SNR Ratio: 8, Epoch 442, Loss: 88.611656\n",
      "SNR Ratio: 8, Epoch 443, Loss: 89.070602\n",
      "SNR Ratio: 8, Epoch 444, Loss: 81.882378\n",
      "SNR Ratio: 8, Epoch 445, Loss: 90.935226\n",
      "SNR Ratio: 8, Epoch 446, Loss: 85.312370\n",
      "SNR Ratio: 8, Epoch 447, Loss: 85.709686\n",
      "SNR Ratio: 8, Epoch 448, Loss: 87.927292\n",
      "SNR Ratio: 8, Epoch 449, Loss: 88.507317\n",
      "SNR Ratio: 8, Epoch 450, Loss: 88.926491\n",
      "SNR Ratio: 8, Epoch 451, Loss: 88.241402\n",
      "SNR Ratio: 8, Epoch 452, Loss: 88.721558\n",
      "SNR Ratio: 8, Epoch 453, Loss: 90.967323\n",
      "SNR Ratio: 8, Epoch 454, Loss: 87.491737\n",
      "SNR Ratio: 8, Epoch 455, Loss: 85.879929\n",
      "SNR Ratio: 8, Epoch 456, Loss: 88.960472\n",
      "SNR Ratio: 8, Epoch 457, Loss: 87.336800\n",
      "SNR Ratio: 8, Epoch 458, Loss: 91.958763\n",
      "SNR Ratio: 8, Epoch 459, Loss: 85.156776\n",
      "SNR Ratio: 8, Epoch 460, Loss: 95.236641\n",
      "SNR Ratio: 8, Epoch 461, Loss: 89.558884\n",
      "SNR Ratio: 8, Epoch 462, Loss: 96.760910\n",
      "SNR Ratio: 8, Epoch 463, Loss: 89.401100\n",
      "SNR Ratio: 8, Epoch 464, Loss: 88.875389\n",
      "SNR Ratio: 8, Epoch 465, Loss: 86.171089\n",
      "SNR Ratio: 8, Epoch 466, Loss: 86.595657\n",
      "SNR Ratio: 8, Epoch 467, Loss: 89.380257\n",
      "SNR Ratio: 8, Epoch 468, Loss: 90.036903\n",
      "SNR Ratio: 8, Epoch 469, Loss: 86.858627\n",
      "SNR Ratio: 8, Epoch 470, Loss: 90.865807\n",
      "SNR Ratio: 8, Epoch 471, Loss: 89.212738\n",
      "SNR Ratio: 8, Epoch 472, Loss: 84.169167\n",
      "SNR Ratio: 8, Epoch 473, Loss: 92.130188\n",
      "SNR Ratio: 8, Epoch 474, Loss: 82.290932\n",
      "SNR Ratio: 8, Epoch 475, Loss: 86.153954\n",
      "SNR Ratio: 8, Epoch 476, Loss: 84.952431\n",
      "SNR Ratio: 8, Epoch 477, Loss: 81.681412\n",
      "SNR Ratio: 8, Epoch 478, Loss: 80.075981\n",
      "SNR Ratio: 8, Epoch 479, Loss: 88.015602\n",
      "SNR Ratio: 8, Epoch 480, Loss: 93.622887\n",
      "SNR Ratio: 8, Epoch 481, Loss: 89.957047\n",
      "SNR Ratio: 8, Epoch 482, Loss: 86.847519\n",
      "SNR Ratio: 8, Epoch 483, Loss: 87.997276\n",
      "SNR Ratio: 8, Epoch 484, Loss: 88.860397\n",
      "SNR Ratio: 8, Epoch 485, Loss: 93.187851\n",
      "SNR Ratio: 8, Epoch 486, Loss: 85.601357\n",
      "SNR Ratio: 8, Epoch 487, Loss: 82.440628\n",
      "SNR Ratio: 8, Epoch 488, Loss: 85.524933\n",
      "SNR Ratio: 8, Epoch 489, Loss: 87.956627\n",
      "SNR Ratio: 8, Epoch 490, Loss: 83.267456\n",
      "SNR Ratio: 8, Epoch 491, Loss: 87.547531\n",
      "SNR Ratio: 8, Epoch 492, Loss: 88.588188\n",
      "SNR Ratio: 8, Epoch 493, Loss: 86.243599\n",
      "SNR Ratio: 8, Epoch 494, Loss: 85.433052\n",
      "SNR Ratio: 8, Epoch 495, Loss: 90.365051\n",
      "SNR Ratio: 8, Epoch 496, Loss: 86.152458\n",
      "SNR Ratio: 8, Epoch 497, Loss: 80.891441\n",
      "SNR Ratio: 8, Epoch 498, Loss: 78.986076\n",
      "SNR Ratio: 8, Epoch 499, Loss: 89.620773\n",
      "SNR Ratio: 8, Epoch 500, Loss: 84.103271\n",
      "SNR Ratio: 8, Epoch 501, Loss: 97.398941\n",
      "SNR Ratio: 8, Epoch 502, Loss: 90.982780\n",
      "SNR Ratio: 8, Epoch 503, Loss: 77.509224\n",
      "SNR Ratio: 8, Epoch 504, Loss: 82.054993\n",
      "SNR Ratio: 8, Epoch 505, Loss: 84.916031\n",
      "SNR Ratio: 8, Epoch 506, Loss: 82.107353\n",
      "SNR Ratio: 8, Epoch 507, Loss: 85.876740\n",
      "SNR Ratio: 8, Epoch 508, Loss: 87.096382\n",
      "SNR Ratio: 8, Epoch 509, Loss: 92.095322\n",
      "SNR Ratio: 8, Epoch 510, Loss: 82.038925\n",
      "SNR Ratio: 8, Epoch 511, Loss: 84.904678\n",
      "SNR Ratio: 8, Epoch 512, Loss: 95.373466\n",
      "SNR Ratio: 8, Epoch 513, Loss: 87.045952\n",
      "SNR Ratio: 8, Epoch 514, Loss: 83.765541\n",
      "SNR Ratio: 8, Epoch 515, Loss: 87.554512\n",
      "SNR Ratio: 8, Epoch 516, Loss: 91.223373\n",
      "SNR Ratio: 8, Epoch 517, Loss: 89.352982\n",
      "SNR Ratio: 8, Epoch 518, Loss: 94.760262\n",
      "SNR Ratio: 8, Epoch 519, Loss: 95.215057\n",
      "SNR Ratio: 8, Epoch 520, Loss: 85.635757\n",
      "SNR Ratio: 8, Epoch 521, Loss: 75.777771\n",
      "SNR Ratio: 8, Epoch 522, Loss: 90.932541\n",
      "SNR Ratio: 8, Epoch 523, Loss: 78.755486\n",
      "SNR Ratio: 8, Epoch 524, Loss: 78.884117\n",
      "SNR Ratio: 8, Epoch 525, Loss: 80.591301\n",
      "SNR Ratio: 8, Epoch 526, Loss: 91.424500\n",
      "SNR Ratio: 8, Epoch 527, Loss: 91.147530\n",
      "SNR Ratio: 8, Epoch 528, Loss: 88.946426\n",
      "SNR Ratio: 8, Epoch 529, Loss: 91.706917\n",
      "SNR Ratio: 8, Epoch 530, Loss: 84.706970\n",
      "SNR Ratio: 8, Epoch 531, Loss: 85.561653\n",
      "SNR Ratio: 8, Epoch 532, Loss: 84.435387\n",
      "SNR Ratio: 8, Epoch 533, Loss: 90.456650\n",
      "SNR Ratio: 8, Epoch 534, Loss: 83.277077\n",
      "SNR Ratio: 8, Epoch 535, Loss: 78.495506\n",
      "SNR Ratio: 8, Epoch 536, Loss: 90.923637\n",
      "SNR Ratio: 8, Epoch 537, Loss: 89.258820\n",
      "SNR Ratio: 8, Epoch 538, Loss: 82.568176\n",
      "SNR Ratio: 8, Epoch 539, Loss: 86.906799\n",
      "SNR Ratio: 8, Epoch 540, Loss: 86.744324\n",
      "SNR Ratio: 8, Epoch 541, Loss: 96.133858\n",
      "SNR Ratio: 8, Epoch 542, Loss: 95.286324\n",
      "SNR Ratio: 8, Epoch 543, Loss: 84.262650\n",
      "SNR Ratio: 8, Epoch 544, Loss: 90.523003\n",
      "SNR Ratio: 8, Epoch 545, Loss: 83.540863\n",
      "SNR Ratio: 8, Epoch 546, Loss: 78.436974\n",
      "SNR Ratio: 8, Epoch 547, Loss: 80.367958\n",
      "SNR Ratio: 8, Epoch 548, Loss: 92.399918\n",
      "SNR Ratio: 8, Epoch 549, Loss: 77.523956\n",
      "SNR Ratio: 8, Epoch 550, Loss: 86.117401\n",
      "SNR Ratio: 8, Epoch 551, Loss: 85.444077\n",
      "SNR Ratio: 8, Epoch 552, Loss: 90.136261\n",
      "SNR Ratio: 8, Epoch 553, Loss: 83.383018\n",
      "SNR Ratio: 8, Epoch 554, Loss: 81.748482\n",
      "SNR Ratio: 8, Epoch 555, Loss: 78.887199\n",
      "SNR Ratio: 8, Epoch 556, Loss: 78.658791\n",
      "SNR Ratio: 8, Epoch 557, Loss: 87.134697\n",
      "SNR Ratio: 8, Epoch 558, Loss: 81.044563\n",
      "SNR Ratio: 8, Epoch 559, Loss: 89.164001\n",
      "SNR Ratio: 8, Epoch 560, Loss: 80.931419\n",
      "SNR Ratio: 8, Epoch 561, Loss: 85.499062\n",
      "SNR Ratio: 8, Epoch 562, Loss: 91.842682\n",
      "SNR Ratio: 8, Epoch 563, Loss: 81.400330\n",
      "SNR Ratio: 8, Epoch 564, Loss: 82.272697\n",
      "SNR Ratio: 8, Epoch 565, Loss: 85.730827\n",
      "SNR Ratio: 8, Epoch 566, Loss: 82.860153\n",
      "SNR Ratio: 8, Epoch 567, Loss: 73.254517\n",
      "SNR Ratio: 8, Epoch 568, Loss: 82.678497\n",
      "SNR Ratio: 8, Epoch 569, Loss: 86.100037\n",
      "SNR Ratio: 8, Epoch 570, Loss: 95.019218\n",
      "SNR Ratio: 8, Epoch 571, Loss: 85.574013\n",
      "SNR Ratio: 8, Epoch 572, Loss: 83.383087\n",
      "SNR Ratio: 8, Epoch 573, Loss: 75.421097\n",
      "SNR Ratio: 8, Epoch 574, Loss: 82.330070\n",
      "SNR Ratio: 8, Epoch 575, Loss: 83.844360\n",
      "SNR Ratio: 8, Epoch 576, Loss: 85.918877\n",
      "SNR Ratio: 8, Epoch 577, Loss: 93.037018\n",
      "SNR Ratio: 8, Epoch 578, Loss: 81.921951\n",
      "SNR Ratio: 8, Epoch 579, Loss: 91.510536\n",
      "SNR Ratio: 8, Epoch 580, Loss: 79.967743\n",
      "SNR Ratio: 8, Epoch 581, Loss: 88.291878\n",
      "SNR Ratio: 8, Epoch 582, Loss: 82.794792\n",
      "SNR Ratio: 8, Epoch 583, Loss: 78.547272\n",
      "SNR Ratio: 8, Epoch 584, Loss: 86.970490\n",
      "SNR Ratio: 8, Epoch 585, Loss: 91.152679\n",
      "SNR Ratio: 8, Epoch 586, Loss: 80.283836\n",
      "SNR Ratio: 8, Epoch 587, Loss: 85.373833\n",
      "SNR Ratio: 8, Epoch 588, Loss: 81.664619\n",
      "SNR Ratio: 8, Epoch 589, Loss: 84.158607\n",
      "SNR Ratio: 8, Epoch 590, Loss: 91.695389\n",
      "SNR Ratio: 8, Epoch 591, Loss: 81.104149\n",
      "SNR Ratio: 8, Epoch 592, Loss: 82.725853\n",
      "SNR Ratio: 8, Epoch 593, Loss: 93.737450\n",
      "SNR Ratio: 8, Epoch 594, Loss: 85.453140\n",
      "SNR Ratio: 8, Epoch 595, Loss: 81.197403\n",
      "SNR Ratio: 8, Epoch 596, Loss: 89.443077\n",
      "SNR Ratio: 8, Epoch 597, Loss: 84.162529\n",
      "SNR Ratio: 8, Epoch 598, Loss: 82.863647\n",
      "SNR Ratio: 8, Epoch 599, Loss: 84.997520\n",
      "SNR Ratio: 8, Epoch 600, Loss: 81.723946\n",
      "SNR Ratio: 8, Epoch 601, Loss: 85.463966\n",
      "SNR Ratio: 8, Epoch 602, Loss: 87.195518\n",
      "SNR Ratio: 8, Epoch 603, Loss: 82.246803\n",
      "SNR Ratio: 8, Epoch 604, Loss: 89.153229\n",
      "SNR Ratio: 8, Epoch 605, Loss: 85.629692\n",
      "SNR Ratio: 8, Epoch 606, Loss: 84.014320\n",
      "SNR Ratio: 8, Epoch 607, Loss: 82.744949\n",
      "SNR Ratio: 8, Epoch 608, Loss: 87.716202\n",
      "SNR Ratio: 8, Epoch 609, Loss: 85.519241\n",
      "SNR Ratio: 8, Epoch 610, Loss: 81.311737\n",
      "SNR Ratio: 8, Epoch 611, Loss: 79.953094\n",
      "SNR Ratio: 8, Epoch 612, Loss: 75.386879\n",
      "SNR Ratio: 8, Epoch 613, Loss: 84.809219\n",
      "SNR Ratio: 8, Epoch 614, Loss: 88.224831\n",
      "SNR Ratio: 8, Epoch 615, Loss: 89.690613\n",
      "SNR Ratio: 8, Epoch 616, Loss: 80.201683\n",
      "SNR Ratio: 8, Epoch 617, Loss: 91.721329\n",
      "SNR Ratio: 8, Epoch 618, Loss: 90.772308\n",
      "SNR Ratio: 8, Epoch 619, Loss: 83.181961\n",
      "SNR Ratio: 8, Epoch 620, Loss: 80.094940\n",
      "SNR Ratio: 8, Epoch 621, Loss: 86.914726\n",
      "SNR Ratio: 8, Epoch 622, Loss: 88.972267\n",
      "SNR Ratio: 8, Epoch 623, Loss: 82.725838\n",
      "SNR Ratio: 8, Epoch 624, Loss: 86.513588\n",
      "SNR Ratio: 8, Epoch 625, Loss: 87.153091\n",
      "SNR Ratio: 8, Epoch 626, Loss: 80.971321\n",
      "SNR Ratio: 8, Epoch 627, Loss: 79.960281\n",
      "SNR Ratio: 8, Epoch 628, Loss: 85.311310\n",
      "SNR Ratio: 8, Epoch 629, Loss: 81.408783\n",
      "SNR Ratio: 8, Epoch 630, Loss: 79.377258\n",
      "SNR Ratio: 8, Epoch 631, Loss: 81.713058\n",
      "SNR Ratio: 8, Epoch 632, Loss: 83.952042\n",
      "SNR Ratio: 8, Epoch 633, Loss: 81.066093\n",
      "SNR Ratio: 8, Epoch 634, Loss: 81.719749\n",
      "SNR Ratio: 8, Epoch 635, Loss: 80.178902\n",
      "SNR Ratio: 8, Epoch 636, Loss: 84.982719\n",
      "SNR Ratio: 8, Epoch 637, Loss: 89.792770\n",
      "SNR Ratio: 8, Epoch 638, Loss: 75.450188\n",
      "SNR Ratio: 8, Epoch 639, Loss: 82.231194\n",
      "SNR Ratio: 8, Epoch 640, Loss: 80.324814\n",
      "SNR Ratio: 8, Epoch 641, Loss: 88.190002\n",
      "SNR Ratio: 8, Epoch 642, Loss: 85.102058\n",
      "SNR Ratio: 8, Epoch 643, Loss: 83.634842\n",
      "SNR Ratio: 8, Epoch 644, Loss: 82.927422\n",
      "SNR Ratio: 8, Epoch 645, Loss: 83.193497\n",
      "SNR Ratio: 8, Epoch 646, Loss: 74.756958\n",
      "SNR Ratio: 8, Epoch 647, Loss: 84.267372\n",
      "SNR Ratio: 8, Epoch 648, Loss: 82.498192\n",
      "SNR Ratio: 8, Epoch 649, Loss: 80.424942\n",
      "SNR Ratio: 8, Epoch 650, Loss: 85.847397\n",
      "SNR Ratio: 8, Epoch 651, Loss: 86.023552\n",
      "SNR Ratio: 8, Epoch 652, Loss: 76.673820\n",
      "SNR Ratio: 8, Epoch 653, Loss: 85.947319\n",
      "SNR Ratio: 8, Epoch 654, Loss: 81.073708\n",
      "SNR Ratio: 8, Epoch 655, Loss: 87.277390\n",
      "SNR Ratio: 8, Epoch 656, Loss: 77.959534\n",
      "SNR Ratio: 8, Epoch 657, Loss: 80.956253\n",
      "SNR Ratio: 8, Epoch 658, Loss: 87.481903\n",
      "SNR Ratio: 8, Epoch 659, Loss: 74.492363\n",
      "SNR Ratio: 8, Epoch 660, Loss: 77.941406\n",
      "SNR Ratio: 8, Epoch 661, Loss: 80.583481\n",
      "SNR Ratio: 8, Epoch 662, Loss: 79.494057\n",
      "SNR Ratio: 8, Epoch 663, Loss: 85.802971\n",
      "SNR Ratio: 8, Epoch 664, Loss: 81.228439\n",
      "SNR Ratio: 8, Epoch 665, Loss: 84.153709\n",
      "SNR Ratio: 8, Epoch 666, Loss: 82.826591\n",
      "SNR Ratio: 8, Epoch 667, Loss: 83.763672\n",
      "Stopped early after 668 epochs, with loss 73.254517\n",
      "SNR Ratio: 11, Epoch 1, Loss: 340.334961\n",
      "SNR Ratio: 11, Epoch 2, Loss: 321.096313\n",
      "SNR Ratio: 11, Epoch 3, Loss: 311.452118\n",
      "SNR Ratio: 11, Epoch 4, Loss: 283.962341\n",
      "SNR Ratio: 11, Epoch 5, Loss: 265.522369\n",
      "SNR Ratio: 11, Epoch 6, Loss: 240.784027\n",
      "SNR Ratio: 11, Epoch 7, Loss: 213.802063\n",
      "SNR Ratio: 11, Epoch 8, Loss: 205.498459\n",
      "SNR Ratio: 11, Epoch 9, Loss: 189.651886\n",
      "SNR Ratio: 11, Epoch 10, Loss: 183.540314\n",
      "SNR Ratio: 11, Epoch 11, Loss: 178.000458\n",
      "SNR Ratio: 11, Epoch 12, Loss: 169.675095\n",
      "SNR Ratio: 11, Epoch 13, Loss: 168.440018\n",
      "SNR Ratio: 11, Epoch 14, Loss: 161.896103\n",
      "SNR Ratio: 11, Epoch 15, Loss: 160.725647\n",
      "SNR Ratio: 11, Epoch 16, Loss: 151.541519\n",
      "SNR Ratio: 11, Epoch 17, Loss: 154.848297\n",
      "SNR Ratio: 11, Epoch 18, Loss: 148.338074\n",
      "SNR Ratio: 11, Epoch 19, Loss: 153.794769\n",
      "SNR Ratio: 11, Epoch 20, Loss: 146.545746\n",
      "SNR Ratio: 11, Epoch 21, Loss: 146.439774\n",
      "SNR Ratio: 11, Epoch 22, Loss: 139.870377\n",
      "SNR Ratio: 11, Epoch 23, Loss: 137.385406\n",
      "SNR Ratio: 11, Epoch 24, Loss: 140.115295\n",
      "SNR Ratio: 11, Epoch 25, Loss: 132.257004\n",
      "SNR Ratio: 11, Epoch 26, Loss: 136.887711\n",
      "SNR Ratio: 11, Epoch 27, Loss: 133.338928\n",
      "SNR Ratio: 11, Epoch 28, Loss: 131.645767\n",
      "SNR Ratio: 11, Epoch 29, Loss: 133.150543\n",
      "SNR Ratio: 11, Epoch 30, Loss: 126.575211\n",
      "SNR Ratio: 11, Epoch 31, Loss: 127.066307\n",
      "SNR Ratio: 11, Epoch 32, Loss: 129.530457\n",
      "SNR Ratio: 11, Epoch 33, Loss: 127.697189\n",
      "SNR Ratio: 11, Epoch 34, Loss: 129.059982\n",
      "SNR Ratio: 11, Epoch 35, Loss: 122.783508\n",
      "SNR Ratio: 11, Epoch 36, Loss: 122.337708\n",
      "SNR Ratio: 11, Epoch 37, Loss: 124.446243\n",
      "SNR Ratio: 11, Epoch 38, Loss: 124.473419\n",
      "SNR Ratio: 11, Epoch 39, Loss: 125.050880\n",
      "SNR Ratio: 11, Epoch 40, Loss: 115.069130\n",
      "SNR Ratio: 11, Epoch 41, Loss: 120.081863\n",
      "SNR Ratio: 11, Epoch 42, Loss: 118.684303\n",
      "SNR Ratio: 11, Epoch 43, Loss: 119.937401\n",
      "SNR Ratio: 11, Epoch 44, Loss: 115.399933\n",
      "SNR Ratio: 11, Epoch 45, Loss: 124.729118\n",
      "SNR Ratio: 11, Epoch 46, Loss: 115.492043\n",
      "SNR Ratio: 11, Epoch 47, Loss: 114.833611\n",
      "SNR Ratio: 11, Epoch 48, Loss: 116.608940\n",
      "SNR Ratio: 11, Epoch 49, Loss: 116.531082\n",
      "SNR Ratio: 11, Epoch 50, Loss: 111.522499\n",
      "SNR Ratio: 11, Epoch 51, Loss: 111.517410\n",
      "SNR Ratio: 11, Epoch 52, Loss: 109.315277\n",
      "SNR Ratio: 11, Epoch 53, Loss: 113.310448\n",
      "SNR Ratio: 11, Epoch 54, Loss: 113.656158\n",
      "SNR Ratio: 11, Epoch 55, Loss: 118.968460\n",
      "SNR Ratio: 11, Epoch 56, Loss: 110.345222\n",
      "SNR Ratio: 11, Epoch 57, Loss: 109.219902\n",
      "SNR Ratio: 11, Epoch 58, Loss: 112.680969\n",
      "SNR Ratio: 11, Epoch 59, Loss: 109.375549\n",
      "SNR Ratio: 11, Epoch 60, Loss: 107.244278\n",
      "SNR Ratio: 11, Epoch 61, Loss: 106.080032\n",
      "SNR Ratio: 11, Epoch 62, Loss: 111.276497\n",
      "SNR Ratio: 11, Epoch 63, Loss: 107.643044\n",
      "SNR Ratio: 11, Epoch 64, Loss: 108.367264\n",
      "SNR Ratio: 11, Epoch 65, Loss: 107.406960\n",
      "SNR Ratio: 11, Epoch 66, Loss: 102.111511\n",
      "SNR Ratio: 11, Epoch 67, Loss: 108.181023\n",
      "SNR Ratio: 11, Epoch 68, Loss: 107.353691\n",
      "SNR Ratio: 11, Epoch 69, Loss: 108.693611\n",
      "SNR Ratio: 11, Epoch 70, Loss: 106.602882\n",
      "SNR Ratio: 11, Epoch 71, Loss: 108.529099\n",
      "SNR Ratio: 11, Epoch 72, Loss: 108.632584\n",
      "SNR Ratio: 11, Epoch 73, Loss: 104.335037\n",
      "SNR Ratio: 11, Epoch 74, Loss: 111.383636\n",
      "SNR Ratio: 11, Epoch 75, Loss: 100.334328\n",
      "SNR Ratio: 11, Epoch 76, Loss: 101.087097\n",
      "SNR Ratio: 11, Epoch 77, Loss: 101.147346\n",
      "SNR Ratio: 11, Epoch 78, Loss: 101.621117\n",
      "SNR Ratio: 11, Epoch 79, Loss: 107.539543\n",
      "SNR Ratio: 11, Epoch 80, Loss: 101.946808\n",
      "SNR Ratio: 11, Epoch 81, Loss: 103.429840\n",
      "SNR Ratio: 11, Epoch 82, Loss: 100.679840\n",
      "SNR Ratio: 11, Epoch 83, Loss: 98.636559\n",
      "SNR Ratio: 11, Epoch 84, Loss: 97.594360\n",
      "SNR Ratio: 11, Epoch 85, Loss: 99.084297\n",
      "SNR Ratio: 11, Epoch 86, Loss: 95.695381\n",
      "SNR Ratio: 11, Epoch 87, Loss: 104.217781\n",
      "SNR Ratio: 11, Epoch 88, Loss: 100.292923\n",
      "SNR Ratio: 11, Epoch 89, Loss: 103.789757\n",
      "SNR Ratio: 11, Epoch 90, Loss: 98.635689\n",
      "SNR Ratio: 11, Epoch 91, Loss: 108.379539\n",
      "SNR Ratio: 11, Epoch 92, Loss: 99.075310\n",
      "SNR Ratio: 11, Epoch 93, Loss: 100.126343\n",
      "SNR Ratio: 11, Epoch 94, Loss: 100.798698\n",
      "SNR Ratio: 11, Epoch 95, Loss: 101.109863\n",
      "SNR Ratio: 11, Epoch 96, Loss: 96.940117\n",
      "SNR Ratio: 11, Epoch 97, Loss: 98.461571\n",
      "SNR Ratio: 11, Epoch 98, Loss: 97.952377\n",
      "SNR Ratio: 11, Epoch 99, Loss: 93.215820\n",
      "SNR Ratio: 11, Epoch 100, Loss: 103.492317\n",
      "SNR Ratio: 11, Epoch 101, Loss: 98.652557\n",
      "SNR Ratio: 11, Epoch 102, Loss: 94.958977\n",
      "SNR Ratio: 11, Epoch 103, Loss: 100.517319\n",
      "SNR Ratio: 11, Epoch 104, Loss: 96.064049\n",
      "SNR Ratio: 11, Epoch 105, Loss: 98.229591\n",
      "SNR Ratio: 11, Epoch 106, Loss: 95.892036\n",
      "SNR Ratio: 11, Epoch 107, Loss: 95.844727\n",
      "SNR Ratio: 11, Epoch 108, Loss: 95.272621\n",
      "SNR Ratio: 11, Epoch 109, Loss: 93.776833\n",
      "SNR Ratio: 11, Epoch 110, Loss: 94.329582\n",
      "SNR Ratio: 11, Epoch 111, Loss: 90.140129\n",
      "SNR Ratio: 11, Epoch 112, Loss: 95.222687\n",
      "SNR Ratio: 11, Epoch 113, Loss: 91.273758\n",
      "SNR Ratio: 11, Epoch 114, Loss: 91.292107\n",
      "SNR Ratio: 11, Epoch 115, Loss: 91.355499\n",
      "SNR Ratio: 11, Epoch 116, Loss: 94.279938\n",
      "SNR Ratio: 11, Epoch 117, Loss: 92.980431\n",
      "SNR Ratio: 11, Epoch 118, Loss: 94.711899\n",
      "SNR Ratio: 11, Epoch 119, Loss: 87.139481\n",
      "SNR Ratio: 11, Epoch 120, Loss: 91.882957\n",
      "SNR Ratio: 11, Epoch 121, Loss: 89.543922\n",
      "SNR Ratio: 11, Epoch 122, Loss: 97.992889\n",
      "SNR Ratio: 11, Epoch 123, Loss: 91.152397\n",
      "SNR Ratio: 11, Epoch 124, Loss: 89.696121\n",
      "SNR Ratio: 11, Epoch 125, Loss: 89.359657\n",
      "SNR Ratio: 11, Epoch 126, Loss: 89.212898\n",
      "SNR Ratio: 11, Epoch 127, Loss: 92.374237\n",
      "SNR Ratio: 11, Epoch 128, Loss: 90.958717\n",
      "SNR Ratio: 11, Epoch 129, Loss: 92.724632\n",
      "SNR Ratio: 11, Epoch 130, Loss: 92.341232\n",
      "SNR Ratio: 11, Epoch 131, Loss: 90.236900\n",
      "SNR Ratio: 11, Epoch 132, Loss: 87.634338\n",
      "SNR Ratio: 11, Epoch 133, Loss: 85.425583\n",
      "SNR Ratio: 11, Epoch 134, Loss: 93.160217\n",
      "SNR Ratio: 11, Epoch 135, Loss: 87.628777\n",
      "SNR Ratio: 11, Epoch 136, Loss: 98.708488\n",
      "SNR Ratio: 11, Epoch 137, Loss: 89.952400\n",
      "SNR Ratio: 11, Epoch 138, Loss: 92.032700\n",
      "SNR Ratio: 11, Epoch 139, Loss: 86.938530\n",
      "SNR Ratio: 11, Epoch 140, Loss: 92.114288\n",
      "SNR Ratio: 11, Epoch 141, Loss: 91.637543\n",
      "SNR Ratio: 11, Epoch 142, Loss: 86.909897\n",
      "SNR Ratio: 11, Epoch 143, Loss: 85.350739\n",
      "SNR Ratio: 11, Epoch 144, Loss: 84.830368\n",
      "SNR Ratio: 11, Epoch 145, Loss: 88.374100\n",
      "SNR Ratio: 11, Epoch 146, Loss: 93.027702\n",
      "SNR Ratio: 11, Epoch 147, Loss: 87.468086\n",
      "SNR Ratio: 11, Epoch 148, Loss: 84.463997\n",
      "SNR Ratio: 11, Epoch 149, Loss: 86.943642\n",
      "SNR Ratio: 11, Epoch 150, Loss: 85.623741\n",
      "SNR Ratio: 11, Epoch 151, Loss: 92.199821\n",
      "SNR Ratio: 11, Epoch 152, Loss: 93.335220\n",
      "SNR Ratio: 11, Epoch 153, Loss: 86.205254\n",
      "SNR Ratio: 11, Epoch 154, Loss: 85.694069\n",
      "SNR Ratio: 11, Epoch 155, Loss: 89.708023\n",
      "SNR Ratio: 11, Epoch 156, Loss: 81.596428\n",
      "SNR Ratio: 11, Epoch 157, Loss: 89.606293\n",
      "SNR Ratio: 11, Epoch 158, Loss: 81.872993\n",
      "SNR Ratio: 11, Epoch 159, Loss: 91.190979\n",
      "SNR Ratio: 11, Epoch 160, Loss: 87.395798\n",
      "SNR Ratio: 11, Epoch 161, Loss: 83.166878\n",
      "SNR Ratio: 11, Epoch 162, Loss: 80.843384\n",
      "SNR Ratio: 11, Epoch 163, Loss: 89.626442\n",
      "SNR Ratio: 11, Epoch 164, Loss: 84.754936\n",
      "SNR Ratio: 11, Epoch 165, Loss: 84.992531\n",
      "SNR Ratio: 11, Epoch 166, Loss: 83.299324\n",
      "SNR Ratio: 11, Epoch 167, Loss: 84.225769\n",
      "SNR Ratio: 11, Epoch 168, Loss: 81.812538\n",
      "SNR Ratio: 11, Epoch 169, Loss: 82.792686\n",
      "SNR Ratio: 11, Epoch 170, Loss: 88.480881\n",
      "SNR Ratio: 11, Epoch 171, Loss: 82.791252\n",
      "SNR Ratio: 11, Epoch 172, Loss: 85.910538\n",
      "SNR Ratio: 11, Epoch 173, Loss: 84.436279\n",
      "SNR Ratio: 11, Epoch 174, Loss: 86.395142\n",
      "SNR Ratio: 11, Epoch 175, Loss: 81.380363\n",
      "SNR Ratio: 11, Epoch 176, Loss: 87.761673\n",
      "SNR Ratio: 11, Epoch 177, Loss: 83.524628\n",
      "SNR Ratio: 11, Epoch 178, Loss: 77.377136\n",
      "SNR Ratio: 11, Epoch 179, Loss: 83.936920\n",
      "SNR Ratio: 11, Epoch 180, Loss: 83.538635\n",
      "SNR Ratio: 11, Epoch 181, Loss: 83.255508\n",
      "SNR Ratio: 11, Epoch 182, Loss: 89.121620\n",
      "SNR Ratio: 11, Epoch 183, Loss: 83.462791\n",
      "SNR Ratio: 11, Epoch 184, Loss: 81.723862\n",
      "SNR Ratio: 11, Epoch 185, Loss: 80.060333\n",
      "SNR Ratio: 11, Epoch 186, Loss: 83.963478\n",
      "SNR Ratio: 11, Epoch 187, Loss: 84.660362\n",
      "SNR Ratio: 11, Epoch 188, Loss: 83.699516\n",
      "SNR Ratio: 11, Epoch 189, Loss: 80.276291\n",
      "SNR Ratio: 11, Epoch 190, Loss: 78.743271\n",
      "SNR Ratio: 11, Epoch 191, Loss: 79.951263\n",
      "SNR Ratio: 11, Epoch 192, Loss: 79.771378\n",
      "SNR Ratio: 11, Epoch 193, Loss: 79.586327\n",
      "SNR Ratio: 11, Epoch 194, Loss: 83.176468\n",
      "SNR Ratio: 11, Epoch 195, Loss: 76.499481\n",
      "SNR Ratio: 11, Epoch 196, Loss: 80.329414\n",
      "SNR Ratio: 11, Epoch 197, Loss: 82.773117\n",
      "SNR Ratio: 11, Epoch 198, Loss: 80.651962\n",
      "SNR Ratio: 11, Epoch 199, Loss: 89.808807\n",
      "SNR Ratio: 11, Epoch 200, Loss: 83.722908\n",
      "SNR Ratio: 11, Epoch 201, Loss: 82.428467\n",
      "SNR Ratio: 11, Epoch 202, Loss: 78.707893\n",
      "SNR Ratio: 11, Epoch 203, Loss: 82.092560\n",
      "SNR Ratio: 11, Epoch 204, Loss: 79.420181\n",
      "SNR Ratio: 11, Epoch 205, Loss: 84.285080\n",
      "SNR Ratio: 11, Epoch 206, Loss: 78.319473\n",
      "SNR Ratio: 11, Epoch 207, Loss: 77.324097\n",
      "SNR Ratio: 11, Epoch 208, Loss: 81.893524\n",
      "SNR Ratio: 11, Epoch 209, Loss: 83.749924\n",
      "SNR Ratio: 11, Epoch 210, Loss: 85.678978\n",
      "SNR Ratio: 11, Epoch 211, Loss: 75.861557\n",
      "SNR Ratio: 11, Epoch 212, Loss: 75.145493\n",
      "SNR Ratio: 11, Epoch 213, Loss: 76.336510\n",
      "SNR Ratio: 11, Epoch 214, Loss: 77.364258\n",
      "SNR Ratio: 11, Epoch 215, Loss: 85.712692\n",
      "SNR Ratio: 11, Epoch 216, Loss: 79.254562\n",
      "SNR Ratio: 11, Epoch 217, Loss: 79.806427\n",
      "SNR Ratio: 11, Epoch 218, Loss: 79.389687\n",
      "SNR Ratio: 11, Epoch 219, Loss: 76.426567\n",
      "SNR Ratio: 11, Epoch 220, Loss: 81.465073\n",
      "SNR Ratio: 11, Epoch 221, Loss: 73.509987\n",
      "SNR Ratio: 11, Epoch 222, Loss: 76.412865\n",
      "SNR Ratio: 11, Epoch 223, Loss: 76.485588\n",
      "SNR Ratio: 11, Epoch 224, Loss: 83.506065\n",
      "SNR Ratio: 11, Epoch 225, Loss: 76.616287\n",
      "SNR Ratio: 11, Epoch 226, Loss: 75.624657\n",
      "SNR Ratio: 11, Epoch 227, Loss: 75.744957\n",
      "SNR Ratio: 11, Epoch 228, Loss: 78.467773\n",
      "SNR Ratio: 11, Epoch 229, Loss: 74.666687\n",
      "SNR Ratio: 11, Epoch 230, Loss: 80.994263\n",
      "SNR Ratio: 11, Epoch 231, Loss: 70.709213\n",
      "SNR Ratio: 11, Epoch 232, Loss: 72.610428\n",
      "SNR Ratio: 11, Epoch 233, Loss: 81.928268\n",
      "SNR Ratio: 11, Epoch 234, Loss: 78.467690\n",
      "SNR Ratio: 11, Epoch 235, Loss: 78.422867\n",
      "SNR Ratio: 11, Epoch 236, Loss: 71.434700\n",
      "SNR Ratio: 11, Epoch 237, Loss: 70.440758\n",
      "SNR Ratio: 11, Epoch 238, Loss: 71.025452\n",
      "SNR Ratio: 11, Epoch 239, Loss: 78.984520\n",
      "SNR Ratio: 11, Epoch 240, Loss: 70.228287\n",
      "SNR Ratio: 11, Epoch 241, Loss: 77.550949\n",
      "SNR Ratio: 11, Epoch 242, Loss: 73.350983\n",
      "SNR Ratio: 11, Epoch 243, Loss: 70.954048\n",
      "SNR Ratio: 11, Epoch 244, Loss: 70.550758\n",
      "SNR Ratio: 11, Epoch 245, Loss: 71.092133\n",
      "SNR Ratio: 11, Epoch 246, Loss: 76.083107\n",
      "SNR Ratio: 11, Epoch 247, Loss: 74.207245\n",
      "SNR Ratio: 11, Epoch 248, Loss: 72.134911\n",
      "SNR Ratio: 11, Epoch 249, Loss: 73.722916\n",
      "SNR Ratio: 11, Epoch 250, Loss: 75.577362\n",
      "SNR Ratio: 11, Epoch 251, Loss: 71.177406\n",
      "SNR Ratio: 11, Epoch 252, Loss: 72.090057\n",
      "SNR Ratio: 11, Epoch 253, Loss: 74.734596\n",
      "SNR Ratio: 11, Epoch 254, Loss: 75.070312\n",
      "SNR Ratio: 11, Epoch 255, Loss: 70.155151\n",
      "SNR Ratio: 11, Epoch 256, Loss: 73.693275\n",
      "SNR Ratio: 11, Epoch 257, Loss: 78.081657\n",
      "SNR Ratio: 11, Epoch 258, Loss: 74.173096\n",
      "SNR Ratio: 11, Epoch 259, Loss: 67.963760\n",
      "SNR Ratio: 11, Epoch 260, Loss: 69.446968\n",
      "SNR Ratio: 11, Epoch 261, Loss: 74.551132\n",
      "SNR Ratio: 11, Epoch 262, Loss: 70.350647\n",
      "SNR Ratio: 11, Epoch 263, Loss: 73.252678\n",
      "SNR Ratio: 11, Epoch 264, Loss: 72.570045\n",
      "SNR Ratio: 11, Epoch 265, Loss: 72.431442\n",
      "SNR Ratio: 11, Epoch 266, Loss: 72.248314\n",
      "SNR Ratio: 11, Epoch 267, Loss: 69.884277\n",
      "SNR Ratio: 11, Epoch 268, Loss: 75.149277\n",
      "SNR Ratio: 11, Epoch 269, Loss: 72.560997\n",
      "SNR Ratio: 11, Epoch 270, Loss: 73.039642\n",
      "SNR Ratio: 11, Epoch 271, Loss: 72.250389\n",
      "SNR Ratio: 11, Epoch 272, Loss: 72.635010\n",
      "SNR Ratio: 11, Epoch 273, Loss: 68.826988\n",
      "SNR Ratio: 11, Epoch 274, Loss: 68.343147\n",
      "SNR Ratio: 11, Epoch 275, Loss: 71.771111\n",
      "SNR Ratio: 11, Epoch 276, Loss: 67.539322\n",
      "SNR Ratio: 11, Epoch 277, Loss: 70.609985\n",
      "SNR Ratio: 11, Epoch 278, Loss: 70.379158\n",
      "SNR Ratio: 11, Epoch 279, Loss: 69.106499\n",
      "SNR Ratio: 11, Epoch 280, Loss: 70.952736\n",
      "SNR Ratio: 11, Epoch 281, Loss: 68.587456\n",
      "SNR Ratio: 11, Epoch 282, Loss: 72.085281\n",
      "SNR Ratio: 11, Epoch 283, Loss: 67.668404\n",
      "SNR Ratio: 11, Epoch 284, Loss: 72.850906\n",
      "SNR Ratio: 11, Epoch 285, Loss: 67.888161\n",
      "SNR Ratio: 11, Epoch 286, Loss: 67.675903\n",
      "SNR Ratio: 11, Epoch 287, Loss: 75.320389\n",
      "SNR Ratio: 11, Epoch 288, Loss: 72.345947\n",
      "SNR Ratio: 11, Epoch 289, Loss: 68.558746\n",
      "SNR Ratio: 11, Epoch 290, Loss: 72.133728\n",
      "SNR Ratio: 11, Epoch 291, Loss: 75.825066\n",
      "SNR Ratio: 11, Epoch 292, Loss: 71.706947\n",
      "SNR Ratio: 11, Epoch 293, Loss: 70.731514\n",
      "SNR Ratio: 11, Epoch 294, Loss: 71.244453\n",
      "SNR Ratio: 11, Epoch 295, Loss: 72.165817\n",
      "SNR Ratio: 11, Epoch 296, Loss: 67.290337\n",
      "SNR Ratio: 11, Epoch 297, Loss: 67.844116\n",
      "SNR Ratio: 11, Epoch 298, Loss: 67.394615\n",
      "SNR Ratio: 11, Epoch 299, Loss: 64.902458\n",
      "SNR Ratio: 11, Epoch 300, Loss: 73.686371\n",
      "SNR Ratio: 11, Epoch 301, Loss: 67.485474\n",
      "SNR Ratio: 11, Epoch 302, Loss: 65.449799\n",
      "SNR Ratio: 11, Epoch 303, Loss: 68.703232\n",
      "SNR Ratio: 11, Epoch 304, Loss: 69.055443\n",
      "SNR Ratio: 11, Epoch 305, Loss: 66.020515\n",
      "SNR Ratio: 11, Epoch 306, Loss: 64.417862\n",
      "SNR Ratio: 11, Epoch 307, Loss: 65.544670\n",
      "SNR Ratio: 11, Epoch 308, Loss: 64.319626\n",
      "SNR Ratio: 11, Epoch 309, Loss: 72.243568\n",
      "SNR Ratio: 11, Epoch 310, Loss: 66.836586\n",
      "SNR Ratio: 11, Epoch 311, Loss: 69.798897\n",
      "SNR Ratio: 11, Epoch 312, Loss: 74.016579\n",
      "SNR Ratio: 11, Epoch 313, Loss: 66.872383\n",
      "SNR Ratio: 11, Epoch 314, Loss: 68.853012\n",
      "SNR Ratio: 11, Epoch 315, Loss: 66.768654\n",
      "SNR Ratio: 11, Epoch 316, Loss: 70.902702\n",
      "SNR Ratio: 11, Epoch 317, Loss: 67.591431\n",
      "SNR Ratio: 11, Epoch 318, Loss: 69.388985\n",
      "SNR Ratio: 11, Epoch 319, Loss: 66.931534\n",
      "SNR Ratio: 11, Epoch 320, Loss: 65.597946\n",
      "SNR Ratio: 11, Epoch 321, Loss: 67.745087\n",
      "SNR Ratio: 11, Epoch 322, Loss: 69.789177\n",
      "SNR Ratio: 11, Epoch 323, Loss: 67.705032\n",
      "SNR Ratio: 11, Epoch 324, Loss: 67.149567\n",
      "SNR Ratio: 11, Epoch 325, Loss: 66.588623\n",
      "SNR Ratio: 11, Epoch 326, Loss: 66.052750\n",
      "SNR Ratio: 11, Epoch 327, Loss: 65.878090\n",
      "SNR Ratio: 11, Epoch 328, Loss: 67.306892\n",
      "SNR Ratio: 11, Epoch 329, Loss: 66.252655\n",
      "SNR Ratio: 11, Epoch 330, Loss: 65.473824\n",
      "SNR Ratio: 11, Epoch 331, Loss: 64.145370\n",
      "SNR Ratio: 11, Epoch 332, Loss: 68.978310\n",
      "SNR Ratio: 11, Epoch 333, Loss: 65.663284\n",
      "SNR Ratio: 11, Epoch 334, Loss: 68.271744\n",
      "SNR Ratio: 11, Epoch 335, Loss: 69.251389\n",
      "SNR Ratio: 11, Epoch 336, Loss: 63.627209\n",
      "SNR Ratio: 11, Epoch 337, Loss: 65.263214\n",
      "SNR Ratio: 11, Epoch 338, Loss: 67.789810\n",
      "SNR Ratio: 11, Epoch 339, Loss: 68.184212\n",
      "SNR Ratio: 11, Epoch 340, Loss: 68.671783\n",
      "SNR Ratio: 11, Epoch 341, Loss: 64.971703\n",
      "SNR Ratio: 11, Epoch 342, Loss: 65.955559\n",
      "SNR Ratio: 11, Epoch 343, Loss: 64.854034\n",
      "SNR Ratio: 11, Epoch 344, Loss: 67.383522\n",
      "SNR Ratio: 11, Epoch 345, Loss: 66.131996\n",
      "SNR Ratio: 11, Epoch 346, Loss: 64.314880\n",
      "SNR Ratio: 11, Epoch 347, Loss: 68.292389\n",
      "SNR Ratio: 11, Epoch 348, Loss: 63.544830\n",
      "SNR Ratio: 11, Epoch 349, Loss: 65.216698\n",
      "SNR Ratio: 11, Epoch 350, Loss: 65.746117\n",
      "SNR Ratio: 11, Epoch 351, Loss: 67.974731\n",
      "SNR Ratio: 11, Epoch 352, Loss: 66.394753\n",
      "SNR Ratio: 11, Epoch 353, Loss: 64.199867\n",
      "SNR Ratio: 11, Epoch 354, Loss: 69.509285\n",
      "SNR Ratio: 11, Epoch 355, Loss: 64.061928\n",
      "SNR Ratio: 11, Epoch 356, Loss: 64.492867\n",
      "SNR Ratio: 11, Epoch 357, Loss: 65.813454\n",
      "SNR Ratio: 11, Epoch 358, Loss: 68.040581\n",
      "SNR Ratio: 11, Epoch 359, Loss: 64.782219\n",
      "SNR Ratio: 11, Epoch 360, Loss: 67.915573\n",
      "SNR Ratio: 11, Epoch 361, Loss: 70.739418\n",
      "SNR Ratio: 11, Epoch 362, Loss: 64.981285\n",
      "SNR Ratio: 11, Epoch 363, Loss: 66.551811\n",
      "SNR Ratio: 11, Epoch 364, Loss: 64.009598\n",
      "SNR Ratio: 11, Epoch 365, Loss: 67.952782\n",
      "SNR Ratio: 11, Epoch 366, Loss: 62.506130\n",
      "SNR Ratio: 11, Epoch 367, Loss: 65.675430\n",
      "SNR Ratio: 11, Epoch 368, Loss: 66.000427\n",
      "SNR Ratio: 11, Epoch 369, Loss: 66.575989\n",
      "SNR Ratio: 11, Epoch 370, Loss: 62.627724\n",
      "SNR Ratio: 11, Epoch 371, Loss: 65.748337\n",
      "SNR Ratio: 11, Epoch 372, Loss: 68.866699\n",
      "SNR Ratio: 11, Epoch 373, Loss: 63.476517\n",
      "SNR Ratio: 11, Epoch 374, Loss: 64.849678\n",
      "SNR Ratio: 11, Epoch 375, Loss: 67.971397\n",
      "SNR Ratio: 11, Epoch 376, Loss: 63.058704\n",
      "SNR Ratio: 11, Epoch 377, Loss: 61.938423\n",
      "SNR Ratio: 11, Epoch 378, Loss: 66.006119\n",
      "SNR Ratio: 11, Epoch 379, Loss: 61.955582\n",
      "SNR Ratio: 11, Epoch 380, Loss: 66.081276\n",
      "SNR Ratio: 11, Epoch 381, Loss: 63.378868\n",
      "SNR Ratio: 11, Epoch 382, Loss: 64.274933\n",
      "SNR Ratio: 11, Epoch 383, Loss: 65.140701\n",
      "SNR Ratio: 11, Epoch 384, Loss: 66.463631\n",
      "SNR Ratio: 11, Epoch 385, Loss: 63.499920\n",
      "SNR Ratio: 11, Epoch 386, Loss: 62.898090\n",
      "SNR Ratio: 11, Epoch 387, Loss: 65.514862\n",
      "SNR Ratio: 11, Epoch 388, Loss: 62.195004\n",
      "SNR Ratio: 11, Epoch 389, Loss: 65.262184\n",
      "SNR Ratio: 11, Epoch 390, Loss: 65.099922\n",
      "SNR Ratio: 11, Epoch 391, Loss: 61.700695\n",
      "SNR Ratio: 11, Epoch 392, Loss: 62.707829\n",
      "SNR Ratio: 11, Epoch 393, Loss: 60.585201\n",
      "SNR Ratio: 11, Epoch 394, Loss: 64.044533\n",
      "SNR Ratio: 11, Epoch 395, Loss: 61.772678\n",
      "SNR Ratio: 11, Epoch 396, Loss: 62.130791\n",
      "SNR Ratio: 11, Epoch 397, Loss: 65.565369\n",
      "SNR Ratio: 11, Epoch 398, Loss: 61.716999\n",
      "SNR Ratio: 11, Epoch 399, Loss: 63.553322\n",
      "SNR Ratio: 11, Epoch 400, Loss: 62.371777\n",
      "SNR Ratio: 11, Epoch 401, Loss: 63.511211\n",
      "SNR Ratio: 11, Epoch 402, Loss: 60.275879\n",
      "SNR Ratio: 11, Epoch 403, Loss: 57.623760\n",
      "SNR Ratio: 11, Epoch 404, Loss: 63.495819\n",
      "SNR Ratio: 11, Epoch 405, Loss: 62.282906\n",
      "SNR Ratio: 11, Epoch 406, Loss: 60.077450\n",
      "SNR Ratio: 11, Epoch 407, Loss: 64.487999\n",
      "SNR Ratio: 11, Epoch 408, Loss: 62.669441\n",
      "SNR Ratio: 11, Epoch 409, Loss: 63.013386\n",
      "SNR Ratio: 11, Epoch 410, Loss: 62.642311\n",
      "SNR Ratio: 11, Epoch 411, Loss: 64.263489\n",
      "SNR Ratio: 11, Epoch 412, Loss: 60.359413\n",
      "SNR Ratio: 11, Epoch 413, Loss: 60.977955\n",
      "SNR Ratio: 11, Epoch 414, Loss: 57.953838\n",
      "SNR Ratio: 11, Epoch 415, Loss: 63.116940\n",
      "SNR Ratio: 11, Epoch 416, Loss: 60.184952\n",
      "SNR Ratio: 11, Epoch 417, Loss: 60.760029\n",
      "SNR Ratio: 11, Epoch 418, Loss: 60.347370\n",
      "SNR Ratio: 11, Epoch 419, Loss: 59.574940\n",
      "SNR Ratio: 11, Epoch 420, Loss: 60.354069\n",
      "SNR Ratio: 11, Epoch 421, Loss: 64.177078\n",
      "SNR Ratio: 11, Epoch 422, Loss: 60.847111\n",
      "SNR Ratio: 11, Epoch 423, Loss: 59.183575\n",
      "SNR Ratio: 11, Epoch 424, Loss: 59.832180\n",
      "SNR Ratio: 11, Epoch 425, Loss: 59.521801\n",
      "SNR Ratio: 11, Epoch 426, Loss: 65.438507\n",
      "SNR Ratio: 11, Epoch 427, Loss: 62.889339\n",
      "SNR Ratio: 11, Epoch 428, Loss: 63.776421\n",
      "SNR Ratio: 11, Epoch 429, Loss: 62.185104\n",
      "SNR Ratio: 11, Epoch 430, Loss: 58.077206\n",
      "SNR Ratio: 11, Epoch 431, Loss: 54.710201\n",
      "SNR Ratio: 11, Epoch 432, Loss: 59.203529\n",
      "SNR Ratio: 11, Epoch 433, Loss: 63.766300\n",
      "SNR Ratio: 11, Epoch 434, Loss: 60.505123\n",
      "SNR Ratio: 11, Epoch 435, Loss: 60.260731\n",
      "SNR Ratio: 11, Epoch 436, Loss: 59.223370\n",
      "SNR Ratio: 11, Epoch 437, Loss: 62.769524\n",
      "SNR Ratio: 11, Epoch 438, Loss: 55.319080\n",
      "SNR Ratio: 11, Epoch 439, Loss: 64.751122\n",
      "SNR Ratio: 11, Epoch 440, Loss: 60.682892\n",
      "SNR Ratio: 11, Epoch 441, Loss: 64.258987\n",
      "SNR Ratio: 11, Epoch 442, Loss: 59.835949\n",
      "SNR Ratio: 11, Epoch 443, Loss: 65.664108\n",
      "SNR Ratio: 11, Epoch 444, Loss: 60.046516\n",
      "SNR Ratio: 11, Epoch 445, Loss: 60.927528\n",
      "SNR Ratio: 11, Epoch 446, Loss: 58.026264\n",
      "SNR Ratio: 11, Epoch 447, Loss: 56.824650\n",
      "SNR Ratio: 11, Epoch 448, Loss: 59.159695\n",
      "SNR Ratio: 11, Epoch 449, Loss: 62.121208\n",
      "SNR Ratio: 11, Epoch 450, Loss: 62.462074\n",
      "SNR Ratio: 11, Epoch 451, Loss: 57.780235\n",
      "SNR Ratio: 11, Epoch 452, Loss: 58.023979\n",
      "SNR Ratio: 11, Epoch 453, Loss: 60.746948\n",
      "SNR Ratio: 11, Epoch 454, Loss: 60.111591\n",
      "SNR Ratio: 11, Epoch 455, Loss: 57.239632\n",
      "SNR Ratio: 11, Epoch 456, Loss: 59.186100\n",
      "SNR Ratio: 11, Epoch 457, Loss: 61.332111\n",
      "SNR Ratio: 11, Epoch 458, Loss: 57.901535\n",
      "SNR Ratio: 11, Epoch 459, Loss: 56.140785\n",
      "SNR Ratio: 11, Epoch 460, Loss: 59.374214\n",
      "SNR Ratio: 11, Epoch 461, Loss: 57.598980\n",
      "SNR Ratio: 11, Epoch 462, Loss: 57.011379\n",
      "SNR Ratio: 11, Epoch 463, Loss: 60.657436\n",
      "SNR Ratio: 11, Epoch 464, Loss: 58.692719\n",
      "SNR Ratio: 11, Epoch 465, Loss: 55.033131\n",
      "SNR Ratio: 11, Epoch 466, Loss: 58.583778\n",
      "SNR Ratio: 11, Epoch 467, Loss: 59.226624\n",
      "SNR Ratio: 11, Epoch 468, Loss: 59.176250\n",
      "SNR Ratio: 11, Epoch 469, Loss: 60.039154\n",
      "SNR Ratio: 11, Epoch 470, Loss: 59.209373\n",
      "SNR Ratio: 11, Epoch 471, Loss: 60.019539\n",
      "SNR Ratio: 11, Epoch 472, Loss: 57.445881\n",
      "SNR Ratio: 11, Epoch 473, Loss: 55.298111\n",
      "SNR Ratio: 11, Epoch 474, Loss: 58.828255\n",
      "SNR Ratio: 11, Epoch 475, Loss: 61.661060\n",
      "SNR Ratio: 11, Epoch 476, Loss: 61.187855\n",
      "SNR Ratio: 11, Epoch 477, Loss: 56.770313\n",
      "SNR Ratio: 11, Epoch 478, Loss: 58.416775\n",
      "SNR Ratio: 11, Epoch 479, Loss: 58.844086\n",
      "SNR Ratio: 11, Epoch 480, Loss: 58.325901\n",
      "SNR Ratio: 11, Epoch 481, Loss: 57.367722\n",
      "SNR Ratio: 11, Epoch 482, Loss: 56.646896\n",
      "SNR Ratio: 11, Epoch 483, Loss: 59.590431\n",
      "SNR Ratio: 11, Epoch 484, Loss: 57.906010\n",
      "SNR Ratio: 11, Epoch 485, Loss: 54.283981\n",
      "SNR Ratio: 11, Epoch 486, Loss: 59.274261\n",
      "SNR Ratio: 11, Epoch 487, Loss: 56.145893\n",
      "SNR Ratio: 11, Epoch 488, Loss: 54.776146\n",
      "SNR Ratio: 11, Epoch 489, Loss: 53.414604\n",
      "SNR Ratio: 11, Epoch 490, Loss: 57.717484\n",
      "SNR Ratio: 11, Epoch 491, Loss: 58.220406\n",
      "SNR Ratio: 11, Epoch 492, Loss: 56.395679\n",
      "SNR Ratio: 11, Epoch 493, Loss: 57.718956\n",
      "SNR Ratio: 11, Epoch 494, Loss: 58.313953\n",
      "SNR Ratio: 11, Epoch 495, Loss: 54.901459\n",
      "SNR Ratio: 11, Epoch 496, Loss: 58.834789\n",
      "SNR Ratio: 11, Epoch 497, Loss: 54.830311\n",
      "SNR Ratio: 11, Epoch 498, Loss: 57.864246\n",
      "SNR Ratio: 11, Epoch 499, Loss: 54.811356\n",
      "SNR Ratio: 11, Epoch 500, Loss: 55.839981\n",
      "SNR Ratio: 11, Epoch 501, Loss: 53.622604\n",
      "SNR Ratio: 11, Epoch 502, Loss: 53.140289\n",
      "SNR Ratio: 11, Epoch 503, Loss: 55.232254\n",
      "SNR Ratio: 11, Epoch 504, Loss: 52.099030\n",
      "SNR Ratio: 11, Epoch 505, Loss: 55.814259\n",
      "SNR Ratio: 11, Epoch 506, Loss: 56.065365\n",
      "SNR Ratio: 11, Epoch 507, Loss: 55.061546\n",
      "SNR Ratio: 11, Epoch 508, Loss: 58.178570\n",
      "SNR Ratio: 11, Epoch 509, Loss: 55.877735\n",
      "SNR Ratio: 11, Epoch 510, Loss: 54.404881\n",
      "SNR Ratio: 11, Epoch 511, Loss: 55.317146\n",
      "SNR Ratio: 11, Epoch 512, Loss: 54.526150\n",
      "SNR Ratio: 11, Epoch 513, Loss: 57.202221\n",
      "SNR Ratio: 11, Epoch 514, Loss: 55.030956\n",
      "SNR Ratio: 11, Epoch 515, Loss: 54.520725\n",
      "SNR Ratio: 11, Epoch 516, Loss: 57.753830\n",
      "SNR Ratio: 11, Epoch 517, Loss: 53.376881\n",
      "SNR Ratio: 11, Epoch 518, Loss: 56.983913\n",
      "SNR Ratio: 11, Epoch 519, Loss: 52.644070\n",
      "SNR Ratio: 11, Epoch 520, Loss: 56.451321\n",
      "SNR Ratio: 11, Epoch 521, Loss: 60.285511\n",
      "SNR Ratio: 11, Epoch 522, Loss: 53.093479\n",
      "SNR Ratio: 11, Epoch 523, Loss: 55.759998\n",
      "SNR Ratio: 11, Epoch 524, Loss: 55.423473\n",
      "SNR Ratio: 11, Epoch 525, Loss: 53.522881\n",
      "SNR Ratio: 11, Epoch 526, Loss: 54.860229\n",
      "SNR Ratio: 11, Epoch 527, Loss: 56.130116\n",
      "SNR Ratio: 11, Epoch 528, Loss: 52.034100\n",
      "SNR Ratio: 11, Epoch 529, Loss: 53.296940\n",
      "SNR Ratio: 11, Epoch 530, Loss: 54.625839\n",
      "SNR Ratio: 11, Epoch 531, Loss: 50.589909\n",
      "SNR Ratio: 11, Epoch 532, Loss: 55.735748\n",
      "SNR Ratio: 11, Epoch 533, Loss: 54.682610\n",
      "SNR Ratio: 11, Epoch 534, Loss: 55.619686\n",
      "SNR Ratio: 11, Epoch 535, Loss: 54.647484\n",
      "SNR Ratio: 11, Epoch 536, Loss: 54.212585\n",
      "SNR Ratio: 11, Epoch 537, Loss: 52.868984\n",
      "SNR Ratio: 11, Epoch 538, Loss: 57.281300\n",
      "SNR Ratio: 11, Epoch 539, Loss: 52.525162\n",
      "SNR Ratio: 11, Epoch 540, Loss: 54.205040\n",
      "SNR Ratio: 11, Epoch 541, Loss: 52.733246\n",
      "SNR Ratio: 11, Epoch 542, Loss: 52.308933\n",
      "SNR Ratio: 11, Epoch 543, Loss: 52.129688\n",
      "SNR Ratio: 11, Epoch 544, Loss: 51.947250\n",
      "SNR Ratio: 11, Epoch 545, Loss: 54.856895\n",
      "SNR Ratio: 11, Epoch 546, Loss: 52.925453\n",
      "SNR Ratio: 11, Epoch 547, Loss: 48.983971\n",
      "SNR Ratio: 11, Epoch 548, Loss: 51.147186\n",
      "SNR Ratio: 11, Epoch 549, Loss: 50.038036\n",
      "SNR Ratio: 11, Epoch 550, Loss: 53.291691\n",
      "SNR Ratio: 11, Epoch 551, Loss: 50.762024\n",
      "SNR Ratio: 11, Epoch 552, Loss: 52.768856\n",
      "SNR Ratio: 11, Epoch 553, Loss: 51.863834\n",
      "SNR Ratio: 11, Epoch 554, Loss: 52.119320\n",
      "SNR Ratio: 11, Epoch 555, Loss: 52.226059\n",
      "SNR Ratio: 11, Epoch 556, Loss: 50.742500\n",
      "SNR Ratio: 11, Epoch 557, Loss: 51.094849\n",
      "SNR Ratio: 11, Epoch 558, Loss: 53.105984\n",
      "SNR Ratio: 11, Epoch 559, Loss: 48.361629\n",
      "SNR Ratio: 11, Epoch 560, Loss: 53.868835\n",
      "SNR Ratio: 11, Epoch 561, Loss: 52.896370\n",
      "SNR Ratio: 11, Epoch 562, Loss: 49.788059\n",
      "SNR Ratio: 11, Epoch 563, Loss: 51.299625\n",
      "SNR Ratio: 11, Epoch 564, Loss: 51.891891\n",
      "SNR Ratio: 11, Epoch 565, Loss: 49.149090\n",
      "SNR Ratio: 11, Epoch 566, Loss: 55.131561\n",
      "SNR Ratio: 11, Epoch 567, Loss: 48.948830\n",
      "SNR Ratio: 11, Epoch 568, Loss: 52.652168\n",
      "SNR Ratio: 11, Epoch 569, Loss: 52.974941\n",
      "SNR Ratio: 11, Epoch 570, Loss: 51.617855\n",
      "SNR Ratio: 11, Epoch 571, Loss: 49.535950\n",
      "SNR Ratio: 11, Epoch 572, Loss: 51.722160\n",
      "SNR Ratio: 11, Epoch 573, Loss: 49.856644\n",
      "SNR Ratio: 11, Epoch 574, Loss: 50.211826\n",
      "SNR Ratio: 11, Epoch 575, Loss: 47.828930\n",
      "SNR Ratio: 11, Epoch 576, Loss: 51.379814\n",
      "SNR Ratio: 11, Epoch 577, Loss: 48.220917\n",
      "SNR Ratio: 11, Epoch 578, Loss: 50.495186\n",
      "SNR Ratio: 11, Epoch 579, Loss: 48.856079\n",
      "SNR Ratio: 11, Epoch 580, Loss: 50.137356\n",
      "SNR Ratio: 11, Epoch 581, Loss: 50.161976\n",
      "SNR Ratio: 11, Epoch 582, Loss: 47.382408\n",
      "SNR Ratio: 11, Epoch 583, Loss: 50.838871\n",
      "SNR Ratio: 11, Epoch 584, Loss: 49.105129\n",
      "SNR Ratio: 11, Epoch 585, Loss: 45.323166\n",
      "SNR Ratio: 11, Epoch 586, Loss: 47.409256\n",
      "SNR Ratio: 11, Epoch 587, Loss: 50.351662\n",
      "SNR Ratio: 11, Epoch 588, Loss: 47.471684\n",
      "SNR Ratio: 11, Epoch 589, Loss: 48.793541\n",
      "SNR Ratio: 11, Epoch 590, Loss: 47.457050\n",
      "SNR Ratio: 11, Epoch 591, Loss: 49.030602\n",
      "SNR Ratio: 11, Epoch 592, Loss: 46.058651\n",
      "SNR Ratio: 11, Epoch 593, Loss: 49.416180\n",
      "SNR Ratio: 11, Epoch 594, Loss: 48.461288\n",
      "SNR Ratio: 11, Epoch 595, Loss: 51.303024\n",
      "SNR Ratio: 11, Epoch 596, Loss: 47.397591\n",
      "SNR Ratio: 11, Epoch 597, Loss: 46.358074\n",
      "SNR Ratio: 11, Epoch 598, Loss: 44.777840\n",
      "SNR Ratio: 11, Epoch 599, Loss: 48.074841\n",
      "SNR Ratio: 11, Epoch 600, Loss: 46.937237\n",
      "SNR Ratio: 11, Epoch 601, Loss: 49.744663\n",
      "SNR Ratio: 11, Epoch 602, Loss: 49.967670\n",
      "SNR Ratio: 11, Epoch 603, Loss: 45.601234\n",
      "SNR Ratio: 11, Epoch 604, Loss: 49.852001\n",
      "SNR Ratio: 11, Epoch 605, Loss: 51.758663\n",
      "SNR Ratio: 11, Epoch 606, Loss: 48.127911\n",
      "SNR Ratio: 11, Epoch 607, Loss: 48.152962\n",
      "SNR Ratio: 11, Epoch 608, Loss: 46.464046\n",
      "SNR Ratio: 11, Epoch 609, Loss: 45.806141\n",
      "SNR Ratio: 11, Epoch 610, Loss: 44.388500\n",
      "SNR Ratio: 11, Epoch 611, Loss: 46.583820\n",
      "SNR Ratio: 11, Epoch 612, Loss: 44.903629\n",
      "SNR Ratio: 11, Epoch 613, Loss: 48.103909\n",
      "SNR Ratio: 11, Epoch 614, Loss: 46.901917\n",
      "SNR Ratio: 11, Epoch 615, Loss: 43.361599\n",
      "SNR Ratio: 11, Epoch 616, Loss: 43.994801\n",
      "SNR Ratio: 11, Epoch 617, Loss: 44.811096\n",
      "SNR Ratio: 11, Epoch 618, Loss: 44.753826\n",
      "SNR Ratio: 11, Epoch 619, Loss: 45.715546\n",
      "SNR Ratio: 11, Epoch 620, Loss: 43.537521\n",
      "SNR Ratio: 11, Epoch 621, Loss: 44.274685\n",
      "SNR Ratio: 11, Epoch 622, Loss: 46.449554\n",
      "SNR Ratio: 11, Epoch 623, Loss: 51.395569\n",
      "SNR Ratio: 11, Epoch 624, Loss: 42.345051\n",
      "SNR Ratio: 11, Epoch 625, Loss: 41.671478\n",
      "SNR Ratio: 11, Epoch 626, Loss: 45.484070\n",
      "SNR Ratio: 11, Epoch 627, Loss: 43.747311\n",
      "SNR Ratio: 11, Epoch 628, Loss: 44.424999\n",
      "SNR Ratio: 11, Epoch 629, Loss: 45.961681\n",
      "SNR Ratio: 11, Epoch 630, Loss: 42.627560\n",
      "SNR Ratio: 11, Epoch 631, Loss: 48.251980\n",
      "SNR Ratio: 11, Epoch 632, Loss: 42.605816\n",
      "SNR Ratio: 11, Epoch 633, Loss: 42.881401\n",
      "SNR Ratio: 11, Epoch 634, Loss: 45.291737\n",
      "SNR Ratio: 11, Epoch 635, Loss: 44.141994\n",
      "SNR Ratio: 11, Epoch 636, Loss: 45.721375\n",
      "SNR Ratio: 11, Epoch 637, Loss: 44.983459\n",
      "SNR Ratio: 11, Epoch 638, Loss: 45.671799\n",
      "SNR Ratio: 11, Epoch 639, Loss: 45.902321\n",
      "SNR Ratio: 11, Epoch 640, Loss: 42.593189\n",
      "SNR Ratio: 11, Epoch 641, Loss: 44.473797\n",
      "SNR Ratio: 11, Epoch 642, Loss: 46.840321\n",
      "SNR Ratio: 11, Epoch 643, Loss: 43.980579\n",
      "SNR Ratio: 11, Epoch 644, Loss: 43.739170\n",
      "SNR Ratio: 11, Epoch 645, Loss: 44.056049\n",
      "SNR Ratio: 11, Epoch 646, Loss: 44.817310\n",
      "SNR Ratio: 11, Epoch 647, Loss: 42.093063\n",
      "SNR Ratio: 11, Epoch 648, Loss: 41.553486\n",
      "SNR Ratio: 11, Epoch 649, Loss: 43.222660\n",
      "SNR Ratio: 11, Epoch 650, Loss: 41.609261\n",
      "SNR Ratio: 11, Epoch 651, Loss: 47.843781\n",
      "SNR Ratio: 11, Epoch 652, Loss: 43.953415\n",
      "SNR Ratio: 11, Epoch 653, Loss: 40.561352\n",
      "SNR Ratio: 11, Epoch 654, Loss: 45.360970\n",
      "SNR Ratio: 11, Epoch 655, Loss: 40.926083\n",
      "SNR Ratio: 11, Epoch 656, Loss: 43.096851\n",
      "SNR Ratio: 11, Epoch 657, Loss: 40.672001\n",
      "SNR Ratio: 11, Epoch 658, Loss: 45.263515\n",
      "SNR Ratio: 11, Epoch 659, Loss: 43.028358\n",
      "SNR Ratio: 11, Epoch 660, Loss: 39.932838\n",
      "SNR Ratio: 11, Epoch 661, Loss: 42.701664\n",
      "SNR Ratio: 11, Epoch 662, Loss: 38.867287\n",
      "SNR Ratio: 11, Epoch 663, Loss: 41.086479\n",
      "SNR Ratio: 11, Epoch 664, Loss: 40.721958\n",
      "SNR Ratio: 11, Epoch 665, Loss: 43.931450\n",
      "SNR Ratio: 11, Epoch 666, Loss: 42.070606\n",
      "SNR Ratio: 11, Epoch 667, Loss: 44.763199\n",
      "SNR Ratio: 11, Epoch 668, Loss: 41.993420\n",
      "SNR Ratio: 11, Epoch 669, Loss: 42.355961\n",
      "SNR Ratio: 11, Epoch 670, Loss: 37.363644\n",
      "SNR Ratio: 11, Epoch 671, Loss: 40.082901\n",
      "SNR Ratio: 11, Epoch 672, Loss: 42.478916\n",
      "SNR Ratio: 11, Epoch 673, Loss: 41.403996\n",
      "SNR Ratio: 11, Epoch 674, Loss: 43.558971\n",
      "SNR Ratio: 11, Epoch 675, Loss: 39.212257\n",
      "SNR Ratio: 11, Epoch 676, Loss: 39.636284\n",
      "SNR Ratio: 11, Epoch 677, Loss: 39.711914\n",
      "SNR Ratio: 11, Epoch 678, Loss: 39.437817\n",
      "SNR Ratio: 11, Epoch 679, Loss: 39.919624\n",
      "SNR Ratio: 11, Epoch 680, Loss: 39.918850\n",
      "SNR Ratio: 11, Epoch 681, Loss: 37.889164\n",
      "SNR Ratio: 11, Epoch 682, Loss: 40.832691\n",
      "SNR Ratio: 11, Epoch 683, Loss: 38.797726\n",
      "SNR Ratio: 11, Epoch 684, Loss: 38.601414\n",
      "SNR Ratio: 11, Epoch 685, Loss: 41.113167\n",
      "SNR Ratio: 11, Epoch 686, Loss: 37.894943\n",
      "SNR Ratio: 11, Epoch 687, Loss: 39.763683\n",
      "SNR Ratio: 11, Epoch 688, Loss: 39.252930\n",
      "SNR Ratio: 11, Epoch 689, Loss: 38.676376\n",
      "SNR Ratio: 11, Epoch 690, Loss: 37.206879\n",
      "SNR Ratio: 11, Epoch 691, Loss: 38.939186\n",
      "SNR Ratio: 11, Epoch 692, Loss: 41.351524\n",
      "SNR Ratio: 11, Epoch 693, Loss: 42.014690\n",
      "SNR Ratio: 11, Epoch 694, Loss: 38.136642\n",
      "SNR Ratio: 11, Epoch 695, Loss: 38.222359\n",
      "SNR Ratio: 11, Epoch 696, Loss: 42.340527\n",
      "SNR Ratio: 11, Epoch 697, Loss: 37.178455\n",
      "SNR Ratio: 11, Epoch 698, Loss: 38.558647\n",
      "SNR Ratio: 11, Epoch 699, Loss: 39.289837\n",
      "SNR Ratio: 11, Epoch 700, Loss: 36.945011\n",
      "SNR Ratio: 11, Epoch 701, Loss: 37.998241\n",
      "SNR Ratio: 11, Epoch 702, Loss: 36.101528\n",
      "SNR Ratio: 11, Epoch 703, Loss: 37.575764\n",
      "SNR Ratio: 11, Epoch 704, Loss: 36.493523\n",
      "SNR Ratio: 11, Epoch 705, Loss: 37.412392\n",
      "SNR Ratio: 11, Epoch 706, Loss: 36.764122\n",
      "SNR Ratio: 11, Epoch 707, Loss: 40.447620\n",
      "SNR Ratio: 11, Epoch 708, Loss: 37.317455\n",
      "SNR Ratio: 11, Epoch 709, Loss: 34.610931\n",
      "SNR Ratio: 11, Epoch 710, Loss: 39.586723\n",
      "SNR Ratio: 11, Epoch 711, Loss: 37.528404\n",
      "SNR Ratio: 11, Epoch 712, Loss: 37.235092\n",
      "SNR Ratio: 11, Epoch 713, Loss: 39.637783\n",
      "SNR Ratio: 11, Epoch 714, Loss: 37.722519\n",
      "SNR Ratio: 11, Epoch 715, Loss: 35.115314\n",
      "SNR Ratio: 11, Epoch 716, Loss: 37.673809\n",
      "SNR Ratio: 11, Epoch 717, Loss: 36.380066\n",
      "SNR Ratio: 11, Epoch 718, Loss: 36.327072\n",
      "SNR Ratio: 11, Epoch 719, Loss: 37.407612\n",
      "SNR Ratio: 11, Epoch 720, Loss: 38.047901\n",
      "SNR Ratio: 11, Epoch 721, Loss: 37.163979\n",
      "SNR Ratio: 11, Epoch 722, Loss: 38.309231\n",
      "SNR Ratio: 11, Epoch 723, Loss: 36.874378\n",
      "SNR Ratio: 11, Epoch 724, Loss: 34.773396\n",
      "SNR Ratio: 11, Epoch 725, Loss: 36.977982\n",
      "SNR Ratio: 11, Epoch 726, Loss: 38.264858\n",
      "SNR Ratio: 11, Epoch 727, Loss: 36.801804\n",
      "SNR Ratio: 11, Epoch 728, Loss: 37.364891\n",
      "SNR Ratio: 11, Epoch 729, Loss: 37.670044\n",
      "SNR Ratio: 11, Epoch 730, Loss: 38.294212\n",
      "SNR Ratio: 11, Epoch 731, Loss: 34.700241\n",
      "SNR Ratio: 11, Epoch 732, Loss: 33.015255\n",
      "SNR Ratio: 11, Epoch 733, Loss: 36.587620\n",
      "SNR Ratio: 11, Epoch 734, Loss: 38.751556\n",
      "SNR Ratio: 11, Epoch 735, Loss: 37.228992\n",
      "SNR Ratio: 11, Epoch 736, Loss: 36.366783\n",
      "SNR Ratio: 11, Epoch 737, Loss: 34.465946\n",
      "SNR Ratio: 11, Epoch 738, Loss: 38.168522\n",
      "SNR Ratio: 11, Epoch 739, Loss: 32.500816\n",
      "SNR Ratio: 11, Epoch 740, Loss: 38.034908\n",
      "SNR Ratio: 11, Epoch 741, Loss: 36.861366\n",
      "SNR Ratio: 11, Epoch 742, Loss: 35.020218\n",
      "SNR Ratio: 11, Epoch 743, Loss: 37.171902\n",
      "SNR Ratio: 11, Epoch 744, Loss: 34.988441\n",
      "SNR Ratio: 11, Epoch 745, Loss: 36.673466\n",
      "SNR Ratio: 11, Epoch 746, Loss: 34.229034\n",
      "SNR Ratio: 11, Epoch 747, Loss: 36.601429\n",
      "SNR Ratio: 11, Epoch 748, Loss: 34.745941\n",
      "SNR Ratio: 11, Epoch 749, Loss: 33.550533\n",
      "SNR Ratio: 11, Epoch 750, Loss: 36.492668\n",
      "SNR Ratio: 11, Epoch 751, Loss: 34.964828\n",
      "SNR Ratio: 11, Epoch 752, Loss: 36.763077\n",
      "SNR Ratio: 11, Epoch 753, Loss: 35.611835\n",
      "SNR Ratio: 11, Epoch 754, Loss: 32.346432\n",
      "SNR Ratio: 11, Epoch 755, Loss: 33.686165\n",
      "SNR Ratio: 11, Epoch 756, Loss: 33.860119\n",
      "SNR Ratio: 11, Epoch 757, Loss: 35.061298\n",
      "SNR Ratio: 11, Epoch 758, Loss: 33.694618\n",
      "SNR Ratio: 11, Epoch 759, Loss: 33.278282\n",
      "SNR Ratio: 11, Epoch 760, Loss: 35.582668\n",
      "SNR Ratio: 11, Epoch 761, Loss: 35.910786\n",
      "SNR Ratio: 11, Epoch 762, Loss: 36.714314\n",
      "SNR Ratio: 11, Epoch 763, Loss: 35.348980\n",
      "SNR Ratio: 11, Epoch 764, Loss: 31.667311\n",
      "SNR Ratio: 11, Epoch 765, Loss: 34.527287\n",
      "SNR Ratio: 11, Epoch 766, Loss: 35.926838\n",
      "SNR Ratio: 11, Epoch 767, Loss: 36.450771\n",
      "SNR Ratio: 11, Epoch 768, Loss: 34.300434\n",
      "SNR Ratio: 11, Epoch 769, Loss: 37.837280\n",
      "SNR Ratio: 11, Epoch 770, Loss: 37.218777\n",
      "SNR Ratio: 11, Epoch 771, Loss: 35.017960\n",
      "SNR Ratio: 11, Epoch 772, Loss: 33.228584\n",
      "SNR Ratio: 11, Epoch 773, Loss: 33.471035\n",
      "SNR Ratio: 11, Epoch 774, Loss: 35.989994\n",
      "SNR Ratio: 11, Epoch 775, Loss: 32.077839\n",
      "SNR Ratio: 11, Epoch 776, Loss: 36.538883\n",
      "SNR Ratio: 11, Epoch 777, Loss: 32.165642\n",
      "SNR Ratio: 11, Epoch 778, Loss: 31.280165\n",
      "SNR Ratio: 11, Epoch 779, Loss: 35.454857\n",
      "SNR Ratio: 11, Epoch 780, Loss: 33.229053\n",
      "SNR Ratio: 11, Epoch 781, Loss: 34.291088\n",
      "SNR Ratio: 11, Epoch 782, Loss: 32.431839\n",
      "SNR Ratio: 11, Epoch 783, Loss: 38.003464\n",
      "SNR Ratio: 11, Epoch 784, Loss: 31.966040\n",
      "SNR Ratio: 11, Epoch 785, Loss: 33.168716\n",
      "SNR Ratio: 11, Epoch 786, Loss: 31.637890\n",
      "SNR Ratio: 11, Epoch 787, Loss: 37.483799\n",
      "SNR Ratio: 11, Epoch 788, Loss: 36.321136\n",
      "SNR Ratio: 11, Epoch 789, Loss: 33.255936\n",
      "SNR Ratio: 11, Epoch 790, Loss: 33.938992\n",
      "SNR Ratio: 11, Epoch 791, Loss: 35.342403\n",
      "SNR Ratio: 11, Epoch 792, Loss: 34.321041\n",
      "SNR Ratio: 11, Epoch 793, Loss: 34.340721\n",
      "SNR Ratio: 11, Epoch 794, Loss: 36.113514\n",
      "SNR Ratio: 11, Epoch 795, Loss: 33.258171\n",
      "SNR Ratio: 11, Epoch 796, Loss: 32.265030\n",
      "SNR Ratio: 11, Epoch 797, Loss: 34.550926\n",
      "SNR Ratio: 11, Epoch 798, Loss: 36.295094\n",
      "SNR Ratio: 11, Epoch 799, Loss: 30.852840\n",
      "SNR Ratio: 11, Epoch 800, Loss: 32.361115\n",
      "SNR Ratio: 11, Epoch 801, Loss: 32.670021\n",
      "SNR Ratio: 11, Epoch 802, Loss: 33.137520\n",
      "SNR Ratio: 11, Epoch 803, Loss: 35.109043\n",
      "SNR Ratio: 11, Epoch 804, Loss: 32.665516\n",
      "SNR Ratio: 11, Epoch 805, Loss: 30.108042\n",
      "SNR Ratio: 11, Epoch 806, Loss: 32.202423\n",
      "SNR Ratio: 11, Epoch 807, Loss: 34.163204\n",
      "SNR Ratio: 11, Epoch 808, Loss: 33.577042\n",
      "SNR Ratio: 11, Epoch 809, Loss: 34.474812\n",
      "SNR Ratio: 11, Epoch 810, Loss: 36.635300\n",
      "SNR Ratio: 11, Epoch 811, Loss: 33.157372\n",
      "SNR Ratio: 11, Epoch 812, Loss: 30.040537\n",
      "SNR Ratio: 11, Epoch 813, Loss: 32.856171\n",
      "SNR Ratio: 11, Epoch 814, Loss: 28.796860\n",
      "SNR Ratio: 11, Epoch 815, Loss: 32.498711\n",
      "SNR Ratio: 11, Epoch 816, Loss: 30.915106\n",
      "SNR Ratio: 11, Epoch 817, Loss: 32.903484\n",
      "SNR Ratio: 11, Epoch 818, Loss: 30.918518\n",
      "SNR Ratio: 11, Epoch 819, Loss: 33.952953\n",
      "SNR Ratio: 11, Epoch 820, Loss: 30.109043\n",
      "SNR Ratio: 11, Epoch 821, Loss: 35.253815\n",
      "SNR Ratio: 11, Epoch 822, Loss: 30.647463\n",
      "SNR Ratio: 11, Epoch 823, Loss: 31.984255\n",
      "SNR Ratio: 11, Epoch 824, Loss: 30.907495\n",
      "SNR Ratio: 11, Epoch 825, Loss: 32.128326\n",
      "SNR Ratio: 11, Epoch 826, Loss: 36.261478\n",
      "SNR Ratio: 11, Epoch 827, Loss: 32.405968\n",
      "SNR Ratio: 11, Epoch 828, Loss: 33.941410\n",
      "SNR Ratio: 11, Epoch 829, Loss: 31.878574\n",
      "SNR Ratio: 11, Epoch 830, Loss: 29.227659\n",
      "SNR Ratio: 11, Epoch 831, Loss: 28.461985\n",
      "SNR Ratio: 11, Epoch 832, Loss: 32.252857\n",
      "SNR Ratio: 11, Epoch 833, Loss: 31.343958\n",
      "SNR Ratio: 11, Epoch 834, Loss: 30.893257\n",
      "SNR Ratio: 11, Epoch 835, Loss: 29.977457\n",
      "SNR Ratio: 11, Epoch 836, Loss: 32.687954\n",
      "SNR Ratio: 11, Epoch 837, Loss: 32.278927\n",
      "SNR Ratio: 11, Epoch 838, Loss: 34.176479\n",
      "SNR Ratio: 11, Epoch 839, Loss: 31.148983\n",
      "SNR Ratio: 11, Epoch 840, Loss: 35.169014\n",
      "SNR Ratio: 11, Epoch 841, Loss: 30.219431\n",
      "SNR Ratio: 11, Epoch 842, Loss: 29.351360\n",
      "SNR Ratio: 11, Epoch 843, Loss: 32.491329\n",
      "SNR Ratio: 11, Epoch 844, Loss: 31.725161\n",
      "SNR Ratio: 11, Epoch 845, Loss: 32.008179\n",
      "SNR Ratio: 11, Epoch 846, Loss: 29.826534\n",
      "SNR Ratio: 11, Epoch 847, Loss: 30.376440\n",
      "SNR Ratio: 11, Epoch 848, Loss: 33.659618\n",
      "SNR Ratio: 11, Epoch 849, Loss: 31.804226\n",
      "SNR Ratio: 11, Epoch 850, Loss: 31.797815\n",
      "SNR Ratio: 11, Epoch 851, Loss: 30.944433\n",
      "SNR Ratio: 11, Epoch 852, Loss: 33.084476\n",
      "SNR Ratio: 11, Epoch 853, Loss: 32.368679\n",
      "SNR Ratio: 11, Epoch 854, Loss: 28.784737\n",
      "SNR Ratio: 11, Epoch 855, Loss: 31.648682\n",
      "SNR Ratio: 11, Epoch 856, Loss: 33.944641\n",
      "SNR Ratio: 11, Epoch 857, Loss: 31.248985\n",
      "SNR Ratio: 11, Epoch 858, Loss: 33.302578\n",
      "SNR Ratio: 11, Epoch 859, Loss: 31.843454\n",
      "SNR Ratio: 11, Epoch 860, Loss: 31.234980\n",
      "SNR Ratio: 11, Epoch 861, Loss: 30.346165\n",
      "SNR Ratio: 11, Epoch 862, Loss: 31.187010\n",
      "SNR Ratio: 11, Epoch 863, Loss: 34.105736\n",
      "SNR Ratio: 11, Epoch 864, Loss: 29.781712\n",
      "SNR Ratio: 11, Epoch 865, Loss: 32.331043\n",
      "SNR Ratio: 11, Epoch 866, Loss: 33.786652\n",
      "SNR Ratio: 11, Epoch 867, Loss: 28.633635\n",
      "SNR Ratio: 11, Epoch 868, Loss: 32.854328\n",
      "SNR Ratio: 11, Epoch 869, Loss: 31.010521\n",
      "SNR Ratio: 11, Epoch 870, Loss: 32.671776\n",
      "SNR Ratio: 11, Epoch 871, Loss: 33.768162\n",
      "SNR Ratio: 11, Epoch 872, Loss: 35.145325\n",
      "SNR Ratio: 11, Epoch 873, Loss: 34.648167\n",
      "SNR Ratio: 11, Epoch 874, Loss: 31.649368\n",
      "SNR Ratio: 11, Epoch 875, Loss: 28.563616\n",
      "SNR Ratio: 11, Epoch 876, Loss: 29.153902\n",
      "SNR Ratio: 11, Epoch 877, Loss: 29.403790\n",
      "SNR Ratio: 11, Epoch 878, Loss: 30.299391\n",
      "SNR Ratio: 11, Epoch 879, Loss: 31.039431\n",
      "SNR Ratio: 11, Epoch 880, Loss: 32.648663\n",
      "SNR Ratio: 11, Epoch 881, Loss: 30.673290\n",
      "SNR Ratio: 11, Epoch 882, Loss: 32.462566\n",
      "SNR Ratio: 11, Epoch 883, Loss: 34.967041\n",
      "SNR Ratio: 11, Epoch 884, Loss: 31.212532\n",
      "SNR Ratio: 11, Epoch 885, Loss: 30.798805\n",
      "SNR Ratio: 11, Epoch 886, Loss: 29.053843\n",
      "SNR Ratio: 11, Epoch 887, Loss: 30.967871\n",
      "SNR Ratio: 11, Epoch 888, Loss: 30.519968\n",
      "SNR Ratio: 11, Epoch 889, Loss: 32.866131\n",
      "SNR Ratio: 11, Epoch 890, Loss: 27.495575\n",
      "SNR Ratio: 11, Epoch 891, Loss: 29.616755\n",
      "SNR Ratio: 11, Epoch 892, Loss: 31.961655\n",
      "SNR Ratio: 11, Epoch 893, Loss: 30.676680\n",
      "SNR Ratio: 11, Epoch 894, Loss: 30.249275\n",
      "SNR Ratio: 11, Epoch 895, Loss: 31.110985\n",
      "SNR Ratio: 11, Epoch 896, Loss: 32.328049\n",
      "SNR Ratio: 11, Epoch 897, Loss: 29.760571\n",
      "SNR Ratio: 11, Epoch 898, Loss: 29.692974\n",
      "SNR Ratio: 11, Epoch 899, Loss: 31.049847\n",
      "SNR Ratio: 11, Epoch 900, Loss: 33.663719\n",
      "SNR Ratio: 11, Epoch 901, Loss: 32.264118\n",
      "SNR Ratio: 11, Epoch 902, Loss: 29.931908\n",
      "SNR Ratio: 11, Epoch 903, Loss: 29.429762\n",
      "SNR Ratio: 11, Epoch 904, Loss: 30.687027\n",
      "SNR Ratio: 11, Epoch 905, Loss: 26.454466\n",
      "SNR Ratio: 11, Epoch 906, Loss: 29.845236\n",
      "SNR Ratio: 11, Epoch 907, Loss: 27.551708\n",
      "SNR Ratio: 11, Epoch 908, Loss: 32.873581\n",
      "SNR Ratio: 11, Epoch 909, Loss: 30.315155\n",
      "SNR Ratio: 11, Epoch 910, Loss: 31.264320\n",
      "SNR Ratio: 11, Epoch 911, Loss: 28.475380\n",
      "SNR Ratio: 11, Epoch 912, Loss: 30.995745\n",
      "SNR Ratio: 11, Epoch 913, Loss: 34.163342\n",
      "SNR Ratio: 11, Epoch 914, Loss: 27.739944\n",
      "SNR Ratio: 11, Epoch 915, Loss: 29.759155\n",
      "SNR Ratio: 11, Epoch 916, Loss: 32.395699\n",
      "SNR Ratio: 11, Epoch 917, Loss: 29.463158\n",
      "SNR Ratio: 11, Epoch 918, Loss: 29.081566\n",
      "SNR Ratio: 11, Epoch 919, Loss: 30.493443\n",
      "SNR Ratio: 11, Epoch 920, Loss: 30.997143\n",
      "SNR Ratio: 11, Epoch 921, Loss: 25.973934\n",
      "SNR Ratio: 11, Epoch 922, Loss: 27.440065\n",
      "SNR Ratio: 11, Epoch 923, Loss: 31.251587\n",
      "SNR Ratio: 11, Epoch 924, Loss: 30.775717\n",
      "SNR Ratio: 11, Epoch 925, Loss: 31.261786\n",
      "SNR Ratio: 11, Epoch 926, Loss: 33.006603\n",
      "SNR Ratio: 11, Epoch 927, Loss: 30.680044\n",
      "SNR Ratio: 11, Epoch 928, Loss: 29.103867\n",
      "SNR Ratio: 11, Epoch 929, Loss: 29.532045\n",
      "SNR Ratio: 11, Epoch 930, Loss: 29.102764\n",
      "SNR Ratio: 11, Epoch 931, Loss: 29.056770\n",
      "SNR Ratio: 11, Epoch 932, Loss: 32.226089\n",
      "SNR Ratio: 11, Epoch 933, Loss: 27.880674\n",
      "SNR Ratio: 11, Epoch 934, Loss: 32.560768\n",
      "SNR Ratio: 11, Epoch 935, Loss: 27.431673\n",
      "SNR Ratio: 11, Epoch 936, Loss: 32.363121\n",
      "SNR Ratio: 11, Epoch 937, Loss: 29.914721\n",
      "SNR Ratio: 11, Epoch 938, Loss: 30.069010\n",
      "SNR Ratio: 11, Epoch 939, Loss: 28.624638\n",
      "SNR Ratio: 11, Epoch 940, Loss: 30.321367\n",
      "SNR Ratio: 11, Epoch 941, Loss: 27.559288\n",
      "SNR Ratio: 11, Epoch 942, Loss: 27.331409\n",
      "SNR Ratio: 11, Epoch 943, Loss: 29.299601\n",
      "SNR Ratio: 11, Epoch 944, Loss: 28.456192\n",
      "SNR Ratio: 11, Epoch 945, Loss: 28.372908\n",
      "SNR Ratio: 11, Epoch 946, Loss: 31.903080\n",
      "SNR Ratio: 11, Epoch 947, Loss: 32.102989\n",
      "SNR Ratio: 11, Epoch 948, Loss: 32.194420\n",
      "SNR Ratio: 11, Epoch 949, Loss: 30.000086\n",
      "SNR Ratio: 11, Epoch 950, Loss: 29.176020\n",
      "SNR Ratio: 11, Epoch 951, Loss: 28.640787\n",
      "SNR Ratio: 11, Epoch 952, Loss: 30.566988\n",
      "SNR Ratio: 11, Epoch 953, Loss: 29.281145\n",
      "SNR Ratio: 11, Epoch 954, Loss: 30.599983\n",
      "SNR Ratio: 11, Epoch 955, Loss: 32.994865\n",
      "SNR Ratio: 11, Epoch 956, Loss: 30.794220\n",
      "SNR Ratio: 11, Epoch 957, Loss: 28.176426\n",
      "SNR Ratio: 11, Epoch 958, Loss: 31.606726\n",
      "SNR Ratio: 11, Epoch 959, Loss: 29.669109\n",
      "SNR Ratio: 11, Epoch 960, Loss: 28.855175\n",
      "SNR Ratio: 11, Epoch 961, Loss: 33.082062\n",
      "SNR Ratio: 11, Epoch 962, Loss: 27.351633\n",
      "SNR Ratio: 11, Epoch 963, Loss: 28.790310\n",
      "SNR Ratio: 11, Epoch 964, Loss: 30.611626\n",
      "SNR Ratio: 11, Epoch 965, Loss: 28.014357\n",
      "SNR Ratio: 11, Epoch 966, Loss: 28.567801\n",
      "SNR Ratio: 11, Epoch 967, Loss: 32.043243\n",
      "SNR Ratio: 11, Epoch 968, Loss: 29.022863\n",
      "SNR Ratio: 11, Epoch 969, Loss: 30.451553\n",
      "SNR Ratio: 11, Epoch 970, Loss: 27.671602\n",
      "SNR Ratio: 11, Epoch 971, Loss: 31.040510\n",
      "SNR Ratio: 11, Epoch 972, Loss: 32.730415\n",
      "SNR Ratio: 11, Epoch 973, Loss: 28.911024\n",
      "SNR Ratio: 11, Epoch 974, Loss: 28.270121\n",
      "SNR Ratio: 11, Epoch 975, Loss: 33.154579\n",
      "SNR Ratio: 11, Epoch 976, Loss: 27.106070\n",
      "SNR Ratio: 11, Epoch 977, Loss: 28.553032\n",
      "SNR Ratio: 11, Epoch 978, Loss: 35.084240\n",
      "SNR Ratio: 11, Epoch 979, Loss: 33.918610\n",
      "SNR Ratio: 11, Epoch 980, Loss: 29.114340\n",
      "SNR Ratio: 11, Epoch 981, Loss: 31.591261\n",
      "SNR Ratio: 11, Epoch 982, Loss: 28.943451\n",
      "SNR Ratio: 11, Epoch 983, Loss: 30.547375\n",
      "SNR Ratio: 11, Epoch 984, Loss: 31.186766\n",
      "SNR Ratio: 11, Epoch 985, Loss: 30.184740\n",
      "SNR Ratio: 11, Epoch 986, Loss: 29.475426\n",
      "SNR Ratio: 11, Epoch 987, Loss: 26.626961\n",
      "SNR Ratio: 11, Epoch 988, Loss: 30.389662\n",
      "SNR Ratio: 11, Epoch 989, Loss: 30.091612\n",
      "SNR Ratio: 11, Epoch 990, Loss: 25.428577\n",
      "SNR Ratio: 11, Epoch 991, Loss: 28.368679\n",
      "SNR Ratio: 11, Epoch 992, Loss: 29.316652\n",
      "SNR Ratio: 11, Epoch 993, Loss: 31.166451\n",
      "SNR Ratio: 11, Epoch 994, Loss: 30.180815\n",
      "SNR Ratio: 11, Epoch 995, Loss: 29.265070\n",
      "SNR Ratio: 11, Epoch 996, Loss: 28.104876\n",
      "SNR Ratio: 11, Epoch 997, Loss: 27.515051\n",
      "SNR Ratio: 11, Epoch 998, Loss: 29.980536\n",
      "SNR Ratio: 11, Epoch 999, Loss: 29.419603\n",
      "SNR Ratio: 11, Epoch 1000, Loss: 25.837490\n",
      "SNR Ratio: 11, Epoch 1001, Loss: 29.001545\n",
      "SNR Ratio: 11, Epoch 1002, Loss: 29.971439\n",
      "SNR Ratio: 11, Epoch 1003, Loss: 28.580786\n",
      "SNR Ratio: 11, Epoch 1004, Loss: 27.774370\n",
      "SNR Ratio: 11, Epoch 1005, Loss: 27.551258\n",
      "SNR Ratio: 11, Epoch 1006, Loss: 28.338415\n",
      "SNR Ratio: 11, Epoch 1007, Loss: 29.221870\n",
      "SNR Ratio: 11, Epoch 1008, Loss: 29.297935\n",
      "SNR Ratio: 11, Epoch 1009, Loss: 27.835482\n",
      "SNR Ratio: 11, Epoch 1010, Loss: 28.057510\n",
      "SNR Ratio: 11, Epoch 1011, Loss: 29.922890\n",
      "SNR Ratio: 11, Epoch 1012, Loss: 25.860287\n",
      "SNR Ratio: 11, Epoch 1013, Loss: 30.297497\n",
      "SNR Ratio: 11, Epoch 1014, Loss: 28.634268\n",
      "SNR Ratio: 11, Epoch 1015, Loss: 30.230122\n",
      "SNR Ratio: 11, Epoch 1016, Loss: 26.182026\n",
      "SNR Ratio: 11, Epoch 1017, Loss: 29.639812\n",
      "SNR Ratio: 11, Epoch 1018, Loss: 31.077225\n",
      "SNR Ratio: 11, Epoch 1019, Loss: 25.476927\n",
      "SNR Ratio: 11, Epoch 1020, Loss: 27.513510\n",
      "SNR Ratio: 11, Epoch 1021, Loss: 30.247528\n",
      "SNR Ratio: 11, Epoch 1022, Loss: 32.155071\n",
      "SNR Ratio: 11, Epoch 1023, Loss: 30.260075\n",
      "SNR Ratio: 11, Epoch 1024, Loss: 28.973684\n",
      "SNR Ratio: 11, Epoch 1025, Loss: 31.318665\n",
      "SNR Ratio: 11, Epoch 1026, Loss: 27.850878\n",
      "SNR Ratio: 11, Epoch 1027, Loss: 28.258314\n",
      "SNR Ratio: 11, Epoch 1028, Loss: 27.156820\n",
      "SNR Ratio: 11, Epoch 1029, Loss: 30.941019\n",
      "SNR Ratio: 11, Epoch 1030, Loss: 28.342648\n",
      "SNR Ratio: 11, Epoch 1031, Loss: 28.708200\n",
      "SNR Ratio: 11, Epoch 1032, Loss: 29.009235\n",
      "SNR Ratio: 11, Epoch 1033, Loss: 29.553883\n",
      "SNR Ratio: 11, Epoch 1034, Loss: 29.298475\n",
      "SNR Ratio: 11, Epoch 1035, Loss: 27.155760\n",
      "SNR Ratio: 11, Epoch 1036, Loss: 29.986893\n",
      "SNR Ratio: 11, Epoch 1037, Loss: 27.565847\n",
      "SNR Ratio: 11, Epoch 1038, Loss: 27.062176\n",
      "SNR Ratio: 11, Epoch 1039, Loss: 28.929640\n",
      "SNR Ratio: 11, Epoch 1040, Loss: 31.748940\n",
      "SNR Ratio: 11, Epoch 1041, Loss: 29.586437\n",
      "SNR Ratio: 11, Epoch 1042, Loss: 30.153990\n",
      "SNR Ratio: 11, Epoch 1043, Loss: 29.436432\n",
      "SNR Ratio: 11, Epoch 1044, Loss: 29.600080\n",
      "SNR Ratio: 11, Epoch 1045, Loss: 29.300245\n",
      "SNR Ratio: 11, Epoch 1046, Loss: 27.780430\n",
      "SNR Ratio: 11, Epoch 1047, Loss: 29.793133\n",
      "SNR Ratio: 11, Epoch 1048, Loss: 25.167986\n",
      "SNR Ratio: 11, Epoch 1049, Loss: 29.656660\n",
      "SNR Ratio: 11, Epoch 1050, Loss: 34.784447\n",
      "SNR Ratio: 11, Epoch 1051, Loss: 30.751850\n",
      "SNR Ratio: 11, Epoch 1052, Loss: 28.726801\n",
      "SNR Ratio: 11, Epoch 1053, Loss: 29.499203\n",
      "SNR Ratio: 11, Epoch 1054, Loss: 27.915630\n",
      "SNR Ratio: 11, Epoch 1055, Loss: 26.863075\n",
      "SNR Ratio: 11, Epoch 1056, Loss: 28.628048\n",
      "SNR Ratio: 11, Epoch 1057, Loss: 28.525826\n",
      "SNR Ratio: 11, Epoch 1058, Loss: 27.933487\n",
      "SNR Ratio: 11, Epoch 1059, Loss: 28.856236\n",
      "SNR Ratio: 11, Epoch 1060, Loss: 32.006805\n",
      "SNR Ratio: 11, Epoch 1061, Loss: 29.521425\n",
      "SNR Ratio: 11, Epoch 1062, Loss: 31.003071\n",
      "SNR Ratio: 11, Epoch 1063, Loss: 28.329535\n",
      "SNR Ratio: 11, Epoch 1064, Loss: 29.625317\n",
      "SNR Ratio: 11, Epoch 1065, Loss: 27.723755\n",
      "SNR Ratio: 11, Epoch 1066, Loss: 26.060345\n",
      "SNR Ratio: 11, Epoch 1067, Loss: 29.174948\n",
      "SNR Ratio: 11, Epoch 1068, Loss: 31.688250\n",
      "SNR Ratio: 11, Epoch 1069, Loss: 30.836124\n",
      "SNR Ratio: 11, Epoch 1070, Loss: 28.829592\n",
      "SNR Ratio: 11, Epoch 1071, Loss: 28.416180\n",
      "SNR Ratio: 11, Epoch 1072, Loss: 25.134186\n",
      "SNR Ratio: 11, Epoch 1073, Loss: 27.969723\n",
      "SNR Ratio: 11, Epoch 1074, Loss: 26.919235\n",
      "SNR Ratio: 11, Epoch 1075, Loss: 27.999874\n",
      "SNR Ratio: 11, Epoch 1076, Loss: 29.061754\n",
      "SNR Ratio: 11, Epoch 1077, Loss: 27.617552\n",
      "SNR Ratio: 11, Epoch 1078, Loss: 29.662121\n",
      "SNR Ratio: 11, Epoch 1079, Loss: 27.162451\n",
      "SNR Ratio: 11, Epoch 1080, Loss: 29.691895\n",
      "SNR Ratio: 11, Epoch 1081, Loss: 26.885710\n",
      "SNR Ratio: 11, Epoch 1082, Loss: 31.756035\n",
      "SNR Ratio: 11, Epoch 1083, Loss: 26.662605\n",
      "SNR Ratio: 11, Epoch 1084, Loss: 31.164015\n",
      "SNR Ratio: 11, Epoch 1085, Loss: 26.936365\n",
      "SNR Ratio: 11, Epoch 1086, Loss: 30.409832\n",
      "SNR Ratio: 11, Epoch 1087, Loss: 31.084980\n",
      "SNR Ratio: 11, Epoch 1088, Loss: 26.478195\n",
      "SNR Ratio: 11, Epoch 1089, Loss: 25.359812\n",
      "SNR Ratio: 11, Epoch 1090, Loss: 31.190704\n",
      "SNR Ratio: 11, Epoch 1091, Loss: 26.715307\n",
      "SNR Ratio: 11, Epoch 1092, Loss: 27.005793\n",
      "SNR Ratio: 11, Epoch 1093, Loss: 27.674763\n",
      "SNR Ratio: 11, Epoch 1094, Loss: 25.999067\n",
      "SNR Ratio: 11, Epoch 1095, Loss: 27.913458\n",
      "SNR Ratio: 11, Epoch 1096, Loss: 26.258982\n",
      "SNR Ratio: 11, Epoch 1097, Loss: 29.035612\n",
      "SNR Ratio: 11, Epoch 1098, Loss: 27.801531\n",
      "SNR Ratio: 11, Epoch 1099, Loss: 30.885035\n",
      "SNR Ratio: 11, Epoch 1100, Loss: 30.849001\n",
      "SNR Ratio: 11, Epoch 1101, Loss: 26.964550\n",
      "SNR Ratio: 11, Epoch 1102, Loss: 30.151979\n",
      "SNR Ratio: 11, Epoch 1103, Loss: 29.079716\n",
      "SNR Ratio: 11, Epoch 1104, Loss: 26.366964\n",
      "SNR Ratio: 11, Epoch 1105, Loss: 28.226587\n",
      "SNR Ratio: 11, Epoch 1106, Loss: 26.357630\n",
      "SNR Ratio: 11, Epoch 1107, Loss: 28.055073\n",
      "SNR Ratio: 11, Epoch 1108, Loss: 26.648020\n",
      "SNR Ratio: 11, Epoch 1109, Loss: 27.796062\n",
      "SNR Ratio: 11, Epoch 1110, Loss: 25.982580\n",
      "SNR Ratio: 11, Epoch 1111, Loss: 27.577845\n",
      "SNR Ratio: 11, Epoch 1112, Loss: 26.855194\n",
      "SNR Ratio: 11, Epoch 1113, Loss: 26.946590\n",
      "SNR Ratio: 11, Epoch 1114, Loss: 28.713255\n",
      "SNR Ratio: 11, Epoch 1115, Loss: 26.476128\n",
      "SNR Ratio: 11, Epoch 1116, Loss: 30.016914\n",
      "SNR Ratio: 11, Epoch 1117, Loss: 28.305662\n",
      "SNR Ratio: 11, Epoch 1118, Loss: 27.697201\n",
      "SNR Ratio: 11, Epoch 1119, Loss: 28.657410\n",
      "SNR Ratio: 11, Epoch 1120, Loss: 25.826756\n",
      "SNR Ratio: 11, Epoch 1121, Loss: 26.499853\n",
      "SNR Ratio: 11, Epoch 1122, Loss: 30.798248\n",
      "SNR Ratio: 11, Epoch 1123, Loss: 27.413372\n",
      "SNR Ratio: 11, Epoch 1124, Loss: 26.829716\n",
      "SNR Ratio: 11, Epoch 1125, Loss: 26.612129\n",
      "SNR Ratio: 11, Epoch 1126, Loss: 27.708763\n",
      "SNR Ratio: 11, Epoch 1127, Loss: 29.722540\n",
      "SNR Ratio: 11, Epoch 1128, Loss: 27.272816\n",
      "SNR Ratio: 11, Epoch 1129, Loss: 28.378466\n",
      "SNR Ratio: 11, Epoch 1130, Loss: 31.041756\n",
      "SNR Ratio: 11, Epoch 1131, Loss: 29.526943\n",
      "SNR Ratio: 11, Epoch 1132, Loss: 26.201468\n",
      "SNR Ratio: 11, Epoch 1133, Loss: 29.206558\n",
      "SNR Ratio: 11, Epoch 1134, Loss: 27.424589\n",
      "SNR Ratio: 11, Epoch 1135, Loss: 32.102646\n",
      "SNR Ratio: 11, Epoch 1136, Loss: 26.348270\n",
      "SNR Ratio: 11, Epoch 1137, Loss: 28.381962\n",
      "SNR Ratio: 11, Epoch 1138, Loss: 26.910915\n",
      "SNR Ratio: 11, Epoch 1139, Loss: 28.090212\n",
      "SNR Ratio: 11, Epoch 1140, Loss: 27.038378\n",
      "SNR Ratio: 11, Epoch 1141, Loss: 27.754810\n",
      "SNR Ratio: 11, Epoch 1142, Loss: 29.087160\n",
      "SNR Ratio: 11, Epoch 1143, Loss: 27.035280\n",
      "SNR Ratio: 11, Epoch 1144, Loss: 25.783392\n",
      "SNR Ratio: 11, Epoch 1145, Loss: 29.018450\n",
      "SNR Ratio: 11, Epoch 1146, Loss: 26.461845\n",
      "SNR Ratio: 11, Epoch 1147, Loss: 27.301685\n",
      "SNR Ratio: 11, Epoch 1148, Loss: 26.992533\n",
      "SNR Ratio: 11, Epoch 1149, Loss: 26.496035\n",
      "SNR Ratio: 11, Epoch 1150, Loss: 26.459885\n",
      "SNR Ratio: 11, Epoch 1151, Loss: 26.989912\n",
      "SNR Ratio: 11, Epoch 1152, Loss: 29.323870\n",
      "SNR Ratio: 11, Epoch 1153, Loss: 23.660347\n",
      "SNR Ratio: 11, Epoch 1154, Loss: 26.961962\n",
      "SNR Ratio: 11, Epoch 1155, Loss: 28.954885\n",
      "SNR Ratio: 11, Epoch 1156, Loss: 29.016846\n",
      "SNR Ratio: 11, Epoch 1157, Loss: 29.892342\n",
      "SNR Ratio: 11, Epoch 1158, Loss: 27.851088\n",
      "SNR Ratio: 11, Epoch 1159, Loss: 30.751835\n",
      "SNR Ratio: 11, Epoch 1160, Loss: 28.728975\n",
      "SNR Ratio: 11, Epoch 1161, Loss: 28.554995\n",
      "SNR Ratio: 11, Epoch 1162, Loss: 25.953098\n",
      "SNR Ratio: 11, Epoch 1163, Loss: 29.494394\n",
      "SNR Ratio: 11, Epoch 1164, Loss: 28.559830\n",
      "SNR Ratio: 11, Epoch 1165, Loss: 29.300268\n",
      "SNR Ratio: 11, Epoch 1166, Loss: 29.200697\n",
      "SNR Ratio: 11, Epoch 1167, Loss: 27.867386\n",
      "SNR Ratio: 11, Epoch 1168, Loss: 28.481750\n",
      "SNR Ratio: 11, Epoch 1169, Loss: 27.001909\n",
      "SNR Ratio: 11, Epoch 1170, Loss: 28.461214\n",
      "SNR Ratio: 11, Epoch 1171, Loss: 30.470024\n",
      "SNR Ratio: 11, Epoch 1172, Loss: 27.172476\n",
      "SNR Ratio: 11, Epoch 1173, Loss: 27.025927\n",
      "SNR Ratio: 11, Epoch 1174, Loss: 30.554775\n",
      "SNR Ratio: 11, Epoch 1175, Loss: 28.653988\n",
      "SNR Ratio: 11, Epoch 1176, Loss: 28.422045\n",
      "SNR Ratio: 11, Epoch 1177, Loss: 27.579596\n",
      "SNR Ratio: 11, Epoch 1178, Loss: 28.828995\n",
      "SNR Ratio: 11, Epoch 1179, Loss: 28.363026\n",
      "SNR Ratio: 11, Epoch 1180, Loss: 26.161922\n",
      "SNR Ratio: 11, Epoch 1181, Loss: 28.800705\n",
      "SNR Ratio: 11, Epoch 1182, Loss: 28.677876\n",
      "SNR Ratio: 11, Epoch 1183, Loss: 28.860365\n",
      "SNR Ratio: 11, Epoch 1184, Loss: 31.237625\n",
      "SNR Ratio: 11, Epoch 1185, Loss: 28.020735\n",
      "SNR Ratio: 11, Epoch 1186, Loss: 29.083223\n",
      "SNR Ratio: 11, Epoch 1187, Loss: 29.407240\n",
      "SNR Ratio: 11, Epoch 1188, Loss: 28.234804\n",
      "SNR Ratio: 11, Epoch 1189, Loss: 26.037294\n",
      "SNR Ratio: 11, Epoch 1190, Loss: 25.851295\n",
      "SNR Ratio: 11, Epoch 1191, Loss: 29.190825\n",
      "SNR Ratio: 11, Epoch 1192, Loss: 26.516476\n",
      "SNR Ratio: 11, Epoch 1193, Loss: 28.435755\n",
      "SNR Ratio: 11, Epoch 1194, Loss: 25.760010\n",
      "SNR Ratio: 11, Epoch 1195, Loss: 25.828205\n",
      "SNR Ratio: 11, Epoch 1196, Loss: 24.755075\n",
      "SNR Ratio: 11, Epoch 1197, Loss: 28.321896\n",
      "SNR Ratio: 11, Epoch 1198, Loss: 27.808784\n",
      "SNR Ratio: 11, Epoch 1199, Loss: 27.847822\n",
      "SNR Ratio: 11, Epoch 1200, Loss: 30.428055\n",
      "SNR Ratio: 11, Epoch 1201, Loss: 25.058941\n",
      "SNR Ratio: 11, Epoch 1202, Loss: 24.889135\n",
      "SNR Ratio: 11, Epoch 1203, Loss: 26.494980\n",
      "SNR Ratio: 11, Epoch 1204, Loss: 30.230675\n",
      "SNR Ratio: 11, Epoch 1205, Loss: 27.996090\n",
      "SNR Ratio: 11, Epoch 1206, Loss: 28.145124\n",
      "SNR Ratio: 11, Epoch 1207, Loss: 27.232018\n",
      "SNR Ratio: 11, Epoch 1208, Loss: 25.870655\n",
      "SNR Ratio: 11, Epoch 1209, Loss: 26.189140\n",
      "SNR Ratio: 11, Epoch 1210, Loss: 27.963415\n",
      "SNR Ratio: 11, Epoch 1211, Loss: 25.552143\n",
      "SNR Ratio: 11, Epoch 1212, Loss: 27.373079\n",
      "SNR Ratio: 11, Epoch 1213, Loss: 29.649046\n",
      "SNR Ratio: 11, Epoch 1214, Loss: 32.373634\n",
      "SNR Ratio: 11, Epoch 1215, Loss: 27.687771\n",
      "SNR Ratio: 11, Epoch 1216, Loss: 24.286797\n",
      "SNR Ratio: 11, Epoch 1217, Loss: 29.356091\n",
      "SNR Ratio: 11, Epoch 1218, Loss: 26.294102\n",
      "SNR Ratio: 11, Epoch 1219, Loss: 27.917259\n",
      "SNR Ratio: 11, Epoch 1220, Loss: 25.111031\n",
      "SNR Ratio: 11, Epoch 1221, Loss: 28.231840\n",
      "SNR Ratio: 11, Epoch 1222, Loss: 26.294645\n",
      "SNR Ratio: 11, Epoch 1223, Loss: 28.297293\n",
      "SNR Ratio: 11, Epoch 1224, Loss: 25.824762\n",
      "SNR Ratio: 11, Epoch 1225, Loss: 27.861683\n",
      "SNR Ratio: 11, Epoch 1226, Loss: 28.830126\n",
      "SNR Ratio: 11, Epoch 1227, Loss: 28.492697\n",
      "SNR Ratio: 11, Epoch 1228, Loss: 27.783840\n",
      "SNR Ratio: 11, Epoch 1229, Loss: 27.240074\n",
      "SNR Ratio: 11, Epoch 1230, Loss: 24.709644\n",
      "SNR Ratio: 11, Epoch 1231, Loss: 26.525230\n",
      "SNR Ratio: 11, Epoch 1232, Loss: 25.079580\n",
      "SNR Ratio: 11, Epoch 1233, Loss: 28.927521\n",
      "SNR Ratio: 11, Epoch 1234, Loss: 29.579954\n",
      "SNR Ratio: 11, Epoch 1235, Loss: 24.853525\n",
      "SNR Ratio: 11, Epoch 1236, Loss: 26.795683\n",
      "SNR Ratio: 11, Epoch 1237, Loss: 25.471388\n",
      "SNR Ratio: 11, Epoch 1238, Loss: 25.223160\n",
      "SNR Ratio: 11, Epoch 1239, Loss: 25.544279\n",
      "SNR Ratio: 11, Epoch 1240, Loss: 27.780832\n",
      "SNR Ratio: 11, Epoch 1241, Loss: 25.313213\n",
      "SNR Ratio: 11, Epoch 1242, Loss: 26.853254\n",
      "SNR Ratio: 11, Epoch 1243, Loss: 25.368265\n",
      "SNR Ratio: 11, Epoch 1244, Loss: 27.497915\n",
      "SNR Ratio: 11, Epoch 1245, Loss: 27.386822\n",
      "SNR Ratio: 11, Epoch 1246, Loss: 28.155502\n",
      "SNR Ratio: 11, Epoch 1247, Loss: 24.085537\n",
      "SNR Ratio: 11, Epoch 1248, Loss: 25.195385\n",
      "SNR Ratio: 11, Epoch 1249, Loss: 24.939804\n",
      "SNR Ratio: 11, Epoch 1250, Loss: 26.370054\n",
      "SNR Ratio: 11, Epoch 1251, Loss: 27.726179\n",
      "SNR Ratio: 11, Epoch 1252, Loss: 25.024050\n",
      "SNR Ratio: 11, Epoch 1253, Loss: 27.716108\n",
      "Stopped early after 1254 epochs, with loss 23.660347\n",
      "SNR Ratio: 14, Epoch 1, Loss: 334.533234\n",
      "SNR Ratio: 14, Epoch 2, Loss: 326.918060\n",
      "SNR Ratio: 14, Epoch 3, Loss: 314.071686\n",
      "SNR Ratio: 14, Epoch 4, Loss: 271.354309\n",
      "SNR Ratio: 14, Epoch 5, Loss: 241.298981\n",
      "SNR Ratio: 14, Epoch 6, Loss: 212.494736\n",
      "SNR Ratio: 14, Epoch 7, Loss: 195.310654\n",
      "SNR Ratio: 14, Epoch 8, Loss: 175.721680\n",
      "SNR Ratio: 14, Epoch 9, Loss: 171.907318\n",
      "SNR Ratio: 14, Epoch 10, Loss: 165.132965\n",
      "SNR Ratio: 14, Epoch 11, Loss: 154.962036\n",
      "SNR Ratio: 14, Epoch 12, Loss: 146.047440\n",
      "SNR Ratio: 14, Epoch 13, Loss: 143.722260\n",
      "SNR Ratio: 14, Epoch 14, Loss: 137.206406\n",
      "SNR Ratio: 14, Epoch 15, Loss: 129.363327\n",
      "SNR Ratio: 14, Epoch 16, Loss: 137.608032\n",
      "SNR Ratio: 14, Epoch 17, Loss: 132.755325\n",
      "SNR Ratio: 14, Epoch 18, Loss: 130.159576\n",
      "SNR Ratio: 14, Epoch 19, Loss: 124.585220\n",
      "SNR Ratio: 14, Epoch 20, Loss: 122.046478\n",
      "SNR Ratio: 14, Epoch 21, Loss: 124.281677\n",
      "SNR Ratio: 14, Epoch 22, Loss: 117.109009\n",
      "SNR Ratio: 14, Epoch 23, Loss: 119.003952\n",
      "SNR Ratio: 14, Epoch 24, Loss: 114.752213\n",
      "SNR Ratio: 14, Epoch 25, Loss: 110.879112\n",
      "SNR Ratio: 14, Epoch 26, Loss: 110.405319\n",
      "SNR Ratio: 14, Epoch 27, Loss: 111.293900\n",
      "SNR Ratio: 14, Epoch 28, Loss: 110.483803\n",
      "SNR Ratio: 14, Epoch 29, Loss: 108.194710\n",
      "SNR Ratio: 14, Epoch 30, Loss: 107.911621\n",
      "SNR Ratio: 14, Epoch 31, Loss: 110.088608\n",
      "SNR Ratio: 14, Epoch 32, Loss: 109.913567\n",
      "SNR Ratio: 14, Epoch 33, Loss: 105.244217\n",
      "SNR Ratio: 14, Epoch 34, Loss: 108.372414\n",
      "SNR Ratio: 14, Epoch 35, Loss: 102.779701\n",
      "SNR Ratio: 14, Epoch 36, Loss: 105.527122\n",
      "SNR Ratio: 14, Epoch 37, Loss: 102.612350\n",
      "SNR Ratio: 14, Epoch 38, Loss: 102.402023\n",
      "SNR Ratio: 14, Epoch 39, Loss: 101.939743\n",
      "SNR Ratio: 14, Epoch 40, Loss: 100.349541\n",
      "SNR Ratio: 14, Epoch 41, Loss: 100.416634\n",
      "SNR Ratio: 14, Epoch 42, Loss: 100.209953\n",
      "SNR Ratio: 14, Epoch 43, Loss: 102.496902\n",
      "SNR Ratio: 14, Epoch 44, Loss: 98.958977\n",
      "SNR Ratio: 14, Epoch 45, Loss: 97.610336\n",
      "SNR Ratio: 14, Epoch 46, Loss: 100.215958\n",
      "SNR Ratio: 14, Epoch 47, Loss: 102.500061\n",
      "SNR Ratio: 14, Epoch 48, Loss: 92.636833\n",
      "SNR Ratio: 14, Epoch 49, Loss: 99.972221\n",
      "SNR Ratio: 14, Epoch 50, Loss: 96.129822\n",
      "SNR Ratio: 14, Epoch 51, Loss: 96.605530\n",
      "SNR Ratio: 14, Epoch 52, Loss: 99.782341\n",
      "SNR Ratio: 14, Epoch 53, Loss: 95.582603\n",
      "SNR Ratio: 14, Epoch 54, Loss: 97.182358\n",
      "SNR Ratio: 14, Epoch 55, Loss: 95.284462\n",
      "SNR Ratio: 14, Epoch 56, Loss: 94.470963\n",
      "SNR Ratio: 14, Epoch 57, Loss: 94.160622\n",
      "SNR Ratio: 14, Epoch 58, Loss: 90.979553\n",
      "SNR Ratio: 14, Epoch 59, Loss: 98.401657\n",
      "SNR Ratio: 14, Epoch 60, Loss: 93.126389\n",
      "SNR Ratio: 14, Epoch 61, Loss: 93.781151\n",
      "SNR Ratio: 14, Epoch 62, Loss: 91.729782\n",
      "SNR Ratio: 14, Epoch 63, Loss: 92.820381\n",
      "SNR Ratio: 14, Epoch 64, Loss: 92.003906\n",
      "SNR Ratio: 14, Epoch 65, Loss: 92.106018\n",
      "SNR Ratio: 14, Epoch 66, Loss: 89.446251\n",
      "SNR Ratio: 14, Epoch 67, Loss: 89.899620\n",
      "SNR Ratio: 14, Epoch 68, Loss: 86.261879\n",
      "SNR Ratio: 14, Epoch 69, Loss: 88.150009\n",
      "SNR Ratio: 14, Epoch 70, Loss: 89.399300\n",
      "SNR Ratio: 14, Epoch 71, Loss: 86.882843\n",
      "SNR Ratio: 14, Epoch 72, Loss: 92.392616\n",
      "SNR Ratio: 14, Epoch 73, Loss: 89.920921\n",
      "SNR Ratio: 14, Epoch 74, Loss: 90.225403\n",
      "SNR Ratio: 14, Epoch 75, Loss: 87.241707\n",
      "SNR Ratio: 14, Epoch 76, Loss: 86.193878\n",
      "SNR Ratio: 14, Epoch 77, Loss: 84.410683\n",
      "SNR Ratio: 14, Epoch 78, Loss: 86.599998\n",
      "SNR Ratio: 14, Epoch 79, Loss: 83.989128\n",
      "SNR Ratio: 14, Epoch 80, Loss: 85.344818\n",
      "SNR Ratio: 14, Epoch 81, Loss: 89.815086\n",
      "SNR Ratio: 14, Epoch 82, Loss: 82.953857\n",
      "SNR Ratio: 14, Epoch 83, Loss: 82.296928\n",
      "SNR Ratio: 14, Epoch 84, Loss: 81.865868\n",
      "SNR Ratio: 14, Epoch 85, Loss: 82.159470\n",
      "SNR Ratio: 14, Epoch 86, Loss: 84.179871\n",
      "SNR Ratio: 14, Epoch 87, Loss: 81.759727\n",
      "SNR Ratio: 14, Epoch 88, Loss: 79.964981\n",
      "SNR Ratio: 14, Epoch 89, Loss: 80.496727\n",
      "SNR Ratio: 14, Epoch 90, Loss: 79.324303\n",
      "SNR Ratio: 14, Epoch 91, Loss: 78.912483\n",
      "SNR Ratio: 14, Epoch 92, Loss: 82.450813\n",
      "SNR Ratio: 14, Epoch 93, Loss: 79.738243\n",
      "SNR Ratio: 14, Epoch 94, Loss: 79.323967\n",
      "SNR Ratio: 14, Epoch 95, Loss: 78.379646\n",
      "SNR Ratio: 14, Epoch 96, Loss: 80.337997\n",
      "SNR Ratio: 14, Epoch 97, Loss: 80.792892\n",
      "SNR Ratio: 14, Epoch 98, Loss: 80.297394\n",
      "SNR Ratio: 14, Epoch 99, Loss: 83.373589\n",
      "SNR Ratio: 14, Epoch 100, Loss: 81.319954\n",
      "SNR Ratio: 14, Epoch 101, Loss: 81.020462\n",
      "SNR Ratio: 14, Epoch 102, Loss: 82.908409\n",
      "SNR Ratio: 14, Epoch 103, Loss: 78.255379\n",
      "SNR Ratio: 14, Epoch 104, Loss: 78.813858\n",
      "SNR Ratio: 14, Epoch 105, Loss: 80.497749\n",
      "SNR Ratio: 14, Epoch 106, Loss: 80.358879\n",
      "SNR Ratio: 14, Epoch 107, Loss: 77.091599\n",
      "SNR Ratio: 14, Epoch 108, Loss: 77.700615\n",
      "SNR Ratio: 14, Epoch 109, Loss: 77.163872\n",
      "SNR Ratio: 14, Epoch 110, Loss: 76.539833\n",
      "SNR Ratio: 14, Epoch 111, Loss: 80.531174\n",
      "SNR Ratio: 14, Epoch 112, Loss: 77.301537\n",
      "SNR Ratio: 14, Epoch 113, Loss: 77.492981\n",
      "SNR Ratio: 14, Epoch 114, Loss: 77.200546\n",
      "SNR Ratio: 14, Epoch 115, Loss: 77.777702\n",
      "SNR Ratio: 14, Epoch 116, Loss: 78.296654\n",
      "SNR Ratio: 14, Epoch 117, Loss: 76.297188\n",
      "SNR Ratio: 14, Epoch 118, Loss: 76.810013\n",
      "SNR Ratio: 14, Epoch 119, Loss: 78.778488\n",
      "SNR Ratio: 14, Epoch 120, Loss: 78.328613\n",
      "SNR Ratio: 14, Epoch 121, Loss: 76.103096\n",
      "SNR Ratio: 14, Epoch 122, Loss: 77.185928\n",
      "SNR Ratio: 14, Epoch 123, Loss: 75.679962\n",
      "SNR Ratio: 14, Epoch 124, Loss: 76.830452\n",
      "SNR Ratio: 14, Epoch 125, Loss: 73.811058\n",
      "SNR Ratio: 14, Epoch 126, Loss: 74.809464\n",
      "SNR Ratio: 14, Epoch 127, Loss: 71.328484\n",
      "SNR Ratio: 14, Epoch 128, Loss: 76.648254\n",
      "SNR Ratio: 14, Epoch 129, Loss: 76.180740\n",
      "SNR Ratio: 14, Epoch 130, Loss: 76.527573\n",
      "SNR Ratio: 14, Epoch 131, Loss: 74.644974\n",
      "SNR Ratio: 14, Epoch 132, Loss: 71.516449\n",
      "SNR Ratio: 14, Epoch 133, Loss: 73.746147\n",
      "SNR Ratio: 14, Epoch 134, Loss: 70.600594\n",
      "SNR Ratio: 14, Epoch 135, Loss: 73.459198\n",
      "SNR Ratio: 14, Epoch 136, Loss: 76.009224\n",
      "SNR Ratio: 14, Epoch 137, Loss: 74.806213\n",
      "SNR Ratio: 14, Epoch 138, Loss: 72.152618\n",
      "SNR Ratio: 14, Epoch 139, Loss: 71.535240\n",
      "SNR Ratio: 14, Epoch 140, Loss: 71.399551\n",
      "SNR Ratio: 14, Epoch 141, Loss: 73.984802\n",
      "SNR Ratio: 14, Epoch 142, Loss: 73.472290\n",
      "SNR Ratio: 14, Epoch 143, Loss: 71.845245\n",
      "SNR Ratio: 14, Epoch 144, Loss: 73.373482\n",
      "SNR Ratio: 14, Epoch 145, Loss: 70.301422\n",
      "SNR Ratio: 14, Epoch 146, Loss: 77.580673\n",
      "SNR Ratio: 14, Epoch 147, Loss: 73.355110\n",
      "SNR Ratio: 14, Epoch 148, Loss: 71.951141\n",
      "SNR Ratio: 14, Epoch 149, Loss: 72.372276\n",
      "SNR Ratio: 14, Epoch 150, Loss: 73.697662\n",
      "SNR Ratio: 14, Epoch 151, Loss: 70.970238\n",
      "SNR Ratio: 14, Epoch 152, Loss: 70.766792\n",
      "SNR Ratio: 14, Epoch 153, Loss: 69.275787\n",
      "SNR Ratio: 14, Epoch 154, Loss: 70.336967\n",
      "SNR Ratio: 14, Epoch 155, Loss: 68.863213\n",
      "SNR Ratio: 14, Epoch 156, Loss: 68.799858\n",
      "SNR Ratio: 14, Epoch 157, Loss: 73.093369\n",
      "SNR Ratio: 14, Epoch 158, Loss: 71.312973\n",
      "SNR Ratio: 14, Epoch 159, Loss: 69.953102\n",
      "SNR Ratio: 14, Epoch 160, Loss: 70.910683\n",
      "SNR Ratio: 14, Epoch 161, Loss: 65.213623\n",
      "SNR Ratio: 14, Epoch 162, Loss: 71.176979\n",
      "SNR Ratio: 14, Epoch 163, Loss: 69.911613\n",
      "SNR Ratio: 14, Epoch 164, Loss: 69.272339\n",
      "SNR Ratio: 14, Epoch 165, Loss: 66.994827\n",
      "SNR Ratio: 14, Epoch 166, Loss: 68.311249\n",
      "SNR Ratio: 14, Epoch 167, Loss: 72.165070\n",
      "SNR Ratio: 14, Epoch 168, Loss: 69.627045\n",
      "SNR Ratio: 14, Epoch 169, Loss: 67.731400\n",
      "SNR Ratio: 14, Epoch 170, Loss: 66.109581\n",
      "SNR Ratio: 14, Epoch 171, Loss: 68.365082\n",
      "SNR Ratio: 14, Epoch 172, Loss: 67.779572\n",
      "SNR Ratio: 14, Epoch 173, Loss: 68.166542\n",
      "SNR Ratio: 14, Epoch 174, Loss: 67.837494\n",
      "SNR Ratio: 14, Epoch 175, Loss: 66.701958\n",
      "SNR Ratio: 14, Epoch 176, Loss: 67.128838\n",
      "SNR Ratio: 14, Epoch 177, Loss: 70.039513\n",
      "SNR Ratio: 14, Epoch 178, Loss: 68.945038\n",
      "SNR Ratio: 14, Epoch 179, Loss: 65.856888\n",
      "SNR Ratio: 14, Epoch 180, Loss: 66.096657\n",
      "SNR Ratio: 14, Epoch 181, Loss: 69.203217\n",
      "SNR Ratio: 14, Epoch 182, Loss: 69.227913\n",
      "SNR Ratio: 14, Epoch 183, Loss: 67.094543\n",
      "SNR Ratio: 14, Epoch 184, Loss: 67.412331\n",
      "SNR Ratio: 14, Epoch 185, Loss: 63.742004\n",
      "SNR Ratio: 14, Epoch 186, Loss: 66.404198\n",
      "SNR Ratio: 14, Epoch 187, Loss: 65.632683\n",
      "SNR Ratio: 14, Epoch 188, Loss: 64.876953\n",
      "SNR Ratio: 14, Epoch 189, Loss: 63.744244\n",
      "SNR Ratio: 14, Epoch 190, Loss: 68.280907\n",
      "SNR Ratio: 14, Epoch 191, Loss: 65.789116\n",
      "SNR Ratio: 14, Epoch 192, Loss: 68.809387\n",
      "SNR Ratio: 14, Epoch 193, Loss: 64.120140\n",
      "SNR Ratio: 14, Epoch 194, Loss: 67.341438\n",
      "SNR Ratio: 14, Epoch 195, Loss: 64.158119\n",
      "SNR Ratio: 14, Epoch 196, Loss: 65.507309\n",
      "SNR Ratio: 14, Epoch 197, Loss: 64.107483\n",
      "SNR Ratio: 14, Epoch 198, Loss: 69.536728\n",
      "SNR Ratio: 14, Epoch 199, Loss: 63.610615\n",
      "SNR Ratio: 14, Epoch 200, Loss: 64.722000\n",
      "SNR Ratio: 14, Epoch 201, Loss: 65.269150\n",
      "SNR Ratio: 14, Epoch 202, Loss: 64.001923\n",
      "SNR Ratio: 14, Epoch 203, Loss: 61.866646\n",
      "SNR Ratio: 14, Epoch 204, Loss: 65.069450\n",
      "SNR Ratio: 14, Epoch 205, Loss: 66.229813\n",
      "SNR Ratio: 14, Epoch 206, Loss: 65.194366\n",
      "SNR Ratio: 14, Epoch 207, Loss: 64.405037\n",
      "SNR Ratio: 14, Epoch 208, Loss: 64.362663\n",
      "SNR Ratio: 14, Epoch 209, Loss: 65.253593\n",
      "SNR Ratio: 14, Epoch 210, Loss: 64.344620\n",
      "SNR Ratio: 14, Epoch 211, Loss: 62.886688\n",
      "SNR Ratio: 14, Epoch 212, Loss: 62.237839\n",
      "SNR Ratio: 14, Epoch 213, Loss: 62.960178\n",
      "SNR Ratio: 14, Epoch 214, Loss: 63.145275\n",
      "SNR Ratio: 14, Epoch 215, Loss: 60.976311\n",
      "SNR Ratio: 14, Epoch 216, Loss: 59.719185\n",
      "SNR Ratio: 14, Epoch 217, Loss: 62.726089\n",
      "SNR Ratio: 14, Epoch 218, Loss: 60.783867\n",
      "SNR Ratio: 14, Epoch 219, Loss: 62.557835\n",
      "SNR Ratio: 14, Epoch 220, Loss: 63.945496\n",
      "SNR Ratio: 14, Epoch 221, Loss: 59.849693\n",
      "SNR Ratio: 14, Epoch 222, Loss: 62.995159\n",
      "SNR Ratio: 14, Epoch 223, Loss: 62.568325\n",
      "SNR Ratio: 14, Epoch 224, Loss: 61.498852\n",
      "SNR Ratio: 14, Epoch 225, Loss: 61.314877\n",
      "SNR Ratio: 14, Epoch 226, Loss: 63.465660\n",
      "SNR Ratio: 14, Epoch 227, Loss: 62.195686\n",
      "SNR Ratio: 14, Epoch 228, Loss: 60.755798\n",
      "SNR Ratio: 14, Epoch 229, Loss: 61.042042\n",
      "SNR Ratio: 14, Epoch 230, Loss: 61.273911\n",
      "SNR Ratio: 14, Epoch 231, Loss: 63.964546\n",
      "SNR Ratio: 14, Epoch 232, Loss: 58.327789\n",
      "SNR Ratio: 14, Epoch 233, Loss: 62.987835\n",
      "SNR Ratio: 14, Epoch 234, Loss: 63.807884\n",
      "SNR Ratio: 14, Epoch 235, Loss: 60.038326\n",
      "SNR Ratio: 14, Epoch 236, Loss: 60.935467\n",
      "SNR Ratio: 14, Epoch 237, Loss: 60.202358\n",
      "SNR Ratio: 14, Epoch 238, Loss: 60.537319\n",
      "SNR Ratio: 14, Epoch 239, Loss: 58.234524\n",
      "SNR Ratio: 14, Epoch 240, Loss: 58.464714\n",
      "SNR Ratio: 14, Epoch 241, Loss: 60.218842\n",
      "SNR Ratio: 14, Epoch 242, Loss: 60.416309\n",
      "SNR Ratio: 14, Epoch 243, Loss: 60.067406\n",
      "SNR Ratio: 14, Epoch 244, Loss: 61.245819\n",
      "SNR Ratio: 14, Epoch 245, Loss: 60.279121\n",
      "SNR Ratio: 14, Epoch 246, Loss: 59.250736\n",
      "SNR Ratio: 14, Epoch 247, Loss: 59.673470\n",
      "SNR Ratio: 14, Epoch 248, Loss: 59.493881\n",
      "SNR Ratio: 14, Epoch 249, Loss: 59.659695\n",
      "SNR Ratio: 14, Epoch 250, Loss: 60.472885\n",
      "SNR Ratio: 14, Epoch 251, Loss: 60.128624\n",
      "SNR Ratio: 14, Epoch 252, Loss: 61.337502\n",
      "SNR Ratio: 14, Epoch 253, Loss: 58.669666\n",
      "SNR Ratio: 14, Epoch 254, Loss: 57.539375\n",
      "SNR Ratio: 14, Epoch 255, Loss: 57.475643\n",
      "SNR Ratio: 14, Epoch 256, Loss: 59.636154\n",
      "SNR Ratio: 14, Epoch 257, Loss: 58.668530\n",
      "SNR Ratio: 14, Epoch 258, Loss: 62.202148\n",
      "SNR Ratio: 14, Epoch 259, Loss: 56.747604\n",
      "SNR Ratio: 14, Epoch 260, Loss: 59.616570\n",
      "SNR Ratio: 14, Epoch 261, Loss: 57.074554\n",
      "SNR Ratio: 14, Epoch 262, Loss: 59.099609\n",
      "SNR Ratio: 14, Epoch 263, Loss: 58.063919\n",
      "SNR Ratio: 14, Epoch 264, Loss: 59.985432\n",
      "SNR Ratio: 14, Epoch 265, Loss: 58.602531\n",
      "SNR Ratio: 14, Epoch 266, Loss: 59.460426\n",
      "SNR Ratio: 14, Epoch 267, Loss: 56.953754\n",
      "SNR Ratio: 14, Epoch 268, Loss: 58.477921\n",
      "SNR Ratio: 14, Epoch 269, Loss: 58.815361\n",
      "SNR Ratio: 14, Epoch 270, Loss: 59.062740\n",
      "SNR Ratio: 14, Epoch 271, Loss: 57.247650\n",
      "SNR Ratio: 14, Epoch 272, Loss: 59.228504\n",
      "SNR Ratio: 14, Epoch 273, Loss: 58.434956\n",
      "SNR Ratio: 14, Epoch 274, Loss: 57.526649\n",
      "SNR Ratio: 14, Epoch 275, Loss: 58.370682\n",
      "SNR Ratio: 14, Epoch 276, Loss: 57.530464\n",
      "SNR Ratio: 14, Epoch 277, Loss: 56.652531\n",
      "SNR Ratio: 14, Epoch 278, Loss: 56.115051\n",
      "SNR Ratio: 14, Epoch 279, Loss: 57.901058\n",
      "SNR Ratio: 14, Epoch 280, Loss: 57.478844\n",
      "SNR Ratio: 14, Epoch 281, Loss: 54.493546\n",
      "SNR Ratio: 14, Epoch 282, Loss: 55.665440\n",
      "SNR Ratio: 14, Epoch 283, Loss: 56.823280\n",
      "SNR Ratio: 14, Epoch 284, Loss: 54.840820\n",
      "SNR Ratio: 14, Epoch 285, Loss: 57.551441\n",
      "SNR Ratio: 14, Epoch 286, Loss: 54.987259\n",
      "SNR Ratio: 14, Epoch 287, Loss: 57.459492\n",
      "SNR Ratio: 14, Epoch 288, Loss: 56.172031\n",
      "SNR Ratio: 14, Epoch 289, Loss: 56.661926\n",
      "SNR Ratio: 14, Epoch 290, Loss: 57.874901\n",
      "SNR Ratio: 14, Epoch 291, Loss: 54.930023\n",
      "SNR Ratio: 14, Epoch 292, Loss: 54.839306\n",
      "SNR Ratio: 14, Epoch 293, Loss: 55.738949\n",
      "SNR Ratio: 14, Epoch 294, Loss: 57.006710\n",
      "SNR Ratio: 14, Epoch 295, Loss: 57.302601\n",
      "SNR Ratio: 14, Epoch 296, Loss: 57.441925\n",
      "SNR Ratio: 14, Epoch 297, Loss: 56.459068\n",
      "SNR Ratio: 14, Epoch 298, Loss: 57.587688\n",
      "SNR Ratio: 14, Epoch 299, Loss: 57.060726\n",
      "SNR Ratio: 14, Epoch 300, Loss: 57.814587\n",
      "SNR Ratio: 14, Epoch 301, Loss: 54.962341\n",
      "SNR Ratio: 14, Epoch 302, Loss: 55.375984\n",
      "SNR Ratio: 14, Epoch 303, Loss: 56.771225\n",
      "SNR Ratio: 14, Epoch 304, Loss: 55.313789\n",
      "SNR Ratio: 14, Epoch 305, Loss: 54.735229\n",
      "SNR Ratio: 14, Epoch 306, Loss: 53.795246\n",
      "SNR Ratio: 14, Epoch 307, Loss: 54.799454\n",
      "SNR Ratio: 14, Epoch 308, Loss: 56.278385\n",
      "SNR Ratio: 14, Epoch 309, Loss: 56.007950\n",
      "SNR Ratio: 14, Epoch 310, Loss: 56.220482\n",
      "SNR Ratio: 14, Epoch 311, Loss: 57.566463\n",
      "SNR Ratio: 14, Epoch 312, Loss: 53.147949\n",
      "SNR Ratio: 14, Epoch 313, Loss: 55.353222\n",
      "SNR Ratio: 14, Epoch 314, Loss: 55.015514\n",
      "SNR Ratio: 14, Epoch 315, Loss: 54.725513\n",
      "SNR Ratio: 14, Epoch 316, Loss: 55.750504\n",
      "SNR Ratio: 14, Epoch 317, Loss: 54.512291\n",
      "SNR Ratio: 14, Epoch 318, Loss: 54.786018\n",
      "SNR Ratio: 14, Epoch 319, Loss: 54.932789\n",
      "SNR Ratio: 14, Epoch 320, Loss: 53.161461\n",
      "SNR Ratio: 14, Epoch 321, Loss: 53.082657\n",
      "SNR Ratio: 14, Epoch 322, Loss: 52.180141\n",
      "SNR Ratio: 14, Epoch 323, Loss: 55.403660\n",
      "SNR Ratio: 14, Epoch 324, Loss: 52.344170\n",
      "SNR Ratio: 14, Epoch 325, Loss: 54.497269\n",
      "SNR Ratio: 14, Epoch 326, Loss: 53.115509\n",
      "SNR Ratio: 14, Epoch 327, Loss: 53.445206\n",
      "SNR Ratio: 14, Epoch 328, Loss: 52.910725\n",
      "SNR Ratio: 14, Epoch 329, Loss: 55.541615\n",
      "SNR Ratio: 14, Epoch 330, Loss: 52.362453\n",
      "SNR Ratio: 14, Epoch 331, Loss: 51.407684\n",
      "SNR Ratio: 14, Epoch 332, Loss: 52.326820\n",
      "SNR Ratio: 14, Epoch 333, Loss: 53.934536\n",
      "SNR Ratio: 14, Epoch 334, Loss: 52.861622\n",
      "SNR Ratio: 14, Epoch 335, Loss: 49.755329\n",
      "SNR Ratio: 14, Epoch 336, Loss: 54.652836\n",
      "SNR Ratio: 14, Epoch 337, Loss: 52.931713\n",
      "SNR Ratio: 14, Epoch 338, Loss: 52.680805\n",
      "SNR Ratio: 14, Epoch 339, Loss: 51.532829\n",
      "SNR Ratio: 14, Epoch 340, Loss: 51.434235\n",
      "SNR Ratio: 14, Epoch 341, Loss: 53.974369\n",
      "SNR Ratio: 14, Epoch 342, Loss: 51.869709\n",
      "SNR Ratio: 14, Epoch 343, Loss: 53.783184\n",
      "SNR Ratio: 14, Epoch 344, Loss: 52.457504\n",
      "SNR Ratio: 14, Epoch 345, Loss: 51.303612\n",
      "SNR Ratio: 14, Epoch 346, Loss: 51.659035\n",
      "SNR Ratio: 14, Epoch 347, Loss: 49.572273\n",
      "SNR Ratio: 14, Epoch 348, Loss: 51.397820\n",
      "SNR Ratio: 14, Epoch 349, Loss: 51.214954\n",
      "SNR Ratio: 14, Epoch 350, Loss: 52.863075\n",
      "SNR Ratio: 14, Epoch 351, Loss: 53.369965\n",
      "SNR Ratio: 14, Epoch 352, Loss: 49.481152\n",
      "SNR Ratio: 14, Epoch 353, Loss: 51.480995\n",
      "SNR Ratio: 14, Epoch 354, Loss: 52.112751\n",
      "SNR Ratio: 14, Epoch 355, Loss: 53.859772\n",
      "SNR Ratio: 14, Epoch 356, Loss: 51.202209\n",
      "SNR Ratio: 14, Epoch 357, Loss: 50.524559\n",
      "SNR Ratio: 14, Epoch 358, Loss: 51.529251\n",
      "SNR Ratio: 14, Epoch 359, Loss: 48.951500\n",
      "SNR Ratio: 14, Epoch 360, Loss: 50.320614\n",
      "SNR Ratio: 14, Epoch 361, Loss: 48.576832\n",
      "SNR Ratio: 14, Epoch 362, Loss: 51.286945\n",
      "SNR Ratio: 14, Epoch 363, Loss: 48.732079\n",
      "SNR Ratio: 14, Epoch 364, Loss: 48.087555\n",
      "SNR Ratio: 14, Epoch 365, Loss: 49.966431\n",
      "SNR Ratio: 14, Epoch 366, Loss: 49.281429\n",
      "SNR Ratio: 14, Epoch 367, Loss: 49.269718\n",
      "SNR Ratio: 14, Epoch 368, Loss: 47.823704\n",
      "SNR Ratio: 14, Epoch 369, Loss: 47.479038\n",
      "SNR Ratio: 14, Epoch 370, Loss: 50.725819\n",
      "SNR Ratio: 14, Epoch 371, Loss: 50.172211\n",
      "SNR Ratio: 14, Epoch 372, Loss: 50.182354\n",
      "SNR Ratio: 14, Epoch 373, Loss: 51.032421\n",
      "SNR Ratio: 14, Epoch 374, Loss: 47.219952\n",
      "SNR Ratio: 14, Epoch 375, Loss: 49.503487\n",
      "SNR Ratio: 14, Epoch 376, Loss: 48.753426\n",
      "SNR Ratio: 14, Epoch 377, Loss: 50.082500\n",
      "SNR Ratio: 14, Epoch 378, Loss: 49.532215\n",
      "SNR Ratio: 14, Epoch 379, Loss: 48.566734\n",
      "SNR Ratio: 14, Epoch 380, Loss: 46.481709\n",
      "SNR Ratio: 14, Epoch 381, Loss: 46.354382\n",
      "SNR Ratio: 14, Epoch 382, Loss: 47.791725\n",
      "SNR Ratio: 14, Epoch 383, Loss: 48.028084\n",
      "SNR Ratio: 14, Epoch 384, Loss: 45.454948\n",
      "SNR Ratio: 14, Epoch 385, Loss: 47.492645\n",
      "SNR Ratio: 14, Epoch 386, Loss: 48.366135\n",
      "SNR Ratio: 14, Epoch 387, Loss: 47.748959\n",
      "SNR Ratio: 14, Epoch 388, Loss: 47.611851\n",
      "SNR Ratio: 14, Epoch 389, Loss: 47.335186\n",
      "SNR Ratio: 14, Epoch 390, Loss: 47.165466\n",
      "SNR Ratio: 14, Epoch 391, Loss: 46.359795\n",
      "SNR Ratio: 14, Epoch 392, Loss: 45.356934\n",
      "SNR Ratio: 14, Epoch 393, Loss: 46.386089\n",
      "SNR Ratio: 14, Epoch 394, Loss: 45.810200\n",
      "SNR Ratio: 14, Epoch 395, Loss: 45.669827\n",
      "SNR Ratio: 14, Epoch 396, Loss: 46.991856\n",
      "SNR Ratio: 14, Epoch 397, Loss: 46.771500\n",
      "SNR Ratio: 14, Epoch 398, Loss: 46.553280\n",
      "SNR Ratio: 14, Epoch 399, Loss: 44.758976\n",
      "SNR Ratio: 14, Epoch 400, Loss: 45.329605\n",
      "SNR Ratio: 14, Epoch 401, Loss: 44.853931\n",
      "SNR Ratio: 14, Epoch 402, Loss: 44.568710\n",
      "SNR Ratio: 14, Epoch 403, Loss: 43.593254\n",
      "SNR Ratio: 14, Epoch 404, Loss: 45.062328\n",
      "SNR Ratio: 14, Epoch 405, Loss: 43.057758\n",
      "SNR Ratio: 14, Epoch 406, Loss: 44.251041\n",
      "SNR Ratio: 14, Epoch 407, Loss: 44.100254\n",
      "SNR Ratio: 14, Epoch 408, Loss: 43.024590\n",
      "SNR Ratio: 14, Epoch 409, Loss: 44.327946\n",
      "SNR Ratio: 14, Epoch 410, Loss: 42.049213\n",
      "SNR Ratio: 14, Epoch 411, Loss: 43.488029\n",
      "SNR Ratio: 14, Epoch 412, Loss: 42.283798\n",
      "SNR Ratio: 14, Epoch 413, Loss: 42.414116\n",
      "SNR Ratio: 14, Epoch 414, Loss: 41.606030\n",
      "SNR Ratio: 14, Epoch 415, Loss: 44.740181\n",
      "SNR Ratio: 14, Epoch 416, Loss: 41.684631\n",
      "SNR Ratio: 14, Epoch 417, Loss: 42.118019\n",
      "SNR Ratio: 14, Epoch 418, Loss: 40.737820\n",
      "SNR Ratio: 14, Epoch 419, Loss: 41.046272\n",
      "SNR Ratio: 14, Epoch 420, Loss: 40.451244\n",
      "SNR Ratio: 14, Epoch 421, Loss: 42.260494\n",
      "SNR Ratio: 14, Epoch 422, Loss: 44.006260\n",
      "SNR Ratio: 14, Epoch 423, Loss: 41.644825\n",
      "SNR Ratio: 14, Epoch 424, Loss: 42.380032\n",
      "SNR Ratio: 14, Epoch 425, Loss: 40.689976\n",
      "SNR Ratio: 14, Epoch 426, Loss: 40.658066\n",
      "SNR Ratio: 14, Epoch 427, Loss: 40.636749\n",
      "SNR Ratio: 14, Epoch 428, Loss: 40.621574\n",
      "SNR Ratio: 14, Epoch 429, Loss: 39.132549\n",
      "SNR Ratio: 14, Epoch 430, Loss: 40.841446\n",
      "SNR Ratio: 14, Epoch 431, Loss: 40.478596\n",
      "SNR Ratio: 14, Epoch 432, Loss: 40.774178\n",
      "SNR Ratio: 14, Epoch 433, Loss: 39.307507\n",
      "SNR Ratio: 14, Epoch 434, Loss: 38.956459\n",
      "SNR Ratio: 14, Epoch 435, Loss: 40.644485\n",
      "SNR Ratio: 14, Epoch 436, Loss: 40.334984\n",
      "SNR Ratio: 14, Epoch 437, Loss: 41.266178\n",
      "SNR Ratio: 14, Epoch 438, Loss: 41.414120\n",
      "SNR Ratio: 14, Epoch 439, Loss: 40.192032\n",
      "SNR Ratio: 14, Epoch 440, Loss: 39.488926\n",
      "SNR Ratio: 14, Epoch 441, Loss: 36.226162\n",
      "SNR Ratio: 14, Epoch 442, Loss: 37.212589\n",
      "SNR Ratio: 14, Epoch 443, Loss: 39.035976\n",
      "SNR Ratio: 14, Epoch 444, Loss: 35.260418\n",
      "SNR Ratio: 14, Epoch 445, Loss: 40.406178\n",
      "SNR Ratio: 14, Epoch 446, Loss: 36.822975\n",
      "SNR Ratio: 14, Epoch 447, Loss: 37.280087\n",
      "SNR Ratio: 14, Epoch 448, Loss: 37.281204\n",
      "SNR Ratio: 14, Epoch 449, Loss: 36.400463\n",
      "SNR Ratio: 14, Epoch 450, Loss: 36.362862\n",
      "SNR Ratio: 14, Epoch 451, Loss: 34.995422\n",
      "SNR Ratio: 14, Epoch 452, Loss: 36.912395\n",
      "SNR Ratio: 14, Epoch 453, Loss: 35.802265\n",
      "SNR Ratio: 14, Epoch 454, Loss: 35.123566\n",
      "SNR Ratio: 14, Epoch 455, Loss: 37.947006\n",
      "SNR Ratio: 14, Epoch 456, Loss: 35.549309\n",
      "SNR Ratio: 14, Epoch 457, Loss: 32.347065\n",
      "SNR Ratio: 14, Epoch 458, Loss: 33.940140\n",
      "SNR Ratio: 14, Epoch 459, Loss: 34.259136\n",
      "SNR Ratio: 14, Epoch 460, Loss: 32.484821\n",
      "SNR Ratio: 14, Epoch 461, Loss: 32.006962\n",
      "SNR Ratio: 14, Epoch 462, Loss: 35.094521\n",
      "SNR Ratio: 14, Epoch 463, Loss: 33.291309\n",
      "SNR Ratio: 14, Epoch 464, Loss: 34.478439\n",
      "SNR Ratio: 14, Epoch 465, Loss: 32.580917\n",
      "SNR Ratio: 14, Epoch 466, Loss: 33.661999\n",
      "SNR Ratio: 14, Epoch 467, Loss: 32.256279\n",
      "SNR Ratio: 14, Epoch 468, Loss: 33.565666\n",
      "SNR Ratio: 14, Epoch 469, Loss: 32.498833\n",
      "SNR Ratio: 14, Epoch 470, Loss: 31.153055\n",
      "SNR Ratio: 14, Epoch 471, Loss: 32.489643\n",
      "SNR Ratio: 14, Epoch 472, Loss: 31.321381\n",
      "SNR Ratio: 14, Epoch 473, Loss: 31.147812\n",
      "SNR Ratio: 14, Epoch 474, Loss: 31.451160\n",
      "SNR Ratio: 14, Epoch 475, Loss: 31.196356\n",
      "SNR Ratio: 14, Epoch 476, Loss: 30.952200\n",
      "SNR Ratio: 14, Epoch 477, Loss: 29.752110\n",
      "SNR Ratio: 14, Epoch 478, Loss: 28.510248\n",
      "SNR Ratio: 14, Epoch 479, Loss: 30.706297\n",
      "SNR Ratio: 14, Epoch 480, Loss: 29.189272\n",
      "SNR Ratio: 14, Epoch 481, Loss: 30.577965\n",
      "SNR Ratio: 14, Epoch 482, Loss: 27.432428\n",
      "SNR Ratio: 14, Epoch 483, Loss: 29.667480\n",
      "SNR Ratio: 14, Epoch 484, Loss: 26.737434\n",
      "SNR Ratio: 14, Epoch 485, Loss: 28.487070\n",
      "SNR Ratio: 14, Epoch 486, Loss: 27.659697\n",
      "SNR Ratio: 14, Epoch 487, Loss: 29.223431\n",
      "SNR Ratio: 14, Epoch 488, Loss: 26.593767\n",
      "SNR Ratio: 14, Epoch 489, Loss: 26.427130\n",
      "SNR Ratio: 14, Epoch 490, Loss: 26.976986\n",
      "SNR Ratio: 14, Epoch 491, Loss: 27.431118\n",
      "SNR Ratio: 14, Epoch 492, Loss: 28.543348\n",
      "SNR Ratio: 14, Epoch 493, Loss: 28.124439\n",
      "SNR Ratio: 14, Epoch 494, Loss: 26.972740\n",
      "SNR Ratio: 14, Epoch 495, Loss: 26.222433\n",
      "SNR Ratio: 14, Epoch 496, Loss: 27.496386\n",
      "SNR Ratio: 14, Epoch 497, Loss: 25.967300\n",
      "SNR Ratio: 14, Epoch 498, Loss: 26.638060\n",
      "SNR Ratio: 14, Epoch 499, Loss: 26.581104\n",
      "SNR Ratio: 14, Epoch 500, Loss: 24.658773\n",
      "SNR Ratio: 14, Epoch 501, Loss: 26.077677\n",
      "SNR Ratio: 14, Epoch 502, Loss: 26.500645\n",
      "SNR Ratio: 14, Epoch 503, Loss: 25.656210\n",
      "SNR Ratio: 14, Epoch 504, Loss: 25.016041\n",
      "SNR Ratio: 14, Epoch 505, Loss: 24.259203\n",
      "SNR Ratio: 14, Epoch 506, Loss: 24.144733\n",
      "SNR Ratio: 14, Epoch 507, Loss: 24.415054\n",
      "SNR Ratio: 14, Epoch 508, Loss: 25.026993\n",
      "SNR Ratio: 14, Epoch 509, Loss: 21.474039\n",
      "SNR Ratio: 14, Epoch 510, Loss: 23.108955\n",
      "SNR Ratio: 14, Epoch 511, Loss: 24.050108\n",
      "SNR Ratio: 14, Epoch 512, Loss: 24.072170\n",
      "SNR Ratio: 14, Epoch 513, Loss: 24.297871\n",
      "SNR Ratio: 14, Epoch 514, Loss: 22.399530\n",
      "SNR Ratio: 14, Epoch 515, Loss: 23.343700\n",
      "SNR Ratio: 14, Epoch 516, Loss: 22.035761\n",
      "SNR Ratio: 14, Epoch 517, Loss: 22.875895\n",
      "SNR Ratio: 14, Epoch 518, Loss: 22.871002\n",
      "SNR Ratio: 14, Epoch 519, Loss: 23.898075\n",
      "SNR Ratio: 14, Epoch 520, Loss: 20.648886\n",
      "SNR Ratio: 14, Epoch 521, Loss: 23.567184\n",
      "SNR Ratio: 14, Epoch 522, Loss: 22.126015\n",
      "SNR Ratio: 14, Epoch 523, Loss: 23.780767\n",
      "SNR Ratio: 14, Epoch 524, Loss: 21.938005\n",
      "SNR Ratio: 14, Epoch 525, Loss: 21.594070\n",
      "SNR Ratio: 14, Epoch 526, Loss: 20.558100\n",
      "SNR Ratio: 14, Epoch 527, Loss: 23.403999\n",
      "SNR Ratio: 14, Epoch 528, Loss: 21.683701\n",
      "SNR Ratio: 14, Epoch 529, Loss: 21.997589\n",
      "SNR Ratio: 14, Epoch 530, Loss: 21.006174\n",
      "SNR Ratio: 14, Epoch 531, Loss: 19.951982\n",
      "SNR Ratio: 14, Epoch 532, Loss: 19.338818\n",
      "SNR Ratio: 14, Epoch 533, Loss: 19.326305\n",
      "SNR Ratio: 14, Epoch 534, Loss: 19.807646\n",
      "SNR Ratio: 14, Epoch 535, Loss: 22.467518\n",
      "SNR Ratio: 14, Epoch 536, Loss: 20.209242\n",
      "SNR Ratio: 14, Epoch 537, Loss: 19.948887\n",
      "SNR Ratio: 14, Epoch 538, Loss: 20.219709\n",
      "SNR Ratio: 14, Epoch 539, Loss: 19.876368\n",
      "SNR Ratio: 14, Epoch 540, Loss: 21.736530\n",
      "SNR Ratio: 14, Epoch 541, Loss: 21.051445\n",
      "SNR Ratio: 14, Epoch 542, Loss: 20.026134\n",
      "SNR Ratio: 14, Epoch 543, Loss: 19.700073\n",
      "SNR Ratio: 14, Epoch 544, Loss: 21.409405\n",
      "SNR Ratio: 14, Epoch 545, Loss: 22.353828\n",
      "SNR Ratio: 14, Epoch 546, Loss: 21.726007\n",
      "SNR Ratio: 14, Epoch 547, Loss: 21.285101\n",
      "SNR Ratio: 14, Epoch 548, Loss: 19.643831\n",
      "SNR Ratio: 14, Epoch 549, Loss: 19.184826\n",
      "SNR Ratio: 14, Epoch 550, Loss: 18.269066\n",
      "SNR Ratio: 14, Epoch 551, Loss: 18.978970\n",
      "SNR Ratio: 14, Epoch 552, Loss: 17.402882\n",
      "SNR Ratio: 14, Epoch 553, Loss: 17.468756\n",
      "SNR Ratio: 14, Epoch 554, Loss: 16.760378\n",
      "SNR Ratio: 14, Epoch 555, Loss: 20.108286\n",
      "SNR Ratio: 14, Epoch 556, Loss: 19.138063\n",
      "SNR Ratio: 14, Epoch 557, Loss: 18.121576\n",
      "SNR Ratio: 14, Epoch 558, Loss: 17.979879\n",
      "SNR Ratio: 14, Epoch 559, Loss: 18.978544\n",
      "SNR Ratio: 14, Epoch 560, Loss: 18.322910\n",
      "SNR Ratio: 14, Epoch 561, Loss: 18.511021\n",
      "SNR Ratio: 14, Epoch 562, Loss: 16.962708\n",
      "SNR Ratio: 14, Epoch 563, Loss: 17.829998\n",
      "SNR Ratio: 14, Epoch 564, Loss: 17.491272\n",
      "SNR Ratio: 14, Epoch 565, Loss: 17.691513\n",
      "SNR Ratio: 14, Epoch 566, Loss: 17.320200\n",
      "SNR Ratio: 14, Epoch 567, Loss: 17.293961\n",
      "SNR Ratio: 14, Epoch 568, Loss: 17.253735\n",
      "SNR Ratio: 14, Epoch 569, Loss: 15.968533\n",
      "SNR Ratio: 14, Epoch 570, Loss: 17.677227\n",
      "SNR Ratio: 14, Epoch 571, Loss: 17.469849\n",
      "SNR Ratio: 14, Epoch 572, Loss: 18.911070\n",
      "SNR Ratio: 14, Epoch 573, Loss: 16.666649\n",
      "SNR Ratio: 14, Epoch 574, Loss: 16.561640\n",
      "SNR Ratio: 14, Epoch 575, Loss: 16.247086\n",
      "SNR Ratio: 14, Epoch 576, Loss: 16.470486\n",
      "SNR Ratio: 14, Epoch 577, Loss: 16.400898\n",
      "SNR Ratio: 14, Epoch 578, Loss: 16.424633\n",
      "SNR Ratio: 14, Epoch 579, Loss: 15.223925\n",
      "SNR Ratio: 14, Epoch 580, Loss: 17.271589\n",
      "SNR Ratio: 14, Epoch 581, Loss: 16.489944\n",
      "SNR Ratio: 14, Epoch 582, Loss: 16.651163\n",
      "SNR Ratio: 14, Epoch 583, Loss: 17.933247\n",
      "SNR Ratio: 14, Epoch 584, Loss: 17.471182\n",
      "SNR Ratio: 14, Epoch 585, Loss: 17.059681\n",
      "SNR Ratio: 14, Epoch 586, Loss: 16.919794\n",
      "SNR Ratio: 14, Epoch 587, Loss: 14.862291\n",
      "SNR Ratio: 14, Epoch 588, Loss: 16.797335\n",
      "SNR Ratio: 14, Epoch 589, Loss: 16.756042\n",
      "SNR Ratio: 14, Epoch 590, Loss: 16.904711\n",
      "SNR Ratio: 14, Epoch 591, Loss: 17.992949\n",
      "SNR Ratio: 14, Epoch 592, Loss: 15.762643\n",
      "SNR Ratio: 14, Epoch 593, Loss: 18.316322\n",
      "SNR Ratio: 14, Epoch 594, Loss: 16.678257\n",
      "SNR Ratio: 14, Epoch 595, Loss: 18.789726\n",
      "SNR Ratio: 14, Epoch 596, Loss: 15.964054\n",
      "SNR Ratio: 14, Epoch 597, Loss: 15.748010\n",
      "SNR Ratio: 14, Epoch 598, Loss: 15.387841\n",
      "SNR Ratio: 14, Epoch 599, Loss: 15.150397\n",
      "SNR Ratio: 14, Epoch 600, Loss: 15.257884\n",
      "SNR Ratio: 14, Epoch 601, Loss: 15.468085\n",
      "SNR Ratio: 14, Epoch 602, Loss: 15.456130\n",
      "SNR Ratio: 14, Epoch 603, Loss: 16.404112\n",
      "SNR Ratio: 14, Epoch 604, Loss: 14.880540\n",
      "SNR Ratio: 14, Epoch 605, Loss: 15.574582\n",
      "SNR Ratio: 14, Epoch 606, Loss: 14.133925\n",
      "SNR Ratio: 14, Epoch 607, Loss: 15.029813\n",
      "SNR Ratio: 14, Epoch 608, Loss: 16.594938\n",
      "SNR Ratio: 14, Epoch 609, Loss: 15.080478\n",
      "SNR Ratio: 14, Epoch 610, Loss: 15.626147\n",
      "SNR Ratio: 14, Epoch 611, Loss: 14.648977\n",
      "SNR Ratio: 14, Epoch 612, Loss: 16.213831\n",
      "SNR Ratio: 14, Epoch 613, Loss: 15.350142\n",
      "SNR Ratio: 14, Epoch 614, Loss: 14.384645\n",
      "SNR Ratio: 14, Epoch 615, Loss: 14.869629\n",
      "SNR Ratio: 14, Epoch 616, Loss: 14.226571\n",
      "SNR Ratio: 14, Epoch 617, Loss: 13.763103\n",
      "SNR Ratio: 14, Epoch 618, Loss: 15.879652\n",
      "SNR Ratio: 14, Epoch 619, Loss: 17.126797\n",
      "SNR Ratio: 14, Epoch 620, Loss: 14.956405\n",
      "SNR Ratio: 14, Epoch 621, Loss: 15.512660\n",
      "SNR Ratio: 14, Epoch 622, Loss: 15.111752\n",
      "SNR Ratio: 14, Epoch 623, Loss: 13.508890\n",
      "SNR Ratio: 14, Epoch 624, Loss: 13.366857\n",
      "SNR Ratio: 14, Epoch 625, Loss: 15.166031\n",
      "SNR Ratio: 14, Epoch 626, Loss: 16.479288\n",
      "SNR Ratio: 14, Epoch 627, Loss: 14.177285\n",
      "SNR Ratio: 14, Epoch 628, Loss: 12.886955\n",
      "SNR Ratio: 14, Epoch 629, Loss: 14.413478\n",
      "SNR Ratio: 14, Epoch 630, Loss: 14.717422\n",
      "SNR Ratio: 14, Epoch 631, Loss: 14.896088\n",
      "SNR Ratio: 14, Epoch 632, Loss: 14.486617\n",
      "SNR Ratio: 14, Epoch 633, Loss: 15.179568\n",
      "SNR Ratio: 14, Epoch 634, Loss: 13.136027\n",
      "SNR Ratio: 14, Epoch 635, Loss: 14.642492\n",
      "SNR Ratio: 14, Epoch 636, Loss: 14.653825\n",
      "SNR Ratio: 14, Epoch 637, Loss: 13.593259\n",
      "SNR Ratio: 14, Epoch 638, Loss: 15.124440\n",
      "SNR Ratio: 14, Epoch 639, Loss: 14.077494\n",
      "SNR Ratio: 14, Epoch 640, Loss: 14.127418\n",
      "SNR Ratio: 14, Epoch 641, Loss: 14.575797\n",
      "SNR Ratio: 14, Epoch 642, Loss: 14.025435\n",
      "SNR Ratio: 14, Epoch 643, Loss: 13.905185\n",
      "SNR Ratio: 14, Epoch 644, Loss: 14.693330\n",
      "SNR Ratio: 14, Epoch 645, Loss: 13.742578\n",
      "SNR Ratio: 14, Epoch 646, Loss: 14.521832\n",
      "SNR Ratio: 14, Epoch 647, Loss: 13.785245\n",
      "SNR Ratio: 14, Epoch 648, Loss: 14.847911\n",
      "SNR Ratio: 14, Epoch 649, Loss: 14.303658\n",
      "SNR Ratio: 14, Epoch 650, Loss: 14.122824\n",
      "SNR Ratio: 14, Epoch 651, Loss: 14.096698\n",
      "SNR Ratio: 14, Epoch 652, Loss: 13.064730\n",
      "SNR Ratio: 14, Epoch 653, Loss: 13.467447\n",
      "SNR Ratio: 14, Epoch 654, Loss: 13.773778\n",
      "SNR Ratio: 14, Epoch 655, Loss: 14.473515\n",
      "SNR Ratio: 14, Epoch 656, Loss: 12.541210\n",
      "SNR Ratio: 14, Epoch 657, Loss: 13.837008\n",
      "SNR Ratio: 14, Epoch 658, Loss: 12.358244\n",
      "SNR Ratio: 14, Epoch 659, Loss: 12.669912\n",
      "SNR Ratio: 14, Epoch 660, Loss: 14.887282\n",
      "SNR Ratio: 14, Epoch 661, Loss: 13.709765\n",
      "SNR Ratio: 14, Epoch 662, Loss: 13.387385\n",
      "SNR Ratio: 14, Epoch 663, Loss: 12.669444\n",
      "SNR Ratio: 14, Epoch 664, Loss: 14.608255\n",
      "SNR Ratio: 14, Epoch 665, Loss: 13.620262\n",
      "SNR Ratio: 14, Epoch 666, Loss: 11.824315\n",
      "SNR Ratio: 14, Epoch 667, Loss: 11.448343\n",
      "SNR Ratio: 14, Epoch 668, Loss: 11.856969\n",
      "SNR Ratio: 14, Epoch 669, Loss: 15.542400\n",
      "SNR Ratio: 14, Epoch 670, Loss: 15.242838\n",
      "SNR Ratio: 14, Epoch 671, Loss: 14.990310\n",
      "SNR Ratio: 14, Epoch 672, Loss: 12.971684\n",
      "SNR Ratio: 14, Epoch 673, Loss: 13.877103\n",
      "SNR Ratio: 14, Epoch 674, Loss: 14.361168\n",
      "SNR Ratio: 14, Epoch 675, Loss: 13.427385\n",
      "SNR Ratio: 14, Epoch 676, Loss: 13.591319\n",
      "SNR Ratio: 14, Epoch 677, Loss: 13.598265\n",
      "SNR Ratio: 14, Epoch 678, Loss: 12.591026\n",
      "SNR Ratio: 14, Epoch 679, Loss: 12.396975\n",
      "SNR Ratio: 14, Epoch 680, Loss: 13.364900\n",
      "SNR Ratio: 14, Epoch 681, Loss: 13.121453\n",
      "SNR Ratio: 14, Epoch 682, Loss: 12.619011\n",
      "SNR Ratio: 14, Epoch 683, Loss: 13.046645\n",
      "SNR Ratio: 14, Epoch 684, Loss: 12.884691\n",
      "SNR Ratio: 14, Epoch 685, Loss: 13.807596\n",
      "SNR Ratio: 14, Epoch 686, Loss: 13.503995\n",
      "SNR Ratio: 14, Epoch 687, Loss: 12.619423\n",
      "SNR Ratio: 14, Epoch 688, Loss: 11.075850\n",
      "SNR Ratio: 14, Epoch 689, Loss: 13.150410\n",
      "SNR Ratio: 14, Epoch 690, Loss: 12.077207\n",
      "SNR Ratio: 14, Epoch 691, Loss: 12.487268\n",
      "SNR Ratio: 14, Epoch 692, Loss: 14.240738\n",
      "SNR Ratio: 14, Epoch 693, Loss: 12.138726\n",
      "SNR Ratio: 14, Epoch 694, Loss: 13.676260\n",
      "SNR Ratio: 14, Epoch 695, Loss: 13.568275\n",
      "SNR Ratio: 14, Epoch 696, Loss: 11.737711\n",
      "SNR Ratio: 14, Epoch 697, Loss: 11.988217\n",
      "SNR Ratio: 14, Epoch 698, Loss: 11.622157\n",
      "SNR Ratio: 14, Epoch 699, Loss: 12.489347\n",
      "SNR Ratio: 14, Epoch 700, Loss: 13.312491\n",
      "SNR Ratio: 14, Epoch 701, Loss: 13.081024\n",
      "SNR Ratio: 14, Epoch 702, Loss: 12.849584\n",
      "SNR Ratio: 14, Epoch 703, Loss: 11.882677\n",
      "SNR Ratio: 14, Epoch 704, Loss: 13.440350\n",
      "SNR Ratio: 14, Epoch 705, Loss: 11.690243\n",
      "SNR Ratio: 14, Epoch 706, Loss: 11.928655\n",
      "SNR Ratio: 14, Epoch 707, Loss: 11.259317\n",
      "SNR Ratio: 14, Epoch 708, Loss: 12.861708\n",
      "SNR Ratio: 14, Epoch 709, Loss: 13.844453\n",
      "SNR Ratio: 14, Epoch 710, Loss: 12.820151\n",
      "SNR Ratio: 14, Epoch 711, Loss: 12.276379\n",
      "SNR Ratio: 14, Epoch 712, Loss: 11.948768\n",
      "SNR Ratio: 14, Epoch 713, Loss: 12.567912\n",
      "SNR Ratio: 14, Epoch 714, Loss: 12.783735\n",
      "SNR Ratio: 14, Epoch 715, Loss: 14.143996\n",
      "SNR Ratio: 14, Epoch 716, Loss: 13.612880\n",
      "SNR Ratio: 14, Epoch 717, Loss: 13.746324\n",
      "SNR Ratio: 14, Epoch 718, Loss: 12.425986\n",
      "SNR Ratio: 14, Epoch 719, Loss: 12.813233\n",
      "SNR Ratio: 14, Epoch 720, Loss: 12.120087\n",
      "SNR Ratio: 14, Epoch 721, Loss: 12.706940\n",
      "SNR Ratio: 14, Epoch 722, Loss: 11.791617\n",
      "SNR Ratio: 14, Epoch 723, Loss: 12.379828\n",
      "SNR Ratio: 14, Epoch 724, Loss: 12.301655\n",
      "SNR Ratio: 14, Epoch 725, Loss: 13.543489\n",
      "SNR Ratio: 14, Epoch 726, Loss: 11.750427\n",
      "SNR Ratio: 14, Epoch 727, Loss: 11.413534\n",
      "SNR Ratio: 14, Epoch 728, Loss: 11.123456\n",
      "SNR Ratio: 14, Epoch 729, Loss: 12.245687\n",
      "SNR Ratio: 14, Epoch 730, Loss: 11.063131\n",
      "SNR Ratio: 14, Epoch 731, Loss: 11.638091\n",
      "SNR Ratio: 14, Epoch 732, Loss: 10.280543\n",
      "SNR Ratio: 14, Epoch 733, Loss: 11.990177\n",
      "SNR Ratio: 14, Epoch 734, Loss: 11.760971\n",
      "SNR Ratio: 14, Epoch 735, Loss: 11.626146\n",
      "SNR Ratio: 14, Epoch 736, Loss: 11.298218\n",
      "SNR Ratio: 14, Epoch 737, Loss: 14.634272\n",
      "SNR Ratio: 14, Epoch 738, Loss: 13.150888\n",
      "SNR Ratio: 14, Epoch 739, Loss: 11.291029\n",
      "SNR Ratio: 14, Epoch 740, Loss: 10.085280\n",
      "SNR Ratio: 14, Epoch 741, Loss: 12.545177\n",
      "SNR Ratio: 14, Epoch 742, Loss: 11.902667\n",
      "SNR Ratio: 14, Epoch 743, Loss: 12.947613\n",
      "SNR Ratio: 14, Epoch 744, Loss: 12.257775\n",
      "SNR Ratio: 14, Epoch 745, Loss: 12.649975\n",
      "SNR Ratio: 14, Epoch 746, Loss: 10.696411\n",
      "SNR Ratio: 14, Epoch 747, Loss: 13.287025\n",
      "SNR Ratio: 14, Epoch 748, Loss: 11.559985\n",
      "SNR Ratio: 14, Epoch 749, Loss: 11.968379\n",
      "SNR Ratio: 14, Epoch 750, Loss: 13.822871\n",
      "SNR Ratio: 14, Epoch 751, Loss: 12.291605\n",
      "SNR Ratio: 14, Epoch 752, Loss: 12.460523\n",
      "SNR Ratio: 14, Epoch 753, Loss: 10.977677\n",
      "SNR Ratio: 14, Epoch 754, Loss: 10.789230\n",
      "SNR Ratio: 14, Epoch 755, Loss: 11.358892\n",
      "SNR Ratio: 14, Epoch 756, Loss: 11.199133\n",
      "SNR Ratio: 14, Epoch 757, Loss: 14.170213\n",
      "SNR Ratio: 14, Epoch 758, Loss: 13.609524\n",
      "SNR Ratio: 14, Epoch 759, Loss: 12.089790\n",
      "SNR Ratio: 14, Epoch 760, Loss: 11.556063\n",
      "SNR Ratio: 14, Epoch 761, Loss: 12.216698\n",
      "SNR Ratio: 14, Epoch 762, Loss: 10.824002\n",
      "SNR Ratio: 14, Epoch 763, Loss: 12.646600\n",
      "SNR Ratio: 14, Epoch 764, Loss: 12.976316\n",
      "SNR Ratio: 14, Epoch 765, Loss: 11.446049\n",
      "SNR Ratio: 14, Epoch 766, Loss: 12.860613\n",
      "SNR Ratio: 14, Epoch 767, Loss: 11.202867\n",
      "SNR Ratio: 14, Epoch 768, Loss: 11.120423\n",
      "SNR Ratio: 14, Epoch 769, Loss: 13.521240\n",
      "SNR Ratio: 14, Epoch 770, Loss: 13.147867\n",
      "SNR Ratio: 14, Epoch 771, Loss: 10.042336\n",
      "SNR Ratio: 14, Epoch 772, Loss: 12.203815\n",
      "SNR Ratio: 14, Epoch 773, Loss: 10.469648\n",
      "SNR Ratio: 14, Epoch 774, Loss: 12.166452\n",
      "SNR Ratio: 14, Epoch 775, Loss: 11.302974\n",
      "SNR Ratio: 14, Epoch 776, Loss: 13.600450\n",
      "SNR Ratio: 14, Epoch 777, Loss: 12.664277\n",
      "SNR Ratio: 14, Epoch 778, Loss: 12.257724\n",
      "SNR Ratio: 14, Epoch 779, Loss: 11.257393\n",
      "SNR Ratio: 14, Epoch 780, Loss: 10.038294\n",
      "SNR Ratio: 14, Epoch 781, Loss: 12.115043\n",
      "SNR Ratio: 14, Epoch 782, Loss: 12.026347\n",
      "SNR Ratio: 14, Epoch 783, Loss: 11.257072\n",
      "SNR Ratio: 14, Epoch 784, Loss: 12.111519\n",
      "SNR Ratio: 14, Epoch 785, Loss: 10.711702\n",
      "SNR Ratio: 14, Epoch 786, Loss: 11.283705\n",
      "SNR Ratio: 14, Epoch 787, Loss: 11.735329\n",
      "SNR Ratio: 14, Epoch 788, Loss: 11.111282\n",
      "SNR Ratio: 14, Epoch 789, Loss: 11.349304\n",
      "SNR Ratio: 14, Epoch 790, Loss: 10.216201\n",
      "SNR Ratio: 14, Epoch 791, Loss: 10.979169\n",
      "SNR Ratio: 14, Epoch 792, Loss: 10.769761\n",
      "SNR Ratio: 14, Epoch 793, Loss: 11.078181\n",
      "SNR Ratio: 14, Epoch 794, Loss: 11.241630\n",
      "SNR Ratio: 14, Epoch 795, Loss: 9.977537\n",
      "SNR Ratio: 14, Epoch 796, Loss: 10.893252\n",
      "SNR Ratio: 14, Epoch 797, Loss: 12.295460\n",
      "SNR Ratio: 14, Epoch 798, Loss: 11.040610\n",
      "SNR Ratio: 14, Epoch 799, Loss: 11.733970\n",
      "SNR Ratio: 14, Epoch 800, Loss: 12.209689\n",
      "SNR Ratio: 14, Epoch 801, Loss: 11.085503\n",
      "SNR Ratio: 14, Epoch 802, Loss: 12.434850\n",
      "SNR Ratio: 14, Epoch 803, Loss: 10.749058\n",
      "SNR Ratio: 14, Epoch 804, Loss: 10.988925\n",
      "SNR Ratio: 14, Epoch 805, Loss: 11.011381\n",
      "SNR Ratio: 14, Epoch 806, Loss: 11.570044\n",
      "SNR Ratio: 14, Epoch 807, Loss: 11.559703\n",
      "SNR Ratio: 14, Epoch 808, Loss: 10.665483\n",
      "SNR Ratio: 14, Epoch 809, Loss: 9.779026\n",
      "SNR Ratio: 14, Epoch 810, Loss: 10.777528\n",
      "SNR Ratio: 14, Epoch 811, Loss: 10.399567\n",
      "SNR Ratio: 14, Epoch 812, Loss: 10.831113\n",
      "SNR Ratio: 14, Epoch 813, Loss: 10.376504\n",
      "SNR Ratio: 14, Epoch 814, Loss: 11.180847\n",
      "SNR Ratio: 14, Epoch 815, Loss: 11.839716\n",
      "SNR Ratio: 14, Epoch 816, Loss: 10.862488\n",
      "SNR Ratio: 14, Epoch 817, Loss: 11.801208\n",
      "SNR Ratio: 14, Epoch 818, Loss: 11.637940\n",
      "SNR Ratio: 14, Epoch 819, Loss: 13.642804\n",
      "SNR Ratio: 14, Epoch 820, Loss: 11.644640\n",
      "SNR Ratio: 14, Epoch 821, Loss: 10.602640\n",
      "SNR Ratio: 14, Epoch 822, Loss: 10.776065\n",
      "SNR Ratio: 14, Epoch 823, Loss: 11.535222\n",
      "SNR Ratio: 14, Epoch 824, Loss: 11.737693\n",
      "SNR Ratio: 14, Epoch 825, Loss: 12.630926\n",
      "SNR Ratio: 14, Epoch 826, Loss: 11.457277\n",
      "SNR Ratio: 14, Epoch 827, Loss: 10.257565\n",
      "SNR Ratio: 14, Epoch 828, Loss: 11.530329\n",
      "SNR Ratio: 14, Epoch 829, Loss: 10.426346\n",
      "SNR Ratio: 14, Epoch 830, Loss: 10.861724\n",
      "SNR Ratio: 14, Epoch 831, Loss: 10.756681\n",
      "SNR Ratio: 14, Epoch 832, Loss: 11.286380\n",
      "SNR Ratio: 14, Epoch 833, Loss: 12.539474\n",
      "SNR Ratio: 14, Epoch 834, Loss: 12.315042\n",
      "SNR Ratio: 14, Epoch 835, Loss: 11.851001\n",
      "SNR Ratio: 14, Epoch 836, Loss: 10.353553\n",
      "SNR Ratio: 14, Epoch 837, Loss: 10.762649\n",
      "SNR Ratio: 14, Epoch 838, Loss: 11.032550\n",
      "SNR Ratio: 14, Epoch 839, Loss: 10.219992\n",
      "SNR Ratio: 14, Epoch 840, Loss: 10.035678\n",
      "SNR Ratio: 14, Epoch 841, Loss: 9.963572\n",
      "SNR Ratio: 14, Epoch 842, Loss: 11.471050\n",
      "SNR Ratio: 14, Epoch 843, Loss: 13.006626\n",
      "SNR Ratio: 14, Epoch 844, Loss: 10.618471\n",
      "SNR Ratio: 14, Epoch 845, Loss: 11.301413\n",
      "SNR Ratio: 14, Epoch 846, Loss: 11.123273\n",
      "SNR Ratio: 14, Epoch 847, Loss: 10.894610\n",
      "SNR Ratio: 14, Epoch 848, Loss: 10.655225\n",
      "SNR Ratio: 14, Epoch 849, Loss: 10.316172\n",
      "SNR Ratio: 14, Epoch 850, Loss: 10.507648\n",
      "SNR Ratio: 14, Epoch 851, Loss: 10.820562\n",
      "SNR Ratio: 14, Epoch 852, Loss: 9.512657\n",
      "SNR Ratio: 14, Epoch 853, Loss: 11.402320\n",
      "SNR Ratio: 14, Epoch 854, Loss: 10.462518\n",
      "SNR Ratio: 14, Epoch 855, Loss: 9.655399\n",
      "SNR Ratio: 14, Epoch 856, Loss: 10.895050\n",
      "SNR Ratio: 14, Epoch 857, Loss: 11.138367\n",
      "SNR Ratio: 14, Epoch 858, Loss: 11.125028\n",
      "SNR Ratio: 14, Epoch 859, Loss: 11.745684\n",
      "SNR Ratio: 14, Epoch 860, Loss: 11.885125\n",
      "SNR Ratio: 14, Epoch 861, Loss: 11.408440\n",
      "SNR Ratio: 14, Epoch 862, Loss: 10.519697\n",
      "SNR Ratio: 14, Epoch 863, Loss: 13.567723\n",
      "SNR Ratio: 14, Epoch 864, Loss: 12.457340\n",
      "SNR Ratio: 14, Epoch 865, Loss: 12.740240\n",
      "SNR Ratio: 14, Epoch 866, Loss: 13.284713\n",
      "SNR Ratio: 14, Epoch 867, Loss: 12.387643\n",
      "SNR Ratio: 14, Epoch 868, Loss: 12.551747\n",
      "SNR Ratio: 14, Epoch 869, Loss: 11.892708\n",
      "SNR Ratio: 14, Epoch 870, Loss: 11.367438\n",
      "SNR Ratio: 14, Epoch 871, Loss: 10.532047\n",
      "SNR Ratio: 14, Epoch 872, Loss: 11.083306\n",
      "SNR Ratio: 14, Epoch 873, Loss: 11.071983\n",
      "SNR Ratio: 14, Epoch 874, Loss: 10.126266\n",
      "SNR Ratio: 14, Epoch 875, Loss: 11.350245\n",
      "SNR Ratio: 14, Epoch 876, Loss: 11.523445\n",
      "SNR Ratio: 14, Epoch 877, Loss: 11.323555\n",
      "SNR Ratio: 14, Epoch 878, Loss: 10.180757\n",
      "SNR Ratio: 14, Epoch 879, Loss: 9.924306\n",
      "SNR Ratio: 14, Epoch 880, Loss: 11.331069\n",
      "SNR Ratio: 14, Epoch 881, Loss: 10.321960\n",
      "SNR Ratio: 14, Epoch 882, Loss: 11.077881\n",
      "SNR Ratio: 14, Epoch 883, Loss: 10.583170\n",
      "SNR Ratio: 14, Epoch 884, Loss: 12.283270\n",
      "SNR Ratio: 14, Epoch 885, Loss: 10.161009\n",
      "SNR Ratio: 14, Epoch 886, Loss: 10.978841\n",
      "SNR Ratio: 14, Epoch 887, Loss: 10.783459\n",
      "SNR Ratio: 14, Epoch 888, Loss: 9.497084\n",
      "SNR Ratio: 14, Epoch 889, Loss: 11.713764\n",
      "SNR Ratio: 14, Epoch 890, Loss: 10.414739\n",
      "SNR Ratio: 14, Epoch 891, Loss: 9.263208\n",
      "SNR Ratio: 14, Epoch 892, Loss: 11.105220\n",
      "SNR Ratio: 14, Epoch 893, Loss: 9.935096\n",
      "SNR Ratio: 14, Epoch 894, Loss: 9.915363\n",
      "SNR Ratio: 14, Epoch 895, Loss: 11.464300\n",
      "SNR Ratio: 14, Epoch 896, Loss: 9.992145\n",
      "SNR Ratio: 14, Epoch 897, Loss: 12.041294\n",
      "SNR Ratio: 14, Epoch 898, Loss: 11.418450\n",
      "SNR Ratio: 14, Epoch 899, Loss: 10.578479\n",
      "SNR Ratio: 14, Epoch 900, Loss: 10.035357\n",
      "SNR Ratio: 14, Epoch 901, Loss: 10.475338\n",
      "SNR Ratio: 14, Epoch 902, Loss: 9.556877\n",
      "SNR Ratio: 14, Epoch 903, Loss: 9.032282\n",
      "SNR Ratio: 14, Epoch 904, Loss: 9.392967\n",
      "SNR Ratio: 14, Epoch 905, Loss: 10.171112\n",
      "SNR Ratio: 14, Epoch 906, Loss: 12.005631\n",
      "SNR Ratio: 14, Epoch 907, Loss: 10.736695\n",
      "SNR Ratio: 14, Epoch 908, Loss: 11.530098\n",
      "SNR Ratio: 14, Epoch 909, Loss: 11.446056\n",
      "SNR Ratio: 14, Epoch 910, Loss: 10.301965\n",
      "SNR Ratio: 14, Epoch 911, Loss: 11.059620\n",
      "SNR Ratio: 14, Epoch 912, Loss: 9.973110\n",
      "SNR Ratio: 14, Epoch 913, Loss: 10.149954\n",
      "SNR Ratio: 14, Epoch 914, Loss: 11.366510\n",
      "SNR Ratio: 14, Epoch 915, Loss: 10.869858\n",
      "SNR Ratio: 14, Epoch 916, Loss: 11.810960\n",
      "SNR Ratio: 14, Epoch 917, Loss: 10.061910\n",
      "SNR Ratio: 14, Epoch 918, Loss: 12.346229\n",
      "SNR Ratio: 14, Epoch 919, Loss: 9.917169\n",
      "SNR Ratio: 14, Epoch 920, Loss: 9.126606\n",
      "SNR Ratio: 14, Epoch 921, Loss: 10.564612\n",
      "SNR Ratio: 14, Epoch 922, Loss: 9.886361\n",
      "SNR Ratio: 14, Epoch 923, Loss: 11.606008\n",
      "SNR Ratio: 14, Epoch 924, Loss: 11.041775\n",
      "SNR Ratio: 14, Epoch 925, Loss: 12.446185\n",
      "SNR Ratio: 14, Epoch 926, Loss: 10.419867\n",
      "SNR Ratio: 14, Epoch 927, Loss: 9.926439\n",
      "SNR Ratio: 14, Epoch 928, Loss: 10.020315\n",
      "SNR Ratio: 14, Epoch 929, Loss: 8.663174\n",
      "SNR Ratio: 14, Epoch 930, Loss: 10.297639\n",
      "SNR Ratio: 14, Epoch 931, Loss: 11.186228\n",
      "SNR Ratio: 14, Epoch 932, Loss: 10.676759\n",
      "SNR Ratio: 14, Epoch 933, Loss: 10.779875\n",
      "SNR Ratio: 14, Epoch 934, Loss: 10.411951\n",
      "SNR Ratio: 14, Epoch 935, Loss: 9.183749\n",
      "SNR Ratio: 14, Epoch 936, Loss: 10.183353\n",
      "SNR Ratio: 14, Epoch 937, Loss: 11.335755\n",
      "SNR Ratio: 14, Epoch 938, Loss: 10.438516\n",
      "SNR Ratio: 14, Epoch 939, Loss: 11.042908\n",
      "SNR Ratio: 14, Epoch 940, Loss: 9.581236\n",
      "SNR Ratio: 14, Epoch 941, Loss: 11.100303\n",
      "SNR Ratio: 14, Epoch 942, Loss: 11.303770\n",
      "SNR Ratio: 14, Epoch 943, Loss: 11.128087\n",
      "SNR Ratio: 14, Epoch 944, Loss: 11.989826\n",
      "SNR Ratio: 14, Epoch 945, Loss: 10.823543\n",
      "SNR Ratio: 14, Epoch 946, Loss: 12.441084\n",
      "SNR Ratio: 14, Epoch 947, Loss: 10.265870\n",
      "SNR Ratio: 14, Epoch 948, Loss: 11.446498\n",
      "SNR Ratio: 14, Epoch 949, Loss: 11.171281\n",
      "SNR Ratio: 14, Epoch 950, Loss: 10.952915\n",
      "SNR Ratio: 14, Epoch 951, Loss: 11.753131\n",
      "SNR Ratio: 14, Epoch 952, Loss: 11.405296\n",
      "SNR Ratio: 14, Epoch 953, Loss: 11.545775\n",
      "SNR Ratio: 14, Epoch 954, Loss: 10.989053\n",
      "SNR Ratio: 14, Epoch 955, Loss: 10.406092\n",
      "SNR Ratio: 14, Epoch 956, Loss: 12.757172\n",
      "SNR Ratio: 14, Epoch 957, Loss: 11.441489\n",
      "SNR Ratio: 14, Epoch 958, Loss: 8.886279\n",
      "SNR Ratio: 14, Epoch 959, Loss: 10.300378\n",
      "SNR Ratio: 14, Epoch 960, Loss: 11.211867\n",
      "SNR Ratio: 14, Epoch 961, Loss: 11.216070\n",
      "SNR Ratio: 14, Epoch 962, Loss: 10.645859\n",
      "SNR Ratio: 14, Epoch 963, Loss: 10.572935\n",
      "SNR Ratio: 14, Epoch 964, Loss: 10.169943\n",
      "SNR Ratio: 14, Epoch 965, Loss: 11.127145\n",
      "SNR Ratio: 14, Epoch 966, Loss: 10.089531\n",
      "SNR Ratio: 14, Epoch 967, Loss: 9.580295\n",
      "SNR Ratio: 14, Epoch 968, Loss: 10.339741\n",
      "SNR Ratio: 14, Epoch 969, Loss: 11.254703\n",
      "SNR Ratio: 14, Epoch 970, Loss: 9.241960\n",
      "SNR Ratio: 14, Epoch 971, Loss: 9.369449\n",
      "SNR Ratio: 14, Epoch 972, Loss: 10.442829\n",
      "SNR Ratio: 14, Epoch 973, Loss: 9.666251\n",
      "SNR Ratio: 14, Epoch 974, Loss: 11.188684\n",
      "SNR Ratio: 14, Epoch 975, Loss: 12.403357\n",
      "SNR Ratio: 14, Epoch 976, Loss: 10.669147\n",
      "SNR Ratio: 14, Epoch 977, Loss: 12.329482\n",
      "SNR Ratio: 14, Epoch 978, Loss: 11.823685\n",
      "SNR Ratio: 14, Epoch 979, Loss: 9.841895\n",
      "SNR Ratio: 14, Epoch 980, Loss: 9.300325\n",
      "SNR Ratio: 14, Epoch 981, Loss: 11.110417\n",
      "SNR Ratio: 14, Epoch 982, Loss: 9.617872\n",
      "SNR Ratio: 14, Epoch 983, Loss: 10.349431\n",
      "SNR Ratio: 14, Epoch 984, Loss: 10.537398\n",
      "SNR Ratio: 14, Epoch 985, Loss: 9.797278\n",
      "SNR Ratio: 14, Epoch 986, Loss: 9.646091\n",
      "SNR Ratio: 14, Epoch 987, Loss: 9.116943\n",
      "SNR Ratio: 14, Epoch 988, Loss: 10.092261\n",
      "SNR Ratio: 14, Epoch 989, Loss: 10.510748\n",
      "SNR Ratio: 14, Epoch 990, Loss: 12.582265\n",
      "SNR Ratio: 14, Epoch 991, Loss: 11.429354\n",
      "SNR Ratio: 14, Epoch 992, Loss: 9.596398\n",
      "SNR Ratio: 14, Epoch 993, Loss: 10.482490\n",
      "SNR Ratio: 14, Epoch 994, Loss: 11.662999\n",
      "SNR Ratio: 14, Epoch 995, Loss: 10.621461\n",
      "SNR Ratio: 14, Epoch 996, Loss: 10.407645\n",
      "SNR Ratio: 14, Epoch 997, Loss: 9.860229\n",
      "SNR Ratio: 14, Epoch 998, Loss: 10.603315\n",
      "SNR Ratio: 14, Epoch 999, Loss: 10.878405\n",
      "SNR Ratio: 14, Epoch 1000, Loss: 11.125160\n",
      "SNR Ratio: 14, Epoch 1001, Loss: 9.716536\n",
      "SNR Ratio: 14, Epoch 1002, Loss: 9.681775\n",
      "SNR Ratio: 14, Epoch 1003, Loss: 10.526721\n",
      "SNR Ratio: 14, Epoch 1004, Loss: 9.230377\n",
      "SNR Ratio: 14, Epoch 1005, Loss: 9.087085\n",
      "SNR Ratio: 14, Epoch 1006, Loss: 10.175440\n",
      "SNR Ratio: 14, Epoch 1007, Loss: 10.406410\n",
      "SNR Ratio: 14, Epoch 1008, Loss: 10.361008\n",
      "SNR Ratio: 14, Epoch 1009, Loss: 11.030979\n",
      "SNR Ratio: 14, Epoch 1010, Loss: 9.716078\n",
      "SNR Ratio: 14, Epoch 1011, Loss: 10.477484\n",
      "SNR Ratio: 14, Epoch 1012, Loss: 11.193185\n",
      "SNR Ratio: 14, Epoch 1013, Loss: 10.471203\n",
      "SNR Ratio: 14, Epoch 1014, Loss: 10.449807\n",
      "SNR Ratio: 14, Epoch 1015, Loss: 11.560677\n",
      "SNR Ratio: 14, Epoch 1016, Loss: 11.465207\n",
      "SNR Ratio: 14, Epoch 1017, Loss: 10.736695\n",
      "SNR Ratio: 14, Epoch 1018, Loss: 9.690701\n",
      "SNR Ratio: 14, Epoch 1019, Loss: 10.343845\n",
      "SNR Ratio: 14, Epoch 1020, Loss: 9.847759\n",
      "SNR Ratio: 14, Epoch 1021, Loss: 10.704096\n",
      "SNR Ratio: 14, Epoch 1022, Loss: 9.531190\n",
      "SNR Ratio: 14, Epoch 1023, Loss: 9.857447\n",
      "SNR Ratio: 14, Epoch 1024, Loss: 10.225352\n",
      "SNR Ratio: 14, Epoch 1025, Loss: 11.168865\n",
      "SNR Ratio: 14, Epoch 1026, Loss: 9.344213\n",
      "SNR Ratio: 14, Epoch 1027, Loss: 10.486133\n",
      "SNR Ratio: 14, Epoch 1028, Loss: 9.803345\n",
      "SNR Ratio: 14, Epoch 1029, Loss: 9.339912\n",
      "Stopped early after 1030 epochs, with loss 8.663174\n",
      "SNR Ratio: 17, Epoch 1, Loss: 330.167267\n",
      "SNR Ratio: 17, Epoch 2, Loss: 321.550873\n",
      "SNR Ratio: 17, Epoch 3, Loss: 300.975372\n",
      "SNR Ratio: 17, Epoch 4, Loss: 270.595734\n",
      "SNR Ratio: 17, Epoch 5, Loss: 244.364044\n",
      "SNR Ratio: 17, Epoch 6, Loss: 216.566574\n",
      "SNR Ratio: 17, Epoch 7, Loss: 192.022476\n",
      "SNR Ratio: 17, Epoch 8, Loss: 179.574844\n",
      "SNR Ratio: 17, Epoch 9, Loss: 164.937225\n",
      "SNR Ratio: 17, Epoch 10, Loss: 157.164062\n",
      "SNR Ratio: 17, Epoch 11, Loss: 148.472244\n",
      "SNR Ratio: 17, Epoch 12, Loss: 141.384689\n",
      "SNR Ratio: 17, Epoch 13, Loss: 138.937332\n",
      "SNR Ratio: 17, Epoch 14, Loss: 131.931564\n",
      "SNR Ratio: 17, Epoch 15, Loss: 129.007126\n",
      "SNR Ratio: 17, Epoch 16, Loss: 127.133820\n",
      "SNR Ratio: 17, Epoch 17, Loss: 121.965797\n",
      "SNR Ratio: 17, Epoch 18, Loss: 116.666039\n",
      "SNR Ratio: 17, Epoch 19, Loss: 114.438637\n",
      "SNR Ratio: 17, Epoch 20, Loss: 113.166908\n",
      "SNR Ratio: 17, Epoch 21, Loss: 114.285316\n",
      "SNR Ratio: 17, Epoch 22, Loss: 112.934753\n",
      "SNR Ratio: 17, Epoch 23, Loss: 109.200943\n",
      "SNR Ratio: 17, Epoch 24, Loss: 107.821159\n",
      "SNR Ratio: 17, Epoch 25, Loss: 109.026894\n",
      "SNR Ratio: 17, Epoch 26, Loss: 109.334000\n",
      "SNR Ratio: 17, Epoch 27, Loss: 103.338699\n",
      "SNR Ratio: 17, Epoch 28, Loss: 103.775902\n",
      "SNR Ratio: 17, Epoch 29, Loss: 102.885368\n",
      "SNR Ratio: 17, Epoch 30, Loss: 100.564140\n",
      "SNR Ratio: 17, Epoch 31, Loss: 98.946732\n",
      "SNR Ratio: 17, Epoch 32, Loss: 97.770027\n",
      "SNR Ratio: 17, Epoch 33, Loss: 96.258583\n",
      "SNR Ratio: 17, Epoch 34, Loss: 98.457802\n",
      "SNR Ratio: 17, Epoch 35, Loss: 96.438957\n",
      "SNR Ratio: 17, Epoch 36, Loss: 95.571564\n",
      "SNR Ratio: 17, Epoch 37, Loss: 95.431358\n",
      "SNR Ratio: 17, Epoch 38, Loss: 93.436012\n",
      "SNR Ratio: 17, Epoch 39, Loss: 93.215363\n",
      "SNR Ratio: 17, Epoch 40, Loss: 92.557007\n",
      "SNR Ratio: 17, Epoch 41, Loss: 92.849197\n",
      "SNR Ratio: 17, Epoch 42, Loss: 88.188683\n",
      "SNR Ratio: 17, Epoch 43, Loss: 89.605743\n",
      "SNR Ratio: 17, Epoch 44, Loss: 91.647598\n",
      "SNR Ratio: 17, Epoch 45, Loss: 88.149811\n",
      "SNR Ratio: 17, Epoch 46, Loss: 89.814171\n",
      "SNR Ratio: 17, Epoch 47, Loss: 90.674492\n",
      "SNR Ratio: 17, Epoch 48, Loss: 91.032753\n",
      "SNR Ratio: 17, Epoch 49, Loss: 89.581223\n",
      "SNR Ratio: 17, Epoch 50, Loss: 86.230949\n",
      "SNR Ratio: 17, Epoch 51, Loss: 86.990646\n",
      "SNR Ratio: 17, Epoch 52, Loss: 86.951279\n",
      "SNR Ratio: 17, Epoch 53, Loss: 84.066139\n",
      "SNR Ratio: 17, Epoch 54, Loss: 88.022057\n",
      "SNR Ratio: 17, Epoch 55, Loss: 85.167282\n",
      "SNR Ratio: 17, Epoch 56, Loss: 84.250763\n",
      "SNR Ratio: 17, Epoch 57, Loss: 82.195915\n",
      "SNR Ratio: 17, Epoch 58, Loss: 86.970451\n",
      "SNR Ratio: 17, Epoch 59, Loss: 83.576462\n",
      "SNR Ratio: 17, Epoch 60, Loss: 83.532639\n",
      "SNR Ratio: 17, Epoch 61, Loss: 83.087463\n",
      "SNR Ratio: 17, Epoch 62, Loss: 83.467491\n",
      "SNR Ratio: 17, Epoch 63, Loss: 83.981552\n",
      "SNR Ratio: 17, Epoch 64, Loss: 84.572617\n",
      "SNR Ratio: 17, Epoch 65, Loss: 82.532112\n",
      "SNR Ratio: 17, Epoch 66, Loss: 83.265305\n",
      "SNR Ratio: 17, Epoch 67, Loss: 83.043213\n",
      "SNR Ratio: 17, Epoch 68, Loss: 81.611427\n",
      "SNR Ratio: 17, Epoch 69, Loss: 82.083397\n",
      "SNR Ratio: 17, Epoch 70, Loss: 80.723053\n",
      "SNR Ratio: 17, Epoch 71, Loss: 80.429657\n",
      "SNR Ratio: 17, Epoch 72, Loss: 78.590492\n",
      "SNR Ratio: 17, Epoch 73, Loss: 80.068459\n",
      "SNR Ratio: 17, Epoch 74, Loss: 79.887863\n",
      "SNR Ratio: 17, Epoch 75, Loss: 78.903374\n",
      "SNR Ratio: 17, Epoch 76, Loss: 78.716721\n",
      "SNR Ratio: 17, Epoch 77, Loss: 80.929932\n",
      "SNR Ratio: 17, Epoch 78, Loss: 82.351761\n",
      "SNR Ratio: 17, Epoch 79, Loss: 82.080887\n",
      "SNR Ratio: 17, Epoch 80, Loss: 80.531006\n",
      "SNR Ratio: 17, Epoch 81, Loss: 79.744858\n",
      "SNR Ratio: 17, Epoch 82, Loss: 80.923393\n",
      "SNR Ratio: 17, Epoch 83, Loss: 79.092018\n",
      "SNR Ratio: 17, Epoch 84, Loss: 78.561913\n",
      "SNR Ratio: 17, Epoch 85, Loss: 77.427132\n",
      "SNR Ratio: 17, Epoch 86, Loss: 76.815002\n",
      "SNR Ratio: 17, Epoch 87, Loss: 75.701668\n",
      "SNR Ratio: 17, Epoch 88, Loss: 76.777878\n",
      "SNR Ratio: 17, Epoch 89, Loss: 74.461182\n",
      "SNR Ratio: 17, Epoch 90, Loss: 75.426796\n",
      "SNR Ratio: 17, Epoch 91, Loss: 76.222054\n",
      "SNR Ratio: 17, Epoch 92, Loss: 76.828590\n",
      "SNR Ratio: 17, Epoch 93, Loss: 77.057808\n",
      "SNR Ratio: 17, Epoch 94, Loss: 77.291679\n",
      "SNR Ratio: 17, Epoch 95, Loss: 75.061798\n",
      "SNR Ratio: 17, Epoch 96, Loss: 72.715652\n",
      "SNR Ratio: 17, Epoch 97, Loss: 73.988144\n",
      "SNR Ratio: 17, Epoch 98, Loss: 74.792763\n",
      "SNR Ratio: 17, Epoch 99, Loss: 74.100960\n",
      "SNR Ratio: 17, Epoch 100, Loss: 74.512161\n",
      "SNR Ratio: 17, Epoch 101, Loss: 73.281715\n",
      "SNR Ratio: 17, Epoch 102, Loss: 75.558037\n",
      "SNR Ratio: 17, Epoch 103, Loss: 72.240128\n",
      "SNR Ratio: 17, Epoch 104, Loss: 74.039139\n",
      "SNR Ratio: 17, Epoch 105, Loss: 73.113922\n",
      "SNR Ratio: 17, Epoch 106, Loss: 71.459648\n",
      "SNR Ratio: 17, Epoch 107, Loss: 73.899857\n",
      "SNR Ratio: 17, Epoch 108, Loss: 73.750671\n",
      "SNR Ratio: 17, Epoch 109, Loss: 72.111008\n",
      "SNR Ratio: 17, Epoch 110, Loss: 71.026016\n",
      "SNR Ratio: 17, Epoch 111, Loss: 72.486572\n",
      "SNR Ratio: 17, Epoch 112, Loss: 73.005585\n",
      "SNR Ratio: 17, Epoch 113, Loss: 70.402771\n",
      "SNR Ratio: 17, Epoch 114, Loss: 72.723114\n",
      "SNR Ratio: 17, Epoch 115, Loss: 72.481094\n",
      "SNR Ratio: 17, Epoch 116, Loss: 70.457443\n",
      "SNR Ratio: 17, Epoch 117, Loss: 71.823708\n",
      "SNR Ratio: 17, Epoch 118, Loss: 69.387009\n",
      "SNR Ratio: 17, Epoch 119, Loss: 72.490479\n",
      "SNR Ratio: 17, Epoch 120, Loss: 70.127800\n",
      "SNR Ratio: 17, Epoch 121, Loss: 68.501137\n",
      "SNR Ratio: 17, Epoch 122, Loss: 71.324257\n",
      "SNR Ratio: 17, Epoch 123, Loss: 71.248848\n",
      "SNR Ratio: 17, Epoch 124, Loss: 67.526237\n",
      "SNR Ratio: 17, Epoch 125, Loss: 68.987473\n",
      "SNR Ratio: 17, Epoch 126, Loss: 68.134789\n",
      "SNR Ratio: 17, Epoch 127, Loss: 68.669914\n",
      "SNR Ratio: 17, Epoch 128, Loss: 69.567078\n",
      "SNR Ratio: 17, Epoch 129, Loss: 67.977501\n",
      "SNR Ratio: 17, Epoch 130, Loss: 67.865868\n",
      "SNR Ratio: 17, Epoch 131, Loss: 67.801018\n",
      "SNR Ratio: 17, Epoch 132, Loss: 69.482140\n",
      "SNR Ratio: 17, Epoch 133, Loss: 70.123718\n",
      "SNR Ratio: 17, Epoch 134, Loss: 66.396011\n",
      "SNR Ratio: 17, Epoch 135, Loss: 68.653008\n",
      "SNR Ratio: 17, Epoch 136, Loss: 66.720497\n",
      "SNR Ratio: 17, Epoch 137, Loss: 69.162552\n",
      "SNR Ratio: 17, Epoch 138, Loss: 67.905586\n",
      "SNR Ratio: 17, Epoch 139, Loss: 65.221024\n",
      "SNR Ratio: 17, Epoch 140, Loss: 68.333984\n",
      "SNR Ratio: 17, Epoch 141, Loss: 67.457611\n",
      "SNR Ratio: 17, Epoch 142, Loss: 65.965782\n",
      "SNR Ratio: 17, Epoch 143, Loss: 66.979523\n",
      "SNR Ratio: 17, Epoch 144, Loss: 68.083832\n",
      "SNR Ratio: 17, Epoch 145, Loss: 66.343033\n",
      "SNR Ratio: 17, Epoch 146, Loss: 67.823807\n",
      "SNR Ratio: 17, Epoch 147, Loss: 66.891968\n",
      "SNR Ratio: 17, Epoch 148, Loss: 67.017990\n",
      "SNR Ratio: 17, Epoch 149, Loss: 67.729294\n",
      "SNR Ratio: 17, Epoch 150, Loss: 64.840828\n",
      "SNR Ratio: 17, Epoch 151, Loss: 64.899170\n",
      "SNR Ratio: 17, Epoch 152, Loss: 64.959976\n",
      "SNR Ratio: 17, Epoch 153, Loss: 63.602886\n",
      "SNR Ratio: 17, Epoch 154, Loss: 64.373810\n",
      "SNR Ratio: 17, Epoch 155, Loss: 63.291512\n",
      "SNR Ratio: 17, Epoch 156, Loss: 64.319847\n",
      "SNR Ratio: 17, Epoch 157, Loss: 62.518345\n",
      "SNR Ratio: 17, Epoch 158, Loss: 63.151176\n",
      "SNR Ratio: 17, Epoch 159, Loss: 66.176666\n",
      "SNR Ratio: 17, Epoch 160, Loss: 65.492340\n",
      "SNR Ratio: 17, Epoch 161, Loss: 66.193283\n",
      "SNR Ratio: 17, Epoch 162, Loss: 64.756958\n",
      "SNR Ratio: 17, Epoch 163, Loss: 61.120174\n",
      "SNR Ratio: 17, Epoch 164, Loss: 64.721092\n",
      "SNR Ratio: 17, Epoch 165, Loss: 62.466637\n",
      "SNR Ratio: 17, Epoch 166, Loss: 63.142300\n",
      "SNR Ratio: 17, Epoch 167, Loss: 61.872749\n",
      "SNR Ratio: 17, Epoch 168, Loss: 63.657520\n",
      "SNR Ratio: 17, Epoch 169, Loss: 65.416611\n",
      "SNR Ratio: 17, Epoch 170, Loss: 65.890068\n",
      "SNR Ratio: 17, Epoch 171, Loss: 62.204781\n",
      "SNR Ratio: 17, Epoch 172, Loss: 64.085793\n",
      "SNR Ratio: 17, Epoch 173, Loss: 61.889172\n",
      "SNR Ratio: 17, Epoch 174, Loss: 63.811932\n",
      "SNR Ratio: 17, Epoch 175, Loss: 64.748886\n",
      "SNR Ratio: 17, Epoch 176, Loss: 62.496670\n",
      "SNR Ratio: 17, Epoch 177, Loss: 62.654316\n",
      "SNR Ratio: 17, Epoch 178, Loss: 62.491562\n",
      "SNR Ratio: 17, Epoch 179, Loss: 63.685516\n",
      "SNR Ratio: 17, Epoch 180, Loss: 62.961037\n",
      "SNR Ratio: 17, Epoch 181, Loss: 63.986980\n",
      "SNR Ratio: 17, Epoch 182, Loss: 62.714546\n",
      "SNR Ratio: 17, Epoch 183, Loss: 63.974621\n",
      "SNR Ratio: 17, Epoch 184, Loss: 63.045647\n",
      "SNR Ratio: 17, Epoch 185, Loss: 60.976292\n",
      "SNR Ratio: 17, Epoch 186, Loss: 62.948940\n",
      "SNR Ratio: 17, Epoch 187, Loss: 63.282822\n",
      "SNR Ratio: 17, Epoch 188, Loss: 62.330795\n",
      "SNR Ratio: 17, Epoch 189, Loss: 61.102940\n",
      "SNR Ratio: 17, Epoch 190, Loss: 61.127785\n",
      "SNR Ratio: 17, Epoch 191, Loss: 60.714119\n",
      "SNR Ratio: 17, Epoch 192, Loss: 60.666359\n",
      "SNR Ratio: 17, Epoch 193, Loss: 60.664696\n",
      "SNR Ratio: 17, Epoch 194, Loss: 60.194881\n",
      "SNR Ratio: 17, Epoch 195, Loss: 61.077606\n",
      "SNR Ratio: 17, Epoch 196, Loss: 60.878071\n",
      "SNR Ratio: 17, Epoch 197, Loss: 64.084869\n",
      "SNR Ratio: 17, Epoch 198, Loss: 60.930279\n",
      "SNR Ratio: 17, Epoch 199, Loss: 63.316952\n",
      "SNR Ratio: 17, Epoch 200, Loss: 59.697289\n",
      "SNR Ratio: 17, Epoch 201, Loss: 62.351051\n",
      "SNR Ratio: 17, Epoch 202, Loss: 61.688721\n",
      "SNR Ratio: 17, Epoch 203, Loss: 61.518318\n",
      "SNR Ratio: 17, Epoch 204, Loss: 60.808460\n",
      "SNR Ratio: 17, Epoch 205, Loss: 60.454578\n",
      "SNR Ratio: 17, Epoch 206, Loss: 59.561985\n",
      "SNR Ratio: 17, Epoch 207, Loss: 60.106159\n",
      "SNR Ratio: 17, Epoch 208, Loss: 61.695755\n",
      "SNR Ratio: 17, Epoch 209, Loss: 62.255386\n",
      "SNR Ratio: 17, Epoch 210, Loss: 61.440746\n",
      "SNR Ratio: 17, Epoch 211, Loss: 59.587711\n",
      "SNR Ratio: 17, Epoch 212, Loss: 60.009445\n",
      "SNR Ratio: 17, Epoch 213, Loss: 58.479671\n",
      "SNR Ratio: 17, Epoch 214, Loss: 59.517132\n",
      "SNR Ratio: 17, Epoch 215, Loss: 59.929810\n",
      "SNR Ratio: 17, Epoch 216, Loss: 60.990116\n",
      "SNR Ratio: 17, Epoch 217, Loss: 59.194149\n",
      "SNR Ratio: 17, Epoch 218, Loss: 60.821838\n",
      "SNR Ratio: 17, Epoch 219, Loss: 58.468605\n",
      "SNR Ratio: 17, Epoch 220, Loss: 58.724541\n",
      "SNR Ratio: 17, Epoch 221, Loss: 60.977234\n",
      "SNR Ratio: 17, Epoch 222, Loss: 60.400166\n",
      "SNR Ratio: 17, Epoch 223, Loss: 61.076641\n",
      "SNR Ratio: 17, Epoch 224, Loss: 59.280205\n",
      "SNR Ratio: 17, Epoch 225, Loss: 58.174278\n",
      "SNR Ratio: 17, Epoch 226, Loss: 58.725399\n",
      "SNR Ratio: 17, Epoch 227, Loss: 58.651192\n",
      "SNR Ratio: 17, Epoch 228, Loss: 61.819092\n",
      "SNR Ratio: 17, Epoch 229, Loss: 58.079109\n",
      "SNR Ratio: 17, Epoch 230, Loss: 59.188625\n",
      "SNR Ratio: 17, Epoch 231, Loss: 58.376919\n",
      "SNR Ratio: 17, Epoch 232, Loss: 58.918804\n",
      "SNR Ratio: 17, Epoch 233, Loss: 58.153702\n",
      "SNR Ratio: 17, Epoch 234, Loss: 58.080379\n",
      "SNR Ratio: 17, Epoch 235, Loss: 57.520214\n",
      "SNR Ratio: 17, Epoch 236, Loss: 57.204494\n",
      "SNR Ratio: 17, Epoch 237, Loss: 55.752918\n",
      "SNR Ratio: 17, Epoch 238, Loss: 57.202641\n",
      "SNR Ratio: 17, Epoch 239, Loss: 58.104530\n",
      "SNR Ratio: 17, Epoch 240, Loss: 59.156910\n",
      "SNR Ratio: 17, Epoch 241, Loss: 58.224434\n",
      "SNR Ratio: 17, Epoch 242, Loss: 59.242336\n",
      "SNR Ratio: 17, Epoch 243, Loss: 58.254292\n",
      "SNR Ratio: 17, Epoch 244, Loss: 57.271832\n",
      "SNR Ratio: 17, Epoch 245, Loss: 58.568279\n",
      "SNR Ratio: 17, Epoch 246, Loss: 57.911591\n",
      "SNR Ratio: 17, Epoch 247, Loss: 56.349972\n",
      "SNR Ratio: 17, Epoch 248, Loss: 59.387810\n",
      "SNR Ratio: 17, Epoch 249, Loss: 56.505100\n",
      "SNR Ratio: 17, Epoch 250, Loss: 57.022705\n",
      "SNR Ratio: 17, Epoch 251, Loss: 57.010330\n",
      "SNR Ratio: 17, Epoch 252, Loss: 55.771561\n",
      "SNR Ratio: 17, Epoch 253, Loss: 56.844158\n",
      "SNR Ratio: 17, Epoch 254, Loss: 55.787834\n",
      "SNR Ratio: 17, Epoch 255, Loss: 54.778881\n",
      "SNR Ratio: 17, Epoch 256, Loss: 58.075565\n",
      "SNR Ratio: 17, Epoch 257, Loss: 58.244541\n",
      "SNR Ratio: 17, Epoch 258, Loss: 57.841709\n",
      "SNR Ratio: 17, Epoch 259, Loss: 56.920792\n",
      "SNR Ratio: 17, Epoch 260, Loss: 56.158295\n",
      "SNR Ratio: 17, Epoch 261, Loss: 55.870770\n",
      "SNR Ratio: 17, Epoch 262, Loss: 55.583946\n",
      "SNR Ratio: 17, Epoch 263, Loss: 56.213169\n",
      "SNR Ratio: 17, Epoch 264, Loss: 54.686729\n",
      "SNR Ratio: 17, Epoch 265, Loss: 55.751949\n",
      "SNR Ratio: 17, Epoch 266, Loss: 55.615879\n",
      "SNR Ratio: 17, Epoch 267, Loss: 55.684879\n",
      "SNR Ratio: 17, Epoch 268, Loss: 54.233505\n",
      "SNR Ratio: 17, Epoch 269, Loss: 55.907082\n",
      "SNR Ratio: 17, Epoch 270, Loss: 55.320316\n",
      "SNR Ratio: 17, Epoch 271, Loss: 55.062164\n",
      "SNR Ratio: 17, Epoch 272, Loss: 54.166065\n",
      "SNR Ratio: 17, Epoch 273, Loss: 55.584625\n",
      "SNR Ratio: 17, Epoch 274, Loss: 54.019306\n",
      "SNR Ratio: 17, Epoch 275, Loss: 53.177277\n",
      "SNR Ratio: 17, Epoch 276, Loss: 55.099983\n",
      "SNR Ratio: 17, Epoch 277, Loss: 56.588421\n",
      "SNR Ratio: 17, Epoch 278, Loss: 52.464100\n",
      "SNR Ratio: 17, Epoch 279, Loss: 54.568562\n",
      "SNR Ratio: 17, Epoch 280, Loss: 53.647354\n",
      "SNR Ratio: 17, Epoch 281, Loss: 52.629181\n",
      "SNR Ratio: 17, Epoch 282, Loss: 52.619091\n",
      "SNR Ratio: 17, Epoch 283, Loss: 54.301949\n",
      "SNR Ratio: 17, Epoch 284, Loss: 53.411411\n",
      "SNR Ratio: 17, Epoch 285, Loss: 54.296169\n",
      "SNR Ratio: 17, Epoch 286, Loss: 54.465134\n",
      "SNR Ratio: 17, Epoch 287, Loss: 54.495049\n",
      "SNR Ratio: 17, Epoch 288, Loss: 53.934551\n",
      "SNR Ratio: 17, Epoch 289, Loss: 55.098289\n",
      "SNR Ratio: 17, Epoch 290, Loss: 54.056496\n",
      "SNR Ratio: 17, Epoch 291, Loss: 53.488831\n",
      "SNR Ratio: 17, Epoch 292, Loss: 53.212440\n",
      "SNR Ratio: 17, Epoch 293, Loss: 51.272751\n",
      "SNR Ratio: 17, Epoch 294, Loss: 52.898670\n",
      "SNR Ratio: 17, Epoch 295, Loss: 51.388535\n",
      "SNR Ratio: 17, Epoch 296, Loss: 53.080055\n",
      "SNR Ratio: 17, Epoch 297, Loss: 51.275200\n",
      "SNR Ratio: 17, Epoch 298, Loss: 51.867538\n",
      "SNR Ratio: 17, Epoch 299, Loss: 54.055214\n",
      "SNR Ratio: 17, Epoch 300, Loss: 52.836117\n",
      "SNR Ratio: 17, Epoch 301, Loss: 51.042961\n",
      "SNR Ratio: 17, Epoch 302, Loss: 51.002716\n",
      "SNR Ratio: 17, Epoch 303, Loss: 50.572575\n",
      "SNR Ratio: 17, Epoch 304, Loss: 51.873371\n",
      "SNR Ratio: 17, Epoch 305, Loss: 52.149551\n",
      "SNR Ratio: 17, Epoch 306, Loss: 50.528591\n",
      "SNR Ratio: 17, Epoch 307, Loss: 51.571453\n",
      "SNR Ratio: 17, Epoch 308, Loss: 51.783169\n",
      "SNR Ratio: 17, Epoch 309, Loss: 51.692699\n",
      "SNR Ratio: 17, Epoch 310, Loss: 52.181511\n",
      "SNR Ratio: 17, Epoch 311, Loss: 49.428799\n",
      "SNR Ratio: 17, Epoch 312, Loss: 52.551495\n",
      "SNR Ratio: 17, Epoch 313, Loss: 46.298729\n",
      "SNR Ratio: 17, Epoch 314, Loss: 50.346230\n",
      "SNR Ratio: 17, Epoch 315, Loss: 49.738384\n",
      "SNR Ratio: 17, Epoch 316, Loss: 49.034721\n",
      "SNR Ratio: 17, Epoch 317, Loss: 51.795769\n",
      "SNR Ratio: 17, Epoch 318, Loss: 49.311214\n",
      "SNR Ratio: 17, Epoch 319, Loss: 50.067429\n",
      "SNR Ratio: 17, Epoch 320, Loss: 48.073818\n",
      "SNR Ratio: 17, Epoch 321, Loss: 48.215820\n",
      "SNR Ratio: 17, Epoch 322, Loss: 47.938820\n",
      "SNR Ratio: 17, Epoch 323, Loss: 48.585918\n",
      "SNR Ratio: 17, Epoch 324, Loss: 47.581631\n",
      "SNR Ratio: 17, Epoch 325, Loss: 47.901588\n",
      "SNR Ratio: 17, Epoch 326, Loss: 46.724731\n",
      "SNR Ratio: 17, Epoch 327, Loss: 48.076752\n",
      "SNR Ratio: 17, Epoch 328, Loss: 47.166435\n",
      "SNR Ratio: 17, Epoch 329, Loss: 49.188526\n",
      "SNR Ratio: 17, Epoch 330, Loss: 49.924446\n",
      "SNR Ratio: 17, Epoch 331, Loss: 48.946110\n",
      "SNR Ratio: 17, Epoch 332, Loss: 47.802670\n",
      "SNR Ratio: 17, Epoch 333, Loss: 46.031120\n",
      "SNR Ratio: 17, Epoch 334, Loss: 48.095268\n",
      "SNR Ratio: 17, Epoch 335, Loss: 44.674160\n",
      "SNR Ratio: 17, Epoch 336, Loss: 46.706188\n",
      "SNR Ratio: 17, Epoch 337, Loss: 46.954380\n",
      "SNR Ratio: 17, Epoch 338, Loss: 47.962196\n",
      "SNR Ratio: 17, Epoch 339, Loss: 46.495171\n",
      "SNR Ratio: 17, Epoch 340, Loss: 46.429661\n",
      "SNR Ratio: 17, Epoch 341, Loss: 46.042706\n",
      "SNR Ratio: 17, Epoch 342, Loss: 45.805431\n",
      "SNR Ratio: 17, Epoch 343, Loss: 46.561386\n",
      "SNR Ratio: 17, Epoch 344, Loss: 45.030739\n",
      "SNR Ratio: 17, Epoch 345, Loss: 46.584560\n",
      "SNR Ratio: 17, Epoch 346, Loss: 44.371361\n",
      "SNR Ratio: 17, Epoch 347, Loss: 46.039341\n",
      "SNR Ratio: 17, Epoch 348, Loss: 45.276150\n",
      "SNR Ratio: 17, Epoch 349, Loss: 45.196159\n",
      "SNR Ratio: 17, Epoch 350, Loss: 43.783791\n",
      "SNR Ratio: 17, Epoch 351, Loss: 45.555794\n",
      "SNR Ratio: 17, Epoch 352, Loss: 42.993801\n",
      "SNR Ratio: 17, Epoch 353, Loss: 44.073399\n",
      "SNR Ratio: 17, Epoch 354, Loss: 42.734924\n",
      "SNR Ratio: 17, Epoch 355, Loss: 42.278561\n",
      "SNR Ratio: 17, Epoch 356, Loss: 44.501194\n",
      "SNR Ratio: 17, Epoch 357, Loss: 42.608440\n",
      "SNR Ratio: 17, Epoch 358, Loss: 42.125961\n",
      "SNR Ratio: 17, Epoch 359, Loss: 41.950958\n",
      "SNR Ratio: 17, Epoch 360, Loss: 41.452114\n",
      "SNR Ratio: 17, Epoch 361, Loss: 42.559425\n",
      "SNR Ratio: 17, Epoch 362, Loss: 41.647663\n",
      "SNR Ratio: 17, Epoch 363, Loss: 42.106022\n",
      "SNR Ratio: 17, Epoch 364, Loss: 41.816952\n",
      "SNR Ratio: 17, Epoch 365, Loss: 43.467030\n",
      "SNR Ratio: 17, Epoch 366, Loss: 42.369968\n",
      "SNR Ratio: 17, Epoch 367, Loss: 41.444340\n",
      "SNR Ratio: 17, Epoch 368, Loss: 41.893978\n",
      "SNR Ratio: 17, Epoch 369, Loss: 38.863861\n",
      "SNR Ratio: 17, Epoch 370, Loss: 39.785252\n",
      "SNR Ratio: 17, Epoch 371, Loss: 41.102909\n",
      "SNR Ratio: 17, Epoch 372, Loss: 39.923828\n",
      "SNR Ratio: 17, Epoch 373, Loss: 39.928490\n",
      "SNR Ratio: 17, Epoch 374, Loss: 38.852467\n",
      "SNR Ratio: 17, Epoch 375, Loss: 38.542683\n",
      "SNR Ratio: 17, Epoch 376, Loss: 39.041649\n",
      "SNR Ratio: 17, Epoch 377, Loss: 38.619930\n",
      "SNR Ratio: 17, Epoch 378, Loss: 36.982304\n",
      "SNR Ratio: 17, Epoch 379, Loss: 38.036709\n",
      "SNR Ratio: 17, Epoch 380, Loss: 38.036087\n",
      "SNR Ratio: 17, Epoch 381, Loss: 36.487431\n",
      "SNR Ratio: 17, Epoch 382, Loss: 35.686337\n",
      "SNR Ratio: 17, Epoch 383, Loss: 37.063881\n",
      "SNR Ratio: 17, Epoch 384, Loss: 36.243977\n",
      "SNR Ratio: 17, Epoch 385, Loss: 38.231640\n",
      "SNR Ratio: 17, Epoch 386, Loss: 35.498356\n",
      "SNR Ratio: 17, Epoch 387, Loss: 35.438793\n",
      "SNR Ratio: 17, Epoch 388, Loss: 36.703426\n",
      "SNR Ratio: 17, Epoch 389, Loss: 37.055603\n",
      "SNR Ratio: 17, Epoch 390, Loss: 36.305882\n",
      "SNR Ratio: 17, Epoch 391, Loss: 32.893501\n",
      "SNR Ratio: 17, Epoch 392, Loss: 34.125332\n",
      "SNR Ratio: 17, Epoch 393, Loss: 32.859863\n",
      "SNR Ratio: 17, Epoch 394, Loss: 35.312389\n",
      "SNR Ratio: 17, Epoch 395, Loss: 33.443882\n",
      "SNR Ratio: 17, Epoch 396, Loss: 33.546051\n",
      "SNR Ratio: 17, Epoch 397, Loss: 33.719006\n",
      "SNR Ratio: 17, Epoch 398, Loss: 32.506725\n",
      "SNR Ratio: 17, Epoch 399, Loss: 33.172874\n",
      "SNR Ratio: 17, Epoch 400, Loss: 29.604912\n",
      "SNR Ratio: 17, Epoch 401, Loss: 30.508692\n",
      "SNR Ratio: 17, Epoch 402, Loss: 31.067293\n",
      "SNR Ratio: 17, Epoch 403, Loss: 30.773661\n",
      "SNR Ratio: 17, Epoch 404, Loss: 30.562244\n",
      "SNR Ratio: 17, Epoch 405, Loss: 29.893089\n",
      "SNR Ratio: 17, Epoch 406, Loss: 29.529285\n",
      "SNR Ratio: 17, Epoch 407, Loss: 29.126072\n",
      "SNR Ratio: 17, Epoch 408, Loss: 29.856272\n",
      "SNR Ratio: 17, Epoch 409, Loss: 29.673475\n",
      "SNR Ratio: 17, Epoch 410, Loss: 27.473257\n",
      "SNR Ratio: 17, Epoch 411, Loss: 27.547424\n",
      "SNR Ratio: 17, Epoch 412, Loss: 27.543791\n",
      "SNR Ratio: 17, Epoch 413, Loss: 28.170679\n",
      "SNR Ratio: 17, Epoch 414, Loss: 26.931986\n",
      "SNR Ratio: 17, Epoch 415, Loss: 26.600559\n",
      "SNR Ratio: 17, Epoch 416, Loss: 28.007469\n",
      "SNR Ratio: 17, Epoch 417, Loss: 26.200809\n",
      "SNR Ratio: 17, Epoch 418, Loss: 26.377478\n",
      "SNR Ratio: 17, Epoch 419, Loss: 26.859184\n",
      "SNR Ratio: 17, Epoch 420, Loss: 26.152170\n",
      "SNR Ratio: 17, Epoch 421, Loss: 25.972565\n",
      "SNR Ratio: 17, Epoch 422, Loss: 26.062187\n",
      "SNR Ratio: 17, Epoch 423, Loss: 22.973513\n",
      "SNR Ratio: 17, Epoch 424, Loss: 25.036385\n",
      "SNR Ratio: 17, Epoch 425, Loss: 24.914545\n",
      "SNR Ratio: 17, Epoch 426, Loss: 22.688471\n",
      "SNR Ratio: 17, Epoch 427, Loss: 23.310225\n",
      "SNR Ratio: 17, Epoch 428, Loss: 22.781731\n",
      "SNR Ratio: 17, Epoch 429, Loss: 23.874880\n",
      "SNR Ratio: 17, Epoch 430, Loss: 23.516535\n",
      "SNR Ratio: 17, Epoch 431, Loss: 23.719379\n",
      "SNR Ratio: 17, Epoch 432, Loss: 22.626162\n",
      "SNR Ratio: 17, Epoch 433, Loss: 21.868034\n",
      "SNR Ratio: 17, Epoch 434, Loss: 21.860947\n",
      "SNR Ratio: 17, Epoch 435, Loss: 22.843060\n",
      "SNR Ratio: 17, Epoch 436, Loss: 21.911125\n",
      "SNR Ratio: 17, Epoch 437, Loss: 21.032797\n",
      "SNR Ratio: 17, Epoch 438, Loss: 20.737423\n",
      "SNR Ratio: 17, Epoch 439, Loss: 21.914869\n",
      "SNR Ratio: 17, Epoch 440, Loss: 19.345690\n",
      "SNR Ratio: 17, Epoch 441, Loss: 19.505726\n",
      "SNR Ratio: 17, Epoch 442, Loss: 20.394726\n",
      "SNR Ratio: 17, Epoch 443, Loss: 19.241409\n",
      "SNR Ratio: 17, Epoch 444, Loss: 19.810953\n",
      "SNR Ratio: 17, Epoch 445, Loss: 20.141890\n",
      "SNR Ratio: 17, Epoch 446, Loss: 20.410166\n",
      "SNR Ratio: 17, Epoch 447, Loss: 19.734333\n",
      "SNR Ratio: 17, Epoch 448, Loss: 17.638962\n",
      "SNR Ratio: 17, Epoch 449, Loss: 19.689974\n",
      "SNR Ratio: 17, Epoch 450, Loss: 18.727686\n",
      "SNR Ratio: 17, Epoch 451, Loss: 20.469101\n",
      "SNR Ratio: 17, Epoch 452, Loss: 19.674706\n",
      "SNR Ratio: 17, Epoch 453, Loss: 20.189251\n",
      "SNR Ratio: 17, Epoch 454, Loss: 17.716190\n",
      "SNR Ratio: 17, Epoch 455, Loss: 16.361761\n",
      "SNR Ratio: 17, Epoch 456, Loss: 17.165159\n",
      "SNR Ratio: 17, Epoch 457, Loss: 17.423948\n",
      "SNR Ratio: 17, Epoch 458, Loss: 15.929063\n",
      "SNR Ratio: 17, Epoch 459, Loss: 16.361927\n",
      "SNR Ratio: 17, Epoch 460, Loss: 16.552460\n",
      "SNR Ratio: 17, Epoch 461, Loss: 17.514608\n",
      "SNR Ratio: 17, Epoch 462, Loss: 16.418119\n",
      "SNR Ratio: 17, Epoch 463, Loss: 16.115351\n",
      "SNR Ratio: 17, Epoch 464, Loss: 15.585438\n",
      "SNR Ratio: 17, Epoch 465, Loss: 16.154932\n",
      "SNR Ratio: 17, Epoch 466, Loss: 15.381066\n",
      "SNR Ratio: 17, Epoch 467, Loss: 15.743885\n",
      "SNR Ratio: 17, Epoch 468, Loss: 15.257713\n",
      "SNR Ratio: 17, Epoch 469, Loss: 14.233280\n",
      "SNR Ratio: 17, Epoch 470, Loss: 15.156476\n",
      "SNR Ratio: 17, Epoch 471, Loss: 13.653217\n",
      "SNR Ratio: 17, Epoch 472, Loss: 15.127797\n",
      "SNR Ratio: 17, Epoch 473, Loss: 16.080717\n",
      "SNR Ratio: 17, Epoch 474, Loss: 15.534890\n",
      "SNR Ratio: 17, Epoch 475, Loss: 15.201935\n",
      "SNR Ratio: 17, Epoch 476, Loss: 14.029387\n",
      "SNR Ratio: 17, Epoch 477, Loss: 12.897783\n",
      "SNR Ratio: 17, Epoch 478, Loss: 14.256738\n",
      "SNR Ratio: 17, Epoch 479, Loss: 13.676043\n",
      "SNR Ratio: 17, Epoch 480, Loss: 13.028635\n",
      "SNR Ratio: 17, Epoch 481, Loss: 13.956870\n",
      "SNR Ratio: 17, Epoch 482, Loss: 12.891873\n",
      "SNR Ratio: 17, Epoch 483, Loss: 13.034396\n",
      "SNR Ratio: 17, Epoch 484, Loss: 15.089353\n",
      "SNR Ratio: 17, Epoch 485, Loss: 15.616403\n",
      "SNR Ratio: 17, Epoch 486, Loss: 15.105073\n",
      "SNR Ratio: 17, Epoch 487, Loss: 13.275434\n",
      "SNR Ratio: 17, Epoch 488, Loss: 13.348542\n",
      "SNR Ratio: 17, Epoch 489, Loss: 14.645058\n",
      "SNR Ratio: 17, Epoch 490, Loss: 12.200437\n",
      "SNR Ratio: 17, Epoch 491, Loss: 11.863590\n",
      "SNR Ratio: 17, Epoch 492, Loss: 12.884048\n",
      "SNR Ratio: 17, Epoch 493, Loss: 12.349844\n",
      "SNR Ratio: 17, Epoch 494, Loss: 12.439253\n",
      "SNR Ratio: 17, Epoch 495, Loss: 11.842120\n",
      "SNR Ratio: 17, Epoch 496, Loss: 11.660012\n",
      "SNR Ratio: 17, Epoch 497, Loss: 11.840670\n",
      "SNR Ratio: 17, Epoch 498, Loss: 12.893714\n",
      "SNR Ratio: 17, Epoch 499, Loss: 11.854745\n",
      "SNR Ratio: 17, Epoch 500, Loss: 13.233035\n",
      "SNR Ratio: 17, Epoch 501, Loss: 11.399475\n",
      "SNR Ratio: 17, Epoch 502, Loss: 11.391735\n",
      "SNR Ratio: 17, Epoch 503, Loss: 11.295817\n",
      "SNR Ratio: 17, Epoch 504, Loss: 10.371693\n",
      "SNR Ratio: 17, Epoch 505, Loss: 11.693623\n",
      "SNR Ratio: 17, Epoch 506, Loss: 11.439383\n",
      "SNR Ratio: 17, Epoch 507, Loss: 11.603827\n",
      "SNR Ratio: 17, Epoch 508, Loss: 11.232754\n",
      "SNR Ratio: 17, Epoch 509, Loss: 10.749720\n",
      "SNR Ratio: 17, Epoch 510, Loss: 11.738345\n",
      "SNR Ratio: 17, Epoch 511, Loss: 11.211936\n",
      "SNR Ratio: 17, Epoch 512, Loss: 11.049183\n",
      "SNR Ratio: 17, Epoch 513, Loss: 11.130818\n",
      "SNR Ratio: 17, Epoch 514, Loss: 11.811400\n",
      "SNR Ratio: 17, Epoch 515, Loss: 11.549585\n",
      "SNR Ratio: 17, Epoch 516, Loss: 11.180625\n",
      "SNR Ratio: 17, Epoch 517, Loss: 11.545211\n",
      "SNR Ratio: 17, Epoch 518, Loss: 11.100840\n",
      "SNR Ratio: 17, Epoch 519, Loss: 10.727463\n",
      "SNR Ratio: 17, Epoch 520, Loss: 10.191188\n",
      "SNR Ratio: 17, Epoch 521, Loss: 9.342925\n",
      "SNR Ratio: 17, Epoch 522, Loss: 9.815076\n",
      "SNR Ratio: 17, Epoch 523, Loss: 10.171021\n",
      "SNR Ratio: 17, Epoch 524, Loss: 9.923776\n",
      "SNR Ratio: 17, Epoch 525, Loss: 10.232455\n",
      "SNR Ratio: 17, Epoch 526, Loss: 10.148833\n",
      "SNR Ratio: 17, Epoch 527, Loss: 10.363317\n",
      "SNR Ratio: 17, Epoch 528, Loss: 9.595702\n",
      "SNR Ratio: 17, Epoch 529, Loss: 10.243298\n",
      "SNR Ratio: 17, Epoch 530, Loss: 9.065891\n",
      "SNR Ratio: 17, Epoch 531, Loss: 9.439857\n",
      "SNR Ratio: 17, Epoch 532, Loss: 10.464952\n",
      "SNR Ratio: 17, Epoch 533, Loss: 10.350169\n",
      "SNR Ratio: 17, Epoch 534, Loss: 9.292325\n",
      "SNR Ratio: 17, Epoch 535, Loss: 9.727311\n",
      "SNR Ratio: 17, Epoch 536, Loss: 10.233992\n",
      "SNR Ratio: 17, Epoch 537, Loss: 10.983855\n",
      "SNR Ratio: 17, Epoch 538, Loss: 10.839250\n",
      "SNR Ratio: 17, Epoch 539, Loss: 10.472323\n",
      "SNR Ratio: 17, Epoch 540, Loss: 10.755539\n",
      "SNR Ratio: 17, Epoch 541, Loss: 10.258476\n",
      "SNR Ratio: 17, Epoch 542, Loss: 10.332872\n",
      "SNR Ratio: 17, Epoch 543, Loss: 10.777175\n",
      "SNR Ratio: 17, Epoch 544, Loss: 8.855190\n",
      "SNR Ratio: 17, Epoch 545, Loss: 9.481804\n",
      "SNR Ratio: 17, Epoch 546, Loss: 9.757208\n",
      "SNR Ratio: 17, Epoch 547, Loss: 10.580985\n",
      "SNR Ratio: 17, Epoch 548, Loss: 8.518638\n",
      "SNR Ratio: 17, Epoch 549, Loss: 8.345962\n",
      "SNR Ratio: 17, Epoch 550, Loss: 8.349707\n",
      "SNR Ratio: 17, Epoch 551, Loss: 9.926899\n",
      "SNR Ratio: 17, Epoch 552, Loss: 14.762410\n",
      "SNR Ratio: 17, Epoch 553, Loss: 11.206705\n",
      "SNR Ratio: 17, Epoch 554, Loss: 12.445205\n",
      "SNR Ratio: 17, Epoch 555, Loss: 10.544188\n",
      "SNR Ratio: 17, Epoch 556, Loss: 8.707812\n",
      "SNR Ratio: 17, Epoch 557, Loss: 9.235391\n",
      "SNR Ratio: 17, Epoch 558, Loss: 8.218225\n",
      "SNR Ratio: 17, Epoch 559, Loss: 8.838709\n",
      "SNR Ratio: 17, Epoch 560, Loss: 8.605663\n",
      "SNR Ratio: 17, Epoch 561, Loss: 8.331314\n",
      "SNR Ratio: 17, Epoch 562, Loss: 8.088837\n",
      "SNR Ratio: 17, Epoch 563, Loss: 7.507593\n",
      "SNR Ratio: 17, Epoch 564, Loss: 7.736748\n",
      "SNR Ratio: 17, Epoch 565, Loss: 9.128881\n",
      "SNR Ratio: 17, Epoch 566, Loss: 8.014029\n",
      "SNR Ratio: 17, Epoch 567, Loss: 9.294678\n",
      "SNR Ratio: 17, Epoch 568, Loss: 7.819526\n",
      "SNR Ratio: 17, Epoch 569, Loss: 7.250599\n",
      "SNR Ratio: 17, Epoch 570, Loss: 7.537340\n",
      "SNR Ratio: 17, Epoch 571, Loss: 7.640320\n",
      "SNR Ratio: 17, Epoch 572, Loss: 8.560410\n",
      "SNR Ratio: 17, Epoch 573, Loss: 7.506320\n",
      "SNR Ratio: 17, Epoch 574, Loss: 7.490814\n",
      "SNR Ratio: 17, Epoch 575, Loss: 7.055412\n",
      "SNR Ratio: 17, Epoch 576, Loss: 7.021736\n",
      "SNR Ratio: 17, Epoch 577, Loss: 7.590304\n",
      "SNR Ratio: 17, Epoch 578, Loss: 8.050382\n",
      "SNR Ratio: 17, Epoch 579, Loss: 8.714356\n",
      "SNR Ratio: 17, Epoch 580, Loss: 7.814689\n",
      "SNR Ratio: 17, Epoch 581, Loss: 7.736311\n",
      "SNR Ratio: 17, Epoch 582, Loss: 8.165593\n",
      "SNR Ratio: 17, Epoch 583, Loss: 8.990407\n",
      "SNR Ratio: 17, Epoch 584, Loss: 8.657878\n",
      "SNR Ratio: 17, Epoch 585, Loss: 7.805643\n",
      "SNR Ratio: 17, Epoch 586, Loss: 8.023277\n",
      "SNR Ratio: 17, Epoch 587, Loss: 7.383451\n",
      "SNR Ratio: 17, Epoch 588, Loss: 7.797069\n",
      "SNR Ratio: 17, Epoch 589, Loss: 7.637025\n",
      "SNR Ratio: 17, Epoch 590, Loss: 7.188865\n",
      "SNR Ratio: 17, Epoch 591, Loss: 7.593771\n",
      "SNR Ratio: 17, Epoch 592, Loss: 10.507463\n",
      "SNR Ratio: 17, Epoch 593, Loss: 11.099841\n",
      "SNR Ratio: 17, Epoch 594, Loss: 9.261657\n",
      "SNR Ratio: 17, Epoch 595, Loss: 8.745146\n",
      "SNR Ratio: 17, Epoch 596, Loss: 9.476175\n",
      "SNR Ratio: 17, Epoch 597, Loss: 8.817268\n",
      "SNR Ratio: 17, Epoch 598, Loss: 7.562946\n",
      "SNR Ratio: 17, Epoch 599, Loss: 7.536711\n",
      "SNR Ratio: 17, Epoch 600, Loss: 7.348392\n",
      "SNR Ratio: 17, Epoch 601, Loss: 7.240379\n",
      "SNR Ratio: 17, Epoch 602, Loss: 8.047647\n",
      "SNR Ratio: 17, Epoch 603, Loss: 6.534369\n",
      "SNR Ratio: 17, Epoch 604, Loss: 7.385409\n",
      "SNR Ratio: 17, Epoch 605, Loss: 7.595508\n",
      "SNR Ratio: 17, Epoch 606, Loss: 6.968811\n",
      "SNR Ratio: 17, Epoch 607, Loss: 6.801976\n",
      "SNR Ratio: 17, Epoch 608, Loss: 6.957633\n",
      "SNR Ratio: 17, Epoch 609, Loss: 6.533326\n",
      "SNR Ratio: 17, Epoch 610, Loss: 7.766273\n",
      "SNR Ratio: 17, Epoch 611, Loss: 7.333405\n",
      "SNR Ratio: 17, Epoch 612, Loss: 9.370315\n",
      "SNR Ratio: 17, Epoch 613, Loss: 8.739193\n",
      "SNR Ratio: 17, Epoch 614, Loss: 7.056560\n",
      "SNR Ratio: 17, Epoch 615, Loss: 7.668957\n",
      "SNR Ratio: 17, Epoch 616, Loss: 7.153641\n",
      "SNR Ratio: 17, Epoch 617, Loss: 7.953505\n",
      "SNR Ratio: 17, Epoch 618, Loss: 10.068004\n",
      "SNR Ratio: 17, Epoch 619, Loss: 10.819427\n",
      "SNR Ratio: 17, Epoch 620, Loss: 7.766495\n",
      "SNR Ratio: 17, Epoch 621, Loss: 8.099944\n",
      "SNR Ratio: 17, Epoch 622, Loss: 8.044786\n",
      "SNR Ratio: 17, Epoch 623, Loss: 7.133410\n",
      "SNR Ratio: 17, Epoch 624, Loss: 7.710585\n",
      "SNR Ratio: 17, Epoch 625, Loss: 7.079493\n",
      "SNR Ratio: 17, Epoch 626, Loss: 5.986537\n",
      "SNR Ratio: 17, Epoch 627, Loss: 5.939060\n",
      "SNR Ratio: 17, Epoch 628, Loss: 6.341417\n",
      "SNR Ratio: 17, Epoch 629, Loss: 6.750155\n",
      "SNR Ratio: 17, Epoch 630, Loss: 6.695851\n",
      "SNR Ratio: 17, Epoch 631, Loss: 7.659188\n",
      "SNR Ratio: 17, Epoch 632, Loss: 6.956021\n",
      "SNR Ratio: 17, Epoch 633, Loss: 6.736381\n",
      "SNR Ratio: 17, Epoch 634, Loss: 7.547687\n",
      "SNR Ratio: 17, Epoch 635, Loss: 6.407799\n",
      "SNR Ratio: 17, Epoch 636, Loss: 6.756009\n",
      "SNR Ratio: 17, Epoch 637, Loss: 6.572224\n",
      "SNR Ratio: 17, Epoch 638, Loss: 7.394557\n",
      "SNR Ratio: 17, Epoch 639, Loss: 6.671038\n",
      "SNR Ratio: 17, Epoch 640, Loss: 7.268463\n",
      "SNR Ratio: 17, Epoch 641, Loss: 11.589642\n",
      "SNR Ratio: 17, Epoch 642, Loss: 10.879119\n",
      "SNR Ratio: 17, Epoch 643, Loss: 8.603465\n",
      "SNR Ratio: 17, Epoch 644, Loss: 6.550366\n",
      "SNR Ratio: 17, Epoch 645, Loss: 5.949434\n",
      "SNR Ratio: 17, Epoch 646, Loss: 7.389220\n",
      "SNR Ratio: 17, Epoch 647, Loss: 6.627149\n",
      "SNR Ratio: 17, Epoch 648, Loss: 6.903288\n",
      "SNR Ratio: 17, Epoch 649, Loss: 6.324422\n",
      "SNR Ratio: 17, Epoch 650, Loss: 6.711098\n",
      "SNR Ratio: 17, Epoch 651, Loss: 5.747236\n",
      "SNR Ratio: 17, Epoch 652, Loss: 6.158607\n",
      "SNR Ratio: 17, Epoch 653, Loss: 6.922044\n",
      "SNR Ratio: 17, Epoch 654, Loss: 6.100552\n",
      "SNR Ratio: 17, Epoch 655, Loss: 6.305640\n",
      "SNR Ratio: 17, Epoch 656, Loss: 6.076130\n",
      "SNR Ratio: 17, Epoch 657, Loss: 6.335557\n",
      "SNR Ratio: 17, Epoch 658, Loss: 5.923846\n",
      "SNR Ratio: 17, Epoch 659, Loss: 6.102945\n",
      "SNR Ratio: 17, Epoch 660, Loss: 6.127309\n",
      "SNR Ratio: 17, Epoch 661, Loss: 5.784973\n",
      "SNR Ratio: 17, Epoch 662, Loss: 6.029295\n",
      "SNR Ratio: 17, Epoch 663, Loss: 5.881639\n",
      "SNR Ratio: 17, Epoch 664, Loss: 6.633903\n",
      "SNR Ratio: 17, Epoch 665, Loss: 7.161979\n",
      "SNR Ratio: 17, Epoch 666, Loss: 6.359152\n",
      "SNR Ratio: 17, Epoch 667, Loss: 6.946023\n",
      "SNR Ratio: 17, Epoch 668, Loss: 5.434635\n",
      "SNR Ratio: 17, Epoch 669, Loss: 7.470287\n",
      "SNR Ratio: 17, Epoch 670, Loss: 6.751323\n",
      "SNR Ratio: 17, Epoch 671, Loss: 6.760383\n",
      "SNR Ratio: 17, Epoch 672, Loss: 7.727066\n",
      "SNR Ratio: 17, Epoch 673, Loss: 6.298480\n",
      "SNR Ratio: 17, Epoch 674, Loss: 5.847819\n",
      "SNR Ratio: 17, Epoch 675, Loss: 6.311041\n",
      "SNR Ratio: 17, Epoch 676, Loss: 6.402424\n",
      "SNR Ratio: 17, Epoch 677, Loss: 6.012881\n",
      "SNR Ratio: 17, Epoch 678, Loss: 7.115411\n",
      "SNR Ratio: 17, Epoch 679, Loss: 8.432772\n",
      "SNR Ratio: 17, Epoch 680, Loss: 7.053461\n",
      "SNR Ratio: 17, Epoch 681, Loss: 7.591325\n",
      "SNR Ratio: 17, Epoch 682, Loss: 7.028769\n",
      "SNR Ratio: 17, Epoch 683, Loss: 7.136175\n",
      "SNR Ratio: 17, Epoch 684, Loss: 7.486467\n",
      "SNR Ratio: 17, Epoch 685, Loss: 6.392644\n",
      "SNR Ratio: 17, Epoch 686, Loss: 6.783108\n",
      "SNR Ratio: 17, Epoch 687, Loss: 6.269097\n",
      "SNR Ratio: 17, Epoch 688, Loss: 8.578927\n",
      "SNR Ratio: 17, Epoch 689, Loss: 7.298852\n",
      "SNR Ratio: 17, Epoch 690, Loss: 6.805152\n",
      "SNR Ratio: 17, Epoch 691, Loss: 5.950386\n",
      "SNR Ratio: 17, Epoch 692, Loss: 7.175911\n",
      "SNR Ratio: 17, Epoch 693, Loss: 7.475311\n",
      "SNR Ratio: 17, Epoch 694, Loss: 7.275625\n",
      "SNR Ratio: 17, Epoch 695, Loss: 5.768806\n",
      "SNR Ratio: 17, Epoch 696, Loss: 5.958785\n",
      "SNR Ratio: 17, Epoch 697, Loss: 6.191468\n",
      "SNR Ratio: 17, Epoch 698, Loss: 6.279003\n",
      "SNR Ratio: 17, Epoch 699, Loss: 6.250684\n",
      "SNR Ratio: 17, Epoch 700, Loss: 5.650314\n",
      "SNR Ratio: 17, Epoch 701, Loss: 5.693629\n",
      "SNR Ratio: 17, Epoch 702, Loss: 6.628516\n",
      "SNR Ratio: 17, Epoch 703, Loss: 8.260500\n",
      "SNR Ratio: 17, Epoch 704, Loss: 6.161074\n",
      "SNR Ratio: 17, Epoch 705, Loss: 6.311882\n",
      "SNR Ratio: 17, Epoch 706, Loss: 6.153157\n",
      "SNR Ratio: 17, Epoch 707, Loss: 6.162757\n",
      "SNR Ratio: 17, Epoch 708, Loss: 6.082749\n",
      "SNR Ratio: 17, Epoch 709, Loss: 5.973249\n",
      "SNR Ratio: 17, Epoch 710, Loss: 5.597645\n",
      "SNR Ratio: 17, Epoch 711, Loss: 6.523635\n",
      "SNR Ratio: 17, Epoch 712, Loss: 5.678354\n",
      "SNR Ratio: 17, Epoch 713, Loss: 7.147741\n",
      "SNR Ratio: 17, Epoch 714, Loss: 6.505729\n",
      "SNR Ratio: 17, Epoch 715, Loss: 6.845844\n",
      "SNR Ratio: 17, Epoch 716, Loss: 5.577714\n",
      "SNR Ratio: 17, Epoch 717, Loss: 5.491211\n",
      "SNR Ratio: 17, Epoch 718, Loss: 6.785147\n",
      "SNR Ratio: 17, Epoch 719, Loss: 5.959514\n",
      "SNR Ratio: 17, Epoch 720, Loss: 5.893590\n",
      "SNR Ratio: 17, Epoch 721, Loss: 6.090441\n",
      "SNR Ratio: 17, Epoch 722, Loss: 6.503674\n",
      "SNR Ratio: 17, Epoch 723, Loss: 6.803331\n",
      "SNR Ratio: 17, Epoch 724, Loss: 6.271183\n",
      "SNR Ratio: 17, Epoch 725, Loss: 5.885581\n",
      "SNR Ratio: 17, Epoch 726, Loss: 6.086857\n",
      "SNR Ratio: 17, Epoch 727, Loss: 5.756655\n",
      "SNR Ratio: 17, Epoch 728, Loss: 5.796131\n",
      "SNR Ratio: 17, Epoch 729, Loss: 5.159884\n",
      "SNR Ratio: 17, Epoch 730, Loss: 4.989639\n",
      "SNR Ratio: 17, Epoch 731, Loss: 5.497121\n",
      "SNR Ratio: 17, Epoch 732, Loss: 6.217819\n",
      "SNR Ratio: 17, Epoch 733, Loss: 6.263561\n",
      "SNR Ratio: 17, Epoch 734, Loss: 6.387034\n",
      "SNR Ratio: 17, Epoch 735, Loss: 6.317498\n",
      "SNR Ratio: 17, Epoch 736, Loss: 7.268077\n",
      "SNR Ratio: 17, Epoch 737, Loss: 6.547858\n",
      "SNR Ratio: 17, Epoch 738, Loss: 6.685551\n",
      "SNR Ratio: 17, Epoch 739, Loss: 8.417851\n",
      "SNR Ratio: 17, Epoch 740, Loss: 6.670245\n",
      "SNR Ratio: 17, Epoch 741, Loss: 6.750101\n",
      "SNR Ratio: 17, Epoch 742, Loss: 5.784725\n",
      "SNR Ratio: 17, Epoch 743, Loss: 5.178916\n",
      "SNR Ratio: 17, Epoch 744, Loss: 5.734736\n",
      "SNR Ratio: 17, Epoch 745, Loss: 5.662373\n",
      "SNR Ratio: 17, Epoch 746, Loss: 6.052104\n",
      "SNR Ratio: 17, Epoch 747, Loss: 5.484932\n",
      "SNR Ratio: 17, Epoch 748, Loss: 5.779585\n",
      "SNR Ratio: 17, Epoch 749, Loss: 5.895089\n",
      "SNR Ratio: 17, Epoch 750, Loss: 5.037077\n",
      "SNR Ratio: 17, Epoch 751, Loss: 5.042046\n",
      "SNR Ratio: 17, Epoch 752, Loss: 5.959051\n",
      "SNR Ratio: 17, Epoch 753, Loss: 6.484119\n",
      "SNR Ratio: 17, Epoch 754, Loss: 5.253977\n",
      "SNR Ratio: 17, Epoch 755, Loss: 5.342981\n",
      "SNR Ratio: 17, Epoch 756, Loss: 5.972841\n",
      "SNR Ratio: 17, Epoch 757, Loss: 5.229748\n",
      "SNR Ratio: 17, Epoch 758, Loss: 5.538977\n",
      "SNR Ratio: 17, Epoch 759, Loss: 5.748320\n",
      "SNR Ratio: 17, Epoch 760, Loss: 5.365474\n",
      "SNR Ratio: 17, Epoch 761, Loss: 5.818412\n",
      "SNR Ratio: 17, Epoch 762, Loss: 5.682047\n",
      "SNR Ratio: 17, Epoch 763, Loss: 4.813248\n",
      "SNR Ratio: 17, Epoch 764, Loss: 5.252733\n",
      "SNR Ratio: 17, Epoch 765, Loss: 5.210029\n",
      "SNR Ratio: 17, Epoch 766, Loss: 6.535896\n",
      "SNR Ratio: 17, Epoch 767, Loss: 5.739580\n",
      "SNR Ratio: 17, Epoch 768, Loss: 5.465221\n",
      "SNR Ratio: 17, Epoch 769, Loss: 7.154795\n",
      "SNR Ratio: 17, Epoch 770, Loss: 6.342500\n",
      "SNR Ratio: 17, Epoch 771, Loss: 5.288892\n",
      "SNR Ratio: 17, Epoch 772, Loss: 5.268435\n",
      "SNR Ratio: 17, Epoch 773, Loss: 5.834716\n",
      "SNR Ratio: 17, Epoch 774, Loss: 5.493541\n",
      "SNR Ratio: 17, Epoch 775, Loss: 5.157971\n",
      "SNR Ratio: 17, Epoch 776, Loss: 6.324124\n",
      "SNR Ratio: 17, Epoch 777, Loss: 5.235710\n",
      "SNR Ratio: 17, Epoch 778, Loss: 7.052820\n",
      "SNR Ratio: 17, Epoch 779, Loss: 6.266979\n",
      "SNR Ratio: 17, Epoch 780, Loss: 5.978690\n",
      "SNR Ratio: 17, Epoch 781, Loss: 5.812957\n",
      "SNR Ratio: 17, Epoch 782, Loss: 5.446091\n",
      "SNR Ratio: 17, Epoch 783, Loss: 5.194315\n",
      "SNR Ratio: 17, Epoch 784, Loss: 6.026763\n",
      "SNR Ratio: 17, Epoch 785, Loss: 5.766824\n",
      "SNR Ratio: 17, Epoch 786, Loss: 5.241372\n",
      "SNR Ratio: 17, Epoch 787, Loss: 5.439091\n",
      "SNR Ratio: 17, Epoch 788, Loss: 5.462058\n",
      "SNR Ratio: 17, Epoch 789, Loss: 4.715478\n",
      "SNR Ratio: 17, Epoch 790, Loss: 6.065159\n",
      "SNR Ratio: 17, Epoch 791, Loss: 5.535595\n",
      "SNR Ratio: 17, Epoch 792, Loss: 5.130220\n",
      "SNR Ratio: 17, Epoch 793, Loss: 6.141046\n",
      "SNR Ratio: 17, Epoch 794, Loss: 4.877409\n",
      "SNR Ratio: 17, Epoch 795, Loss: 6.333720\n",
      "SNR Ratio: 17, Epoch 796, Loss: 4.859123\n",
      "SNR Ratio: 17, Epoch 797, Loss: 4.155097\n",
      "SNR Ratio: 17, Epoch 798, Loss: 5.443005\n",
      "SNR Ratio: 17, Epoch 799, Loss: 5.225269\n",
      "SNR Ratio: 17, Epoch 800, Loss: 5.056413\n",
      "SNR Ratio: 17, Epoch 801, Loss: 5.617375\n",
      "SNR Ratio: 17, Epoch 802, Loss: 4.828464\n",
      "SNR Ratio: 17, Epoch 803, Loss: 6.265325\n",
      "SNR Ratio: 17, Epoch 804, Loss: 5.673770\n",
      "SNR Ratio: 17, Epoch 805, Loss: 4.936484\n",
      "SNR Ratio: 17, Epoch 806, Loss: 5.658719\n",
      "SNR Ratio: 17, Epoch 807, Loss: 5.143214\n",
      "SNR Ratio: 17, Epoch 808, Loss: 5.977489\n",
      "SNR Ratio: 17, Epoch 809, Loss: 5.672158\n",
      "SNR Ratio: 17, Epoch 810, Loss: 5.247624\n",
      "SNR Ratio: 17, Epoch 811, Loss: 5.615172\n",
      "SNR Ratio: 17, Epoch 812, Loss: 5.662890\n",
      "SNR Ratio: 17, Epoch 813, Loss: 5.565801\n",
      "SNR Ratio: 17, Epoch 814, Loss: 7.700629\n",
      "SNR Ratio: 17, Epoch 815, Loss: 6.533402\n",
      "SNR Ratio: 17, Epoch 816, Loss: 7.159152\n",
      "SNR Ratio: 17, Epoch 817, Loss: 7.392305\n",
      "SNR Ratio: 17, Epoch 818, Loss: 5.763448\n",
      "SNR Ratio: 17, Epoch 819, Loss: 6.030425\n",
      "SNR Ratio: 17, Epoch 820, Loss: 6.045592\n",
      "SNR Ratio: 17, Epoch 821, Loss: 5.210712\n",
      "SNR Ratio: 17, Epoch 822, Loss: 4.999194\n",
      "SNR Ratio: 17, Epoch 823, Loss: 4.716977\n",
      "SNR Ratio: 17, Epoch 824, Loss: 4.562316\n",
      "SNR Ratio: 17, Epoch 825, Loss: 4.961496\n",
      "SNR Ratio: 17, Epoch 826, Loss: 5.001815\n",
      "SNR Ratio: 17, Epoch 827, Loss: 6.824454\n",
      "SNR Ratio: 17, Epoch 828, Loss: 4.977163\n",
      "SNR Ratio: 17, Epoch 829, Loss: 4.956582\n",
      "SNR Ratio: 17, Epoch 830, Loss: 4.931052\n",
      "SNR Ratio: 17, Epoch 831, Loss: 5.505635\n",
      "SNR Ratio: 17, Epoch 832, Loss: 6.489528\n",
      "SNR Ratio: 17, Epoch 833, Loss: 6.984787\n",
      "SNR Ratio: 17, Epoch 834, Loss: 5.825465\n",
      "SNR Ratio: 17, Epoch 835, Loss: 5.612792\n",
      "SNR Ratio: 17, Epoch 836, Loss: 5.406145\n",
      "SNR Ratio: 17, Epoch 837, Loss: 5.302507\n",
      "SNR Ratio: 17, Epoch 838, Loss: 5.032886\n",
      "SNR Ratio: 17, Epoch 839, Loss: 4.711608\n",
      "SNR Ratio: 17, Epoch 840, Loss: 5.832963\n",
      "SNR Ratio: 17, Epoch 841, Loss: 5.804537\n",
      "SNR Ratio: 17, Epoch 842, Loss: 5.023363\n",
      "SNR Ratio: 17, Epoch 843, Loss: 6.041901\n",
      "SNR Ratio: 17, Epoch 844, Loss: 5.135896\n",
      "SNR Ratio: 17, Epoch 845, Loss: 5.066515\n",
      "SNR Ratio: 17, Epoch 846, Loss: 5.376002\n",
      "SNR Ratio: 17, Epoch 847, Loss: 5.332876\n",
      "SNR Ratio: 17, Epoch 848, Loss: 5.137290\n",
      "SNR Ratio: 17, Epoch 849, Loss: 5.056417\n",
      "SNR Ratio: 17, Epoch 850, Loss: 6.169218\n",
      "SNR Ratio: 17, Epoch 851, Loss: 6.000699\n",
      "SNR Ratio: 17, Epoch 852, Loss: 5.864482\n",
      "SNR Ratio: 17, Epoch 853, Loss: 4.990803\n",
      "SNR Ratio: 17, Epoch 854, Loss: 4.707763\n",
      "SNR Ratio: 17, Epoch 855, Loss: 4.799808\n",
      "SNR Ratio: 17, Epoch 856, Loss: 5.181422\n",
      "SNR Ratio: 17, Epoch 857, Loss: 4.797524\n",
      "SNR Ratio: 17, Epoch 858, Loss: 4.851029\n",
      "SNR Ratio: 17, Epoch 859, Loss: 4.312479\n",
      "SNR Ratio: 17, Epoch 860, Loss: 6.268393\n",
      "SNR Ratio: 17, Epoch 861, Loss: 5.241948\n",
      "SNR Ratio: 17, Epoch 862, Loss: 5.287683\n",
      "SNR Ratio: 17, Epoch 863, Loss: 5.212662\n",
      "SNR Ratio: 17, Epoch 864, Loss: 5.410089\n",
      "SNR Ratio: 17, Epoch 865, Loss: 4.800207\n",
      "SNR Ratio: 17, Epoch 866, Loss: 5.729306\n",
      "SNR Ratio: 17, Epoch 867, Loss: 5.762615\n",
      "SNR Ratio: 17, Epoch 868, Loss: 8.241659\n",
      "SNR Ratio: 17, Epoch 869, Loss: 6.361095\n",
      "SNR Ratio: 17, Epoch 870, Loss: 5.855891\n",
      "SNR Ratio: 17, Epoch 871, Loss: 5.098199\n",
      "SNR Ratio: 17, Epoch 872, Loss: 5.349420\n",
      "SNR Ratio: 17, Epoch 873, Loss: 4.928099\n",
      "SNR Ratio: 17, Epoch 874, Loss: 4.947284\n",
      "SNR Ratio: 17, Epoch 875, Loss: 5.564095\n",
      "SNR Ratio: 17, Epoch 876, Loss: 5.695030\n",
      "SNR Ratio: 17, Epoch 877, Loss: 5.526833\n",
      "SNR Ratio: 17, Epoch 878, Loss: 4.761141\n",
      "SNR Ratio: 17, Epoch 879, Loss: 5.219279\n",
      "SNR Ratio: 17, Epoch 880, Loss: 4.479192\n",
      "SNR Ratio: 17, Epoch 881, Loss: 4.753759\n",
      "SNR Ratio: 17, Epoch 882, Loss: 5.684672\n",
      "SNR Ratio: 17, Epoch 883, Loss: 5.613139\n",
      "SNR Ratio: 17, Epoch 884, Loss: 5.043811\n",
      "SNR Ratio: 17, Epoch 885, Loss: 5.612671\n",
      "SNR Ratio: 17, Epoch 886, Loss: 4.977340\n",
      "SNR Ratio: 17, Epoch 887, Loss: 5.065816\n",
      "SNR Ratio: 17, Epoch 888, Loss: 5.537334\n",
      "SNR Ratio: 17, Epoch 889, Loss: 5.173056\n",
      "SNR Ratio: 17, Epoch 890, Loss: 5.544109\n",
      "SNR Ratio: 17, Epoch 891, Loss: 8.759200\n",
      "SNR Ratio: 17, Epoch 892, Loss: 5.486282\n",
      "SNR Ratio: 17, Epoch 893, Loss: 5.261996\n",
      "SNR Ratio: 17, Epoch 894, Loss: 4.969661\n",
      "SNR Ratio: 17, Epoch 895, Loss: 5.149205\n",
      "SNR Ratio: 17, Epoch 896, Loss: 5.606624\n",
      "SNR Ratio: 17, Epoch 897, Loss: 6.161250\n",
      "Stopped early after 898 epochs, with loss 4.155097\n",
      "SNR Ratio: 20, Epoch 1, Loss: 331.052094\n",
      "SNR Ratio: 20, Epoch 2, Loss: 329.472931\n",
      "SNR Ratio: 20, Epoch 3, Loss: 312.256287\n",
      "SNR Ratio: 20, Epoch 4, Loss: 265.558289\n",
      "SNR Ratio: 20, Epoch 5, Loss: 246.203827\n",
      "SNR Ratio: 20, Epoch 6, Loss: 211.381760\n",
      "SNR Ratio: 20, Epoch 7, Loss: 198.621078\n",
      "SNR Ratio: 20, Epoch 8, Loss: 184.965424\n",
      "SNR Ratio: 20, Epoch 9, Loss: 167.933685\n",
      "SNR Ratio: 20, Epoch 10, Loss: 152.516327\n",
      "SNR Ratio: 20, Epoch 11, Loss: 150.307281\n",
      "SNR Ratio: 20, Epoch 12, Loss: 138.750763\n",
      "SNR Ratio: 20, Epoch 13, Loss: 134.525055\n",
      "SNR Ratio: 20, Epoch 14, Loss: 132.443634\n",
      "SNR Ratio: 20, Epoch 15, Loss: 127.328758\n",
      "SNR Ratio: 20, Epoch 16, Loss: 123.703140\n",
      "SNR Ratio: 20, Epoch 17, Loss: 118.326569\n",
      "SNR Ratio: 20, Epoch 18, Loss: 115.561043\n",
      "SNR Ratio: 20, Epoch 19, Loss: 114.423683\n",
      "SNR Ratio: 20, Epoch 20, Loss: 111.677063\n",
      "SNR Ratio: 20, Epoch 21, Loss: 109.948059\n",
      "SNR Ratio: 20, Epoch 22, Loss: 108.914078\n",
      "SNR Ratio: 20, Epoch 23, Loss: 107.539490\n",
      "SNR Ratio: 20, Epoch 24, Loss: 105.750763\n",
      "SNR Ratio: 20, Epoch 25, Loss: 100.579163\n",
      "SNR Ratio: 20, Epoch 26, Loss: 104.212189\n",
      "SNR Ratio: 20, Epoch 27, Loss: 104.292458\n",
      "SNR Ratio: 20, Epoch 28, Loss: 103.284851\n",
      "SNR Ratio: 20, Epoch 29, Loss: 100.350281\n",
      "SNR Ratio: 20, Epoch 30, Loss: 99.096809\n",
      "SNR Ratio: 20, Epoch 31, Loss: 101.370842\n",
      "SNR Ratio: 20, Epoch 32, Loss: 97.435059\n",
      "SNR Ratio: 20, Epoch 33, Loss: 95.060707\n",
      "SNR Ratio: 20, Epoch 34, Loss: 93.966072\n",
      "SNR Ratio: 20, Epoch 35, Loss: 94.397926\n",
      "SNR Ratio: 20, Epoch 36, Loss: 93.934387\n",
      "SNR Ratio: 20, Epoch 37, Loss: 91.390549\n",
      "SNR Ratio: 20, Epoch 38, Loss: 91.315010\n",
      "SNR Ratio: 20, Epoch 39, Loss: 89.806839\n",
      "SNR Ratio: 20, Epoch 40, Loss: 92.451073\n",
      "SNR Ratio: 20, Epoch 41, Loss: 89.380859\n",
      "SNR Ratio: 20, Epoch 42, Loss: 87.189011\n",
      "SNR Ratio: 20, Epoch 43, Loss: 89.411118\n",
      "SNR Ratio: 20, Epoch 44, Loss: 89.307503\n",
      "SNR Ratio: 20, Epoch 45, Loss: 87.666443\n",
      "SNR Ratio: 20, Epoch 46, Loss: 88.825569\n",
      "SNR Ratio: 20, Epoch 47, Loss: 85.740936\n",
      "SNR Ratio: 20, Epoch 48, Loss: 85.754021\n",
      "SNR Ratio: 20, Epoch 49, Loss: 82.726646\n",
      "SNR Ratio: 20, Epoch 50, Loss: 82.623802\n",
      "SNR Ratio: 20, Epoch 51, Loss: 82.772728\n",
      "SNR Ratio: 20, Epoch 52, Loss: 83.978104\n",
      "SNR Ratio: 20, Epoch 53, Loss: 82.014008\n",
      "SNR Ratio: 20, Epoch 54, Loss: 81.722710\n",
      "SNR Ratio: 20, Epoch 55, Loss: 84.818031\n",
      "SNR Ratio: 20, Epoch 56, Loss: 80.596519\n",
      "SNR Ratio: 20, Epoch 57, Loss: 79.450233\n",
      "SNR Ratio: 20, Epoch 58, Loss: 80.741432\n",
      "SNR Ratio: 20, Epoch 59, Loss: 80.214043\n",
      "SNR Ratio: 20, Epoch 60, Loss: 81.810722\n",
      "SNR Ratio: 20, Epoch 61, Loss: 79.662231\n",
      "SNR Ratio: 20, Epoch 62, Loss: 78.488876\n",
      "SNR Ratio: 20, Epoch 63, Loss: 79.557953\n",
      "SNR Ratio: 20, Epoch 64, Loss: 80.768784\n",
      "SNR Ratio: 20, Epoch 65, Loss: 79.350967\n",
      "SNR Ratio: 20, Epoch 66, Loss: 77.196823\n",
      "SNR Ratio: 20, Epoch 67, Loss: 80.572151\n",
      "SNR Ratio: 20, Epoch 68, Loss: 79.814812\n",
      "SNR Ratio: 20, Epoch 69, Loss: 76.628487\n",
      "SNR Ratio: 20, Epoch 70, Loss: 77.967117\n",
      "SNR Ratio: 20, Epoch 71, Loss: 77.476707\n",
      "SNR Ratio: 20, Epoch 72, Loss: 74.322548\n",
      "SNR Ratio: 20, Epoch 73, Loss: 76.466316\n",
      "SNR Ratio: 20, Epoch 74, Loss: 76.265221\n",
      "SNR Ratio: 20, Epoch 75, Loss: 74.274590\n",
      "SNR Ratio: 20, Epoch 76, Loss: 76.099327\n",
      "SNR Ratio: 20, Epoch 77, Loss: 74.710907\n",
      "SNR Ratio: 20, Epoch 78, Loss: 75.248596\n",
      "SNR Ratio: 20, Epoch 79, Loss: 73.202988\n",
      "SNR Ratio: 20, Epoch 80, Loss: 72.526550\n",
      "SNR Ratio: 20, Epoch 81, Loss: 72.924507\n",
      "SNR Ratio: 20, Epoch 82, Loss: 75.095100\n",
      "SNR Ratio: 20, Epoch 83, Loss: 73.423378\n",
      "SNR Ratio: 20, Epoch 84, Loss: 75.415558\n",
      "SNR Ratio: 20, Epoch 85, Loss: 71.064651\n",
      "SNR Ratio: 20, Epoch 86, Loss: 72.490738\n",
      "SNR Ratio: 20, Epoch 87, Loss: 69.807823\n",
      "SNR Ratio: 20, Epoch 88, Loss: 71.922661\n",
      "SNR Ratio: 20, Epoch 89, Loss: 71.163101\n",
      "SNR Ratio: 20, Epoch 90, Loss: 72.319672\n",
      "SNR Ratio: 20, Epoch 91, Loss: 72.296318\n",
      "SNR Ratio: 20, Epoch 92, Loss: 71.486824\n",
      "SNR Ratio: 20, Epoch 93, Loss: 71.703827\n",
      "SNR Ratio: 20, Epoch 94, Loss: 70.837898\n",
      "SNR Ratio: 20, Epoch 95, Loss: 71.641388\n",
      "SNR Ratio: 20, Epoch 96, Loss: 70.728310\n",
      "SNR Ratio: 20, Epoch 97, Loss: 69.296173\n",
      "SNR Ratio: 20, Epoch 98, Loss: 72.079430\n",
      "SNR Ratio: 20, Epoch 99, Loss: 69.759987\n",
      "SNR Ratio: 20, Epoch 100, Loss: 69.492935\n",
      "SNR Ratio: 20, Epoch 101, Loss: 70.101334\n",
      "SNR Ratio: 20, Epoch 102, Loss: 69.584198\n",
      "SNR Ratio: 20, Epoch 103, Loss: 68.250854\n",
      "SNR Ratio: 20, Epoch 104, Loss: 70.092018\n",
      "SNR Ratio: 20, Epoch 105, Loss: 70.471252\n",
      "SNR Ratio: 20, Epoch 106, Loss: 70.095627\n",
      "SNR Ratio: 20, Epoch 107, Loss: 70.485992\n",
      "SNR Ratio: 20, Epoch 108, Loss: 70.559196\n",
      "SNR Ratio: 20, Epoch 109, Loss: 66.193466\n",
      "SNR Ratio: 20, Epoch 110, Loss: 66.463737\n",
      "SNR Ratio: 20, Epoch 111, Loss: 68.891792\n",
      "SNR Ratio: 20, Epoch 112, Loss: 65.979286\n",
      "SNR Ratio: 20, Epoch 113, Loss: 68.063828\n",
      "SNR Ratio: 20, Epoch 114, Loss: 66.721420\n",
      "SNR Ratio: 20, Epoch 115, Loss: 68.084213\n",
      "SNR Ratio: 20, Epoch 116, Loss: 68.798248\n",
      "SNR Ratio: 20, Epoch 117, Loss: 66.923630\n",
      "SNR Ratio: 20, Epoch 118, Loss: 65.445618\n",
      "SNR Ratio: 20, Epoch 119, Loss: 66.701714\n",
      "SNR Ratio: 20, Epoch 120, Loss: 67.593719\n",
      "SNR Ratio: 20, Epoch 121, Loss: 65.708862\n",
      "SNR Ratio: 20, Epoch 122, Loss: 67.032028\n",
      "SNR Ratio: 20, Epoch 123, Loss: 66.625038\n",
      "SNR Ratio: 20, Epoch 124, Loss: 66.937134\n",
      "SNR Ratio: 20, Epoch 125, Loss: 66.980492\n",
      "SNR Ratio: 20, Epoch 126, Loss: 65.534698\n",
      "SNR Ratio: 20, Epoch 127, Loss: 67.121574\n",
      "SNR Ratio: 20, Epoch 128, Loss: 65.439919\n",
      "SNR Ratio: 20, Epoch 129, Loss: 67.329079\n",
      "SNR Ratio: 20, Epoch 130, Loss: 64.339561\n",
      "SNR Ratio: 20, Epoch 131, Loss: 64.976883\n",
      "SNR Ratio: 20, Epoch 132, Loss: 64.463852\n",
      "SNR Ratio: 20, Epoch 133, Loss: 64.715912\n",
      "SNR Ratio: 20, Epoch 134, Loss: 62.041740\n",
      "SNR Ratio: 20, Epoch 135, Loss: 64.931427\n",
      "SNR Ratio: 20, Epoch 136, Loss: 63.075260\n",
      "SNR Ratio: 20, Epoch 137, Loss: 65.575066\n",
      "SNR Ratio: 20, Epoch 138, Loss: 64.289436\n",
      "SNR Ratio: 20, Epoch 139, Loss: 64.020782\n",
      "SNR Ratio: 20, Epoch 140, Loss: 61.391899\n",
      "SNR Ratio: 20, Epoch 141, Loss: 62.603611\n",
      "SNR Ratio: 20, Epoch 142, Loss: 63.493038\n",
      "SNR Ratio: 20, Epoch 143, Loss: 64.871468\n",
      "SNR Ratio: 20, Epoch 144, Loss: 61.309711\n",
      "SNR Ratio: 20, Epoch 145, Loss: 62.646389\n",
      "SNR Ratio: 20, Epoch 146, Loss: 62.087791\n",
      "SNR Ratio: 20, Epoch 147, Loss: 62.178589\n",
      "SNR Ratio: 20, Epoch 148, Loss: 61.964764\n",
      "SNR Ratio: 20, Epoch 149, Loss: 62.679230\n",
      "SNR Ratio: 20, Epoch 150, Loss: 63.365730\n",
      "SNR Ratio: 20, Epoch 151, Loss: 61.810349\n",
      "SNR Ratio: 20, Epoch 152, Loss: 63.976830\n",
      "SNR Ratio: 20, Epoch 153, Loss: 61.995579\n",
      "SNR Ratio: 20, Epoch 154, Loss: 61.699081\n",
      "SNR Ratio: 20, Epoch 155, Loss: 61.910549\n",
      "SNR Ratio: 20, Epoch 156, Loss: 61.059525\n",
      "SNR Ratio: 20, Epoch 157, Loss: 63.256294\n",
      "SNR Ratio: 20, Epoch 158, Loss: 62.707375\n",
      "SNR Ratio: 20, Epoch 159, Loss: 63.167984\n",
      "SNR Ratio: 20, Epoch 160, Loss: 62.275970\n",
      "SNR Ratio: 20, Epoch 161, Loss: 61.886669\n",
      "SNR Ratio: 20, Epoch 162, Loss: 59.120010\n",
      "SNR Ratio: 20, Epoch 163, Loss: 61.785606\n",
      "SNR Ratio: 20, Epoch 164, Loss: 58.755119\n",
      "SNR Ratio: 20, Epoch 165, Loss: 58.910221\n",
      "SNR Ratio: 20, Epoch 166, Loss: 60.160809\n",
      "SNR Ratio: 20, Epoch 167, Loss: 60.535389\n",
      "SNR Ratio: 20, Epoch 168, Loss: 61.164886\n",
      "SNR Ratio: 20, Epoch 169, Loss: 59.649063\n",
      "SNR Ratio: 20, Epoch 170, Loss: 60.476799\n",
      "SNR Ratio: 20, Epoch 171, Loss: 61.419930\n",
      "SNR Ratio: 20, Epoch 172, Loss: 59.491329\n",
      "SNR Ratio: 20, Epoch 173, Loss: 62.393768\n",
      "SNR Ratio: 20, Epoch 174, Loss: 59.461552\n",
      "SNR Ratio: 20, Epoch 175, Loss: 61.515419\n",
      "SNR Ratio: 20, Epoch 176, Loss: 58.210678\n",
      "SNR Ratio: 20, Epoch 177, Loss: 58.386662\n",
      "SNR Ratio: 20, Epoch 178, Loss: 59.357269\n",
      "SNR Ratio: 20, Epoch 179, Loss: 57.552582\n",
      "SNR Ratio: 20, Epoch 180, Loss: 59.208080\n",
      "SNR Ratio: 20, Epoch 181, Loss: 58.814201\n",
      "SNR Ratio: 20, Epoch 182, Loss: 58.007214\n",
      "SNR Ratio: 20, Epoch 183, Loss: 59.493721\n",
      "SNR Ratio: 20, Epoch 184, Loss: 58.279789\n",
      "SNR Ratio: 20, Epoch 185, Loss: 59.413239\n",
      "SNR Ratio: 20, Epoch 186, Loss: 58.516312\n",
      "SNR Ratio: 20, Epoch 187, Loss: 60.268742\n",
      "SNR Ratio: 20, Epoch 188, Loss: 60.474430\n",
      "SNR Ratio: 20, Epoch 189, Loss: 59.382118\n",
      "SNR Ratio: 20, Epoch 190, Loss: 59.993000\n",
      "SNR Ratio: 20, Epoch 191, Loss: 60.447922\n",
      "SNR Ratio: 20, Epoch 192, Loss: 57.264820\n",
      "SNR Ratio: 20, Epoch 193, Loss: 58.694618\n",
      "SNR Ratio: 20, Epoch 194, Loss: 58.945110\n",
      "SNR Ratio: 20, Epoch 195, Loss: 57.610432\n",
      "SNR Ratio: 20, Epoch 196, Loss: 58.388229\n",
      "SNR Ratio: 20, Epoch 197, Loss: 56.811626\n",
      "SNR Ratio: 20, Epoch 198, Loss: 56.515556\n",
      "SNR Ratio: 20, Epoch 199, Loss: 59.244431\n",
      "SNR Ratio: 20, Epoch 200, Loss: 57.252071\n",
      "SNR Ratio: 20, Epoch 201, Loss: 58.362850\n",
      "SNR Ratio: 20, Epoch 202, Loss: 56.160934\n",
      "SNR Ratio: 20, Epoch 203, Loss: 59.174011\n",
      "SNR Ratio: 20, Epoch 204, Loss: 58.117325\n",
      "SNR Ratio: 20, Epoch 205, Loss: 56.228001\n",
      "SNR Ratio: 20, Epoch 206, Loss: 57.734951\n",
      "SNR Ratio: 20, Epoch 207, Loss: 59.191605\n",
      "SNR Ratio: 20, Epoch 208, Loss: 55.727474\n",
      "SNR Ratio: 20, Epoch 209, Loss: 55.673931\n",
      "SNR Ratio: 20, Epoch 210, Loss: 58.062035\n",
      "SNR Ratio: 20, Epoch 211, Loss: 55.180374\n",
      "SNR Ratio: 20, Epoch 212, Loss: 56.294460\n",
      "SNR Ratio: 20, Epoch 213, Loss: 57.902077\n",
      "SNR Ratio: 20, Epoch 214, Loss: 57.475658\n",
      "SNR Ratio: 20, Epoch 215, Loss: 57.043495\n",
      "SNR Ratio: 20, Epoch 216, Loss: 56.746006\n",
      "SNR Ratio: 20, Epoch 217, Loss: 55.490166\n",
      "SNR Ratio: 20, Epoch 218, Loss: 58.235153\n",
      "SNR Ratio: 20, Epoch 219, Loss: 57.061199\n",
      "SNR Ratio: 20, Epoch 220, Loss: 55.898281\n",
      "SNR Ratio: 20, Epoch 221, Loss: 54.074844\n",
      "SNR Ratio: 20, Epoch 222, Loss: 57.014900\n",
      "SNR Ratio: 20, Epoch 223, Loss: 56.582764\n",
      "SNR Ratio: 20, Epoch 224, Loss: 55.745815\n",
      "SNR Ratio: 20, Epoch 225, Loss: 55.163471\n",
      "SNR Ratio: 20, Epoch 226, Loss: 53.288944\n",
      "SNR Ratio: 20, Epoch 227, Loss: 55.683220\n",
      "SNR Ratio: 20, Epoch 228, Loss: 56.292091\n",
      "SNR Ratio: 20, Epoch 229, Loss: 55.815441\n",
      "SNR Ratio: 20, Epoch 230, Loss: 56.488506\n",
      "SNR Ratio: 20, Epoch 231, Loss: 53.970516\n",
      "SNR Ratio: 20, Epoch 232, Loss: 54.651733\n",
      "SNR Ratio: 20, Epoch 233, Loss: 53.995941\n",
      "SNR Ratio: 20, Epoch 234, Loss: 53.627846\n",
      "SNR Ratio: 20, Epoch 235, Loss: 54.611870\n",
      "SNR Ratio: 20, Epoch 236, Loss: 54.240780\n",
      "SNR Ratio: 20, Epoch 237, Loss: 55.301571\n",
      "SNR Ratio: 20, Epoch 238, Loss: 54.754379\n",
      "SNR Ratio: 20, Epoch 239, Loss: 54.555538\n",
      "SNR Ratio: 20, Epoch 240, Loss: 54.108971\n",
      "SNR Ratio: 20, Epoch 241, Loss: 55.102581\n",
      "SNR Ratio: 20, Epoch 242, Loss: 53.567364\n",
      "SNR Ratio: 20, Epoch 243, Loss: 54.190861\n",
      "SNR Ratio: 20, Epoch 244, Loss: 53.509476\n",
      "SNR Ratio: 20, Epoch 245, Loss: 53.983700\n",
      "SNR Ratio: 20, Epoch 246, Loss: 56.356190\n",
      "SNR Ratio: 20, Epoch 247, Loss: 53.853291\n",
      "SNR Ratio: 20, Epoch 248, Loss: 53.580330\n",
      "SNR Ratio: 20, Epoch 249, Loss: 52.856613\n",
      "SNR Ratio: 20, Epoch 250, Loss: 53.721577\n",
      "SNR Ratio: 20, Epoch 251, Loss: 53.403236\n",
      "SNR Ratio: 20, Epoch 252, Loss: 52.382420\n",
      "SNR Ratio: 20, Epoch 253, Loss: 53.060814\n",
      "SNR Ratio: 20, Epoch 254, Loss: 53.773006\n",
      "SNR Ratio: 20, Epoch 255, Loss: 51.123989\n",
      "SNR Ratio: 20, Epoch 256, Loss: 53.603374\n",
      "SNR Ratio: 20, Epoch 257, Loss: 51.386734\n",
      "SNR Ratio: 20, Epoch 258, Loss: 51.971497\n",
      "SNR Ratio: 20, Epoch 259, Loss: 54.417934\n",
      "SNR Ratio: 20, Epoch 260, Loss: 51.168404\n",
      "SNR Ratio: 20, Epoch 261, Loss: 52.423996\n",
      "SNR Ratio: 20, Epoch 262, Loss: 53.212780\n",
      "SNR Ratio: 20, Epoch 263, Loss: 52.563808\n",
      "SNR Ratio: 20, Epoch 264, Loss: 52.792019\n",
      "SNR Ratio: 20, Epoch 265, Loss: 51.957588\n",
      "SNR Ratio: 20, Epoch 266, Loss: 51.870419\n",
      "SNR Ratio: 20, Epoch 267, Loss: 51.420204\n",
      "SNR Ratio: 20, Epoch 268, Loss: 51.755699\n",
      "SNR Ratio: 20, Epoch 269, Loss: 53.325500\n",
      "SNR Ratio: 20, Epoch 270, Loss: 52.435001\n",
      "SNR Ratio: 20, Epoch 271, Loss: 50.343441\n",
      "SNR Ratio: 20, Epoch 272, Loss: 50.926338\n",
      "SNR Ratio: 20, Epoch 273, Loss: 49.177689\n",
      "SNR Ratio: 20, Epoch 274, Loss: 51.536243\n",
      "SNR Ratio: 20, Epoch 275, Loss: 49.242901\n",
      "SNR Ratio: 20, Epoch 276, Loss: 50.669704\n",
      "SNR Ratio: 20, Epoch 277, Loss: 49.203300\n",
      "SNR Ratio: 20, Epoch 278, Loss: 48.398804\n",
      "SNR Ratio: 20, Epoch 279, Loss: 48.748299\n",
      "SNR Ratio: 20, Epoch 280, Loss: 50.523041\n",
      "SNR Ratio: 20, Epoch 281, Loss: 50.844856\n",
      "SNR Ratio: 20, Epoch 282, Loss: 49.443996\n",
      "SNR Ratio: 20, Epoch 283, Loss: 47.854317\n",
      "SNR Ratio: 20, Epoch 284, Loss: 47.345772\n",
      "SNR Ratio: 20, Epoch 285, Loss: 49.779690\n",
      "SNR Ratio: 20, Epoch 286, Loss: 48.833996\n",
      "SNR Ratio: 20, Epoch 287, Loss: 50.022114\n",
      "SNR Ratio: 20, Epoch 288, Loss: 46.598999\n",
      "SNR Ratio: 20, Epoch 289, Loss: 48.628399\n",
      "SNR Ratio: 20, Epoch 290, Loss: 49.416771\n",
      "SNR Ratio: 20, Epoch 291, Loss: 47.859329\n",
      "SNR Ratio: 20, Epoch 292, Loss: 47.471771\n",
      "SNR Ratio: 20, Epoch 293, Loss: 48.921162\n",
      "SNR Ratio: 20, Epoch 294, Loss: 47.699730\n",
      "SNR Ratio: 20, Epoch 295, Loss: 46.223412\n",
      "SNR Ratio: 20, Epoch 296, Loss: 48.666576\n",
      "SNR Ratio: 20, Epoch 297, Loss: 45.533581\n",
      "SNR Ratio: 20, Epoch 298, Loss: 46.759415\n",
      "SNR Ratio: 20, Epoch 299, Loss: 46.549793\n",
      "SNR Ratio: 20, Epoch 300, Loss: 47.090500\n",
      "SNR Ratio: 20, Epoch 301, Loss: 45.554020\n",
      "SNR Ratio: 20, Epoch 302, Loss: 45.680981\n",
      "SNR Ratio: 20, Epoch 303, Loss: 46.372887\n",
      "SNR Ratio: 20, Epoch 304, Loss: 46.474258\n",
      "SNR Ratio: 20, Epoch 305, Loss: 44.816921\n",
      "SNR Ratio: 20, Epoch 306, Loss: 45.133366\n",
      "SNR Ratio: 20, Epoch 307, Loss: 45.559830\n",
      "SNR Ratio: 20, Epoch 308, Loss: 46.670036\n",
      "SNR Ratio: 20, Epoch 309, Loss: 45.532478\n",
      "SNR Ratio: 20, Epoch 310, Loss: 46.181053\n",
      "SNR Ratio: 20, Epoch 311, Loss: 44.521633\n",
      "SNR Ratio: 20, Epoch 312, Loss: 44.295170\n",
      "SNR Ratio: 20, Epoch 313, Loss: 44.753139\n",
      "SNR Ratio: 20, Epoch 314, Loss: 43.446644\n",
      "SNR Ratio: 20, Epoch 315, Loss: 44.355301\n",
      "SNR Ratio: 20, Epoch 316, Loss: 42.665691\n",
      "SNR Ratio: 20, Epoch 317, Loss: 41.536411\n",
      "SNR Ratio: 20, Epoch 318, Loss: 42.196495\n",
      "SNR Ratio: 20, Epoch 319, Loss: 41.856739\n",
      "SNR Ratio: 20, Epoch 320, Loss: 43.050640\n",
      "SNR Ratio: 20, Epoch 321, Loss: 43.077274\n",
      "SNR Ratio: 20, Epoch 322, Loss: 42.751099\n",
      "SNR Ratio: 20, Epoch 323, Loss: 43.825901\n",
      "SNR Ratio: 20, Epoch 324, Loss: 42.888706\n",
      "SNR Ratio: 20, Epoch 325, Loss: 41.622860\n",
      "SNR Ratio: 20, Epoch 326, Loss: 40.380524\n",
      "SNR Ratio: 20, Epoch 327, Loss: 39.858479\n",
      "SNR Ratio: 20, Epoch 328, Loss: 38.416409\n",
      "SNR Ratio: 20, Epoch 329, Loss: 41.355236\n",
      "SNR Ratio: 20, Epoch 330, Loss: 40.453629\n",
      "SNR Ratio: 20, Epoch 331, Loss: 41.497349\n",
      "SNR Ratio: 20, Epoch 332, Loss: 40.482853\n",
      "SNR Ratio: 20, Epoch 333, Loss: 39.581467\n",
      "SNR Ratio: 20, Epoch 334, Loss: 39.254875\n",
      "SNR Ratio: 20, Epoch 335, Loss: 40.088444\n",
      "SNR Ratio: 20, Epoch 336, Loss: 40.276539\n",
      "SNR Ratio: 20, Epoch 337, Loss: 38.982124\n",
      "SNR Ratio: 20, Epoch 338, Loss: 38.727764\n",
      "SNR Ratio: 20, Epoch 339, Loss: 38.737495\n",
      "SNR Ratio: 20, Epoch 340, Loss: 37.261517\n",
      "SNR Ratio: 20, Epoch 341, Loss: 37.175720\n",
      "SNR Ratio: 20, Epoch 342, Loss: 36.471516\n",
      "SNR Ratio: 20, Epoch 343, Loss: 35.882385\n",
      "SNR Ratio: 20, Epoch 344, Loss: 36.349258\n",
      "SNR Ratio: 20, Epoch 345, Loss: 38.124336\n",
      "SNR Ratio: 20, Epoch 346, Loss: 36.909924\n",
      "SNR Ratio: 20, Epoch 347, Loss: 35.718250\n",
      "SNR Ratio: 20, Epoch 348, Loss: 36.190372\n",
      "SNR Ratio: 20, Epoch 349, Loss: 35.512878\n",
      "SNR Ratio: 20, Epoch 350, Loss: 34.192604\n",
      "SNR Ratio: 20, Epoch 351, Loss: 34.117207\n",
      "SNR Ratio: 20, Epoch 352, Loss: 34.631371\n",
      "SNR Ratio: 20, Epoch 353, Loss: 31.662195\n",
      "SNR Ratio: 20, Epoch 354, Loss: 33.537155\n",
      "SNR Ratio: 20, Epoch 355, Loss: 33.666996\n",
      "SNR Ratio: 20, Epoch 356, Loss: 34.305695\n",
      "SNR Ratio: 20, Epoch 357, Loss: 32.034199\n",
      "SNR Ratio: 20, Epoch 358, Loss: 31.019037\n",
      "SNR Ratio: 20, Epoch 359, Loss: 30.471693\n",
      "SNR Ratio: 20, Epoch 360, Loss: 30.352039\n",
      "SNR Ratio: 20, Epoch 361, Loss: 30.428335\n",
      "SNR Ratio: 20, Epoch 362, Loss: 32.218182\n",
      "SNR Ratio: 20, Epoch 363, Loss: 32.264385\n",
      "SNR Ratio: 20, Epoch 364, Loss: 28.970335\n",
      "SNR Ratio: 20, Epoch 365, Loss: 29.946753\n",
      "SNR Ratio: 20, Epoch 366, Loss: 29.970543\n",
      "SNR Ratio: 20, Epoch 367, Loss: 28.217436\n",
      "SNR Ratio: 20, Epoch 368, Loss: 29.526173\n",
      "SNR Ratio: 20, Epoch 369, Loss: 29.580111\n",
      "SNR Ratio: 20, Epoch 370, Loss: 29.707392\n",
      "SNR Ratio: 20, Epoch 371, Loss: 27.522961\n",
      "SNR Ratio: 20, Epoch 372, Loss: 27.227955\n",
      "SNR Ratio: 20, Epoch 373, Loss: 29.292122\n",
      "SNR Ratio: 20, Epoch 374, Loss: 26.047672\n",
      "SNR Ratio: 20, Epoch 375, Loss: 26.118027\n",
      "SNR Ratio: 20, Epoch 376, Loss: 25.615419\n",
      "SNR Ratio: 20, Epoch 377, Loss: 27.019350\n",
      "SNR Ratio: 20, Epoch 378, Loss: 27.184975\n",
      "SNR Ratio: 20, Epoch 379, Loss: 25.355221\n",
      "SNR Ratio: 20, Epoch 380, Loss: 25.240503\n",
      "SNR Ratio: 20, Epoch 381, Loss: 23.914505\n",
      "SNR Ratio: 20, Epoch 382, Loss: 24.551430\n",
      "SNR Ratio: 20, Epoch 383, Loss: 25.321615\n",
      "SNR Ratio: 20, Epoch 384, Loss: 24.250759\n",
      "SNR Ratio: 20, Epoch 385, Loss: 25.111792\n",
      "SNR Ratio: 20, Epoch 386, Loss: 22.785524\n",
      "SNR Ratio: 20, Epoch 387, Loss: 24.779152\n",
      "SNR Ratio: 20, Epoch 388, Loss: 23.221704\n",
      "SNR Ratio: 20, Epoch 389, Loss: 22.709202\n",
      "SNR Ratio: 20, Epoch 390, Loss: 21.982269\n",
      "SNR Ratio: 20, Epoch 391, Loss: 23.542065\n",
      "SNR Ratio: 20, Epoch 392, Loss: 20.649010\n",
      "SNR Ratio: 20, Epoch 393, Loss: 21.790951\n",
      "SNR Ratio: 20, Epoch 394, Loss: 22.776785\n",
      "SNR Ratio: 20, Epoch 395, Loss: 22.340967\n",
      "SNR Ratio: 20, Epoch 396, Loss: 20.220501\n",
      "SNR Ratio: 20, Epoch 397, Loss: 23.066902\n",
      "SNR Ratio: 20, Epoch 398, Loss: 21.727390\n",
      "SNR Ratio: 20, Epoch 399, Loss: 20.420429\n",
      "SNR Ratio: 20, Epoch 400, Loss: 21.745226\n",
      "SNR Ratio: 20, Epoch 401, Loss: 20.843571\n",
      "SNR Ratio: 20, Epoch 402, Loss: 21.511894\n",
      "SNR Ratio: 20, Epoch 403, Loss: 19.292097\n",
      "SNR Ratio: 20, Epoch 404, Loss: 17.639669\n",
      "SNR Ratio: 20, Epoch 405, Loss: 18.002871\n",
      "SNR Ratio: 20, Epoch 406, Loss: 18.566130\n",
      "SNR Ratio: 20, Epoch 407, Loss: 16.667093\n",
      "SNR Ratio: 20, Epoch 408, Loss: 18.875599\n",
      "SNR Ratio: 20, Epoch 409, Loss: 17.402004\n",
      "SNR Ratio: 20, Epoch 410, Loss: 18.044323\n",
      "SNR Ratio: 20, Epoch 411, Loss: 17.450550\n",
      "SNR Ratio: 20, Epoch 412, Loss: 17.812286\n",
      "SNR Ratio: 20, Epoch 413, Loss: 17.187132\n",
      "SNR Ratio: 20, Epoch 414, Loss: 15.926444\n",
      "SNR Ratio: 20, Epoch 415, Loss: 17.538681\n",
      "SNR Ratio: 20, Epoch 416, Loss: 16.803427\n",
      "SNR Ratio: 20, Epoch 417, Loss: 17.634335\n",
      "SNR Ratio: 20, Epoch 418, Loss: 15.421910\n",
      "SNR Ratio: 20, Epoch 419, Loss: 15.376809\n",
      "SNR Ratio: 20, Epoch 420, Loss: 15.751142\n",
      "SNR Ratio: 20, Epoch 421, Loss: 16.901831\n",
      "SNR Ratio: 20, Epoch 422, Loss: 16.826900\n",
      "SNR Ratio: 20, Epoch 423, Loss: 15.775392\n",
      "SNR Ratio: 20, Epoch 424, Loss: 17.636198\n",
      "SNR Ratio: 20, Epoch 425, Loss: 16.144930\n",
      "SNR Ratio: 20, Epoch 426, Loss: 16.507536\n",
      "SNR Ratio: 20, Epoch 427, Loss: 14.776480\n",
      "SNR Ratio: 20, Epoch 428, Loss: 17.253590\n",
      "SNR Ratio: 20, Epoch 429, Loss: 14.093310\n",
      "SNR Ratio: 20, Epoch 430, Loss: 15.603947\n",
      "SNR Ratio: 20, Epoch 431, Loss: 15.350835\n",
      "SNR Ratio: 20, Epoch 432, Loss: 15.704591\n",
      "SNR Ratio: 20, Epoch 433, Loss: 14.747160\n",
      "SNR Ratio: 20, Epoch 434, Loss: 14.253907\n",
      "SNR Ratio: 20, Epoch 435, Loss: 14.224920\n",
      "SNR Ratio: 20, Epoch 436, Loss: 12.528418\n",
      "SNR Ratio: 20, Epoch 437, Loss: 14.260110\n",
      "SNR Ratio: 20, Epoch 438, Loss: 13.587458\n",
      "SNR Ratio: 20, Epoch 439, Loss: 14.041793\n",
      "SNR Ratio: 20, Epoch 440, Loss: 13.615911\n",
      "SNR Ratio: 20, Epoch 441, Loss: 13.385869\n",
      "SNR Ratio: 20, Epoch 442, Loss: 14.012105\n",
      "SNR Ratio: 20, Epoch 443, Loss: 13.425217\n",
      "SNR Ratio: 20, Epoch 444, Loss: 13.078822\n",
      "SNR Ratio: 20, Epoch 445, Loss: 13.537415\n",
      "SNR Ratio: 20, Epoch 446, Loss: 14.410592\n",
      "SNR Ratio: 20, Epoch 447, Loss: 11.896020\n",
      "SNR Ratio: 20, Epoch 448, Loss: 14.408282\n",
      "SNR Ratio: 20, Epoch 449, Loss: 14.005982\n",
      "SNR Ratio: 20, Epoch 450, Loss: 14.188420\n",
      "SNR Ratio: 20, Epoch 451, Loss: 12.107133\n",
      "SNR Ratio: 20, Epoch 452, Loss: 11.567778\n",
      "SNR Ratio: 20, Epoch 453, Loss: 15.725798\n",
      "SNR Ratio: 20, Epoch 454, Loss: 18.297243\n",
      "SNR Ratio: 20, Epoch 455, Loss: 14.292718\n",
      "SNR Ratio: 20, Epoch 456, Loss: 11.795884\n",
      "SNR Ratio: 20, Epoch 457, Loss: 12.566400\n",
      "SNR Ratio: 20, Epoch 458, Loss: 11.200933\n",
      "SNR Ratio: 20, Epoch 459, Loss: 11.920463\n",
      "SNR Ratio: 20, Epoch 460, Loss: 11.836685\n",
      "SNR Ratio: 20, Epoch 461, Loss: 12.402227\n",
      "SNR Ratio: 20, Epoch 462, Loss: 12.896293\n",
      "SNR Ratio: 20, Epoch 463, Loss: 10.931259\n",
      "SNR Ratio: 20, Epoch 464, Loss: 12.693970\n",
      "SNR Ratio: 20, Epoch 465, Loss: 10.111472\n",
      "SNR Ratio: 20, Epoch 466, Loss: 11.397569\n",
      "SNR Ratio: 20, Epoch 467, Loss: 10.045448\n",
      "SNR Ratio: 20, Epoch 468, Loss: 11.615467\n",
      "SNR Ratio: 20, Epoch 469, Loss: 10.860236\n",
      "SNR Ratio: 20, Epoch 470, Loss: 10.621469\n",
      "SNR Ratio: 20, Epoch 471, Loss: 11.584203\n",
      "SNR Ratio: 20, Epoch 472, Loss: 9.284206\n",
      "SNR Ratio: 20, Epoch 473, Loss: 10.849278\n",
      "SNR Ratio: 20, Epoch 474, Loss: 10.465379\n",
      "SNR Ratio: 20, Epoch 475, Loss: 10.993245\n",
      "SNR Ratio: 20, Epoch 476, Loss: 9.224632\n",
      "SNR Ratio: 20, Epoch 477, Loss: 10.887265\n",
      "SNR Ratio: 20, Epoch 478, Loss: 12.860179\n",
      "SNR Ratio: 20, Epoch 479, Loss: 10.698001\n",
      "SNR Ratio: 20, Epoch 480, Loss: 11.200974\n",
      "SNR Ratio: 20, Epoch 481, Loss: 9.521494\n",
      "SNR Ratio: 20, Epoch 482, Loss: 9.516676\n",
      "SNR Ratio: 20, Epoch 483, Loss: 9.347725\n",
      "SNR Ratio: 20, Epoch 484, Loss: 10.208205\n",
      "SNR Ratio: 20, Epoch 485, Loss: 9.389764\n",
      "SNR Ratio: 20, Epoch 486, Loss: 9.721030\n",
      "SNR Ratio: 20, Epoch 487, Loss: 9.167944\n",
      "SNR Ratio: 20, Epoch 488, Loss: 9.087621\n",
      "SNR Ratio: 20, Epoch 489, Loss: 9.065775\n",
      "SNR Ratio: 20, Epoch 490, Loss: 9.139605\n",
      "SNR Ratio: 20, Epoch 491, Loss: 11.620690\n",
      "SNR Ratio: 20, Epoch 492, Loss: 12.037297\n",
      "SNR Ratio: 20, Epoch 493, Loss: 10.423840\n",
      "SNR Ratio: 20, Epoch 494, Loss: 10.572421\n",
      "SNR Ratio: 20, Epoch 495, Loss: 8.379593\n",
      "SNR Ratio: 20, Epoch 496, Loss: 8.504306\n",
      "SNR Ratio: 20, Epoch 497, Loss: 10.682035\n",
      "SNR Ratio: 20, Epoch 498, Loss: 13.494182\n",
      "SNR Ratio: 20, Epoch 499, Loss: 11.021425\n",
      "SNR Ratio: 20, Epoch 500, Loss: 8.015385\n",
      "SNR Ratio: 20, Epoch 501, Loss: 8.605763\n",
      "SNR Ratio: 20, Epoch 502, Loss: 9.538912\n",
      "SNR Ratio: 20, Epoch 503, Loss: 9.511188\n",
      "SNR Ratio: 20, Epoch 504, Loss: 9.788720\n",
      "SNR Ratio: 20, Epoch 505, Loss: 8.536793\n",
      "SNR Ratio: 20, Epoch 506, Loss: 8.171756\n",
      "SNR Ratio: 20, Epoch 507, Loss: 8.941594\n",
      "SNR Ratio: 20, Epoch 508, Loss: 8.432140\n",
      "SNR Ratio: 20, Epoch 509, Loss: 9.510976\n",
      "SNR Ratio: 20, Epoch 510, Loss: 9.298340\n",
      "SNR Ratio: 20, Epoch 511, Loss: 8.836610\n",
      "SNR Ratio: 20, Epoch 512, Loss: 7.927043\n",
      "SNR Ratio: 20, Epoch 513, Loss: 8.457369\n",
      "SNR Ratio: 20, Epoch 514, Loss: 8.162210\n",
      "SNR Ratio: 20, Epoch 515, Loss: 9.662416\n",
      "SNR Ratio: 20, Epoch 516, Loss: 9.767131\n",
      "SNR Ratio: 20, Epoch 517, Loss: 10.865370\n",
      "SNR Ratio: 20, Epoch 518, Loss: 8.831284\n",
      "SNR Ratio: 20, Epoch 519, Loss: 7.994534\n",
      "SNR Ratio: 20, Epoch 520, Loss: 8.483128\n",
      "SNR Ratio: 20, Epoch 521, Loss: 8.297460\n",
      "SNR Ratio: 20, Epoch 522, Loss: 8.271266\n",
      "SNR Ratio: 20, Epoch 523, Loss: 8.796894\n",
      "SNR Ratio: 20, Epoch 524, Loss: 8.285356\n",
      "SNR Ratio: 20, Epoch 525, Loss: 7.850432\n",
      "SNR Ratio: 20, Epoch 526, Loss: 7.956134\n",
      "SNR Ratio: 20, Epoch 527, Loss: 9.474508\n",
      "SNR Ratio: 20, Epoch 528, Loss: 8.365810\n",
      "SNR Ratio: 20, Epoch 529, Loss: 8.112728\n",
      "SNR Ratio: 20, Epoch 530, Loss: 9.381137\n",
      "SNR Ratio: 20, Epoch 531, Loss: 7.428544\n",
      "SNR Ratio: 20, Epoch 532, Loss: 6.985630\n",
      "SNR Ratio: 20, Epoch 533, Loss: 6.941471\n",
      "SNR Ratio: 20, Epoch 534, Loss: 8.396397\n",
      "SNR Ratio: 20, Epoch 535, Loss: 8.186750\n",
      "SNR Ratio: 20, Epoch 536, Loss: 7.785728\n",
      "SNR Ratio: 20, Epoch 537, Loss: 6.806882\n",
      "SNR Ratio: 20, Epoch 538, Loss: 8.236753\n",
      "SNR Ratio: 20, Epoch 539, Loss: 7.403692\n",
      "SNR Ratio: 20, Epoch 540, Loss: 7.256877\n",
      "SNR Ratio: 20, Epoch 541, Loss: 8.046667\n",
      "SNR Ratio: 20, Epoch 542, Loss: 7.660820\n",
      "SNR Ratio: 20, Epoch 543, Loss: 7.801654\n",
      "SNR Ratio: 20, Epoch 544, Loss: 7.506095\n",
      "SNR Ratio: 20, Epoch 545, Loss: 7.313107\n",
      "SNR Ratio: 20, Epoch 546, Loss: 7.260717\n",
      "SNR Ratio: 20, Epoch 547, Loss: 7.445723\n",
      "SNR Ratio: 20, Epoch 548, Loss: 7.790370\n",
      "SNR Ratio: 20, Epoch 549, Loss: 7.599829\n",
      "SNR Ratio: 20, Epoch 550, Loss: 8.579061\n",
      "SNR Ratio: 20, Epoch 551, Loss: 7.154579\n",
      "SNR Ratio: 20, Epoch 552, Loss: 6.516508\n",
      "SNR Ratio: 20, Epoch 553, Loss: 8.720359\n",
      "SNR Ratio: 20, Epoch 554, Loss: 7.887855\n",
      "SNR Ratio: 20, Epoch 555, Loss: 7.587643\n",
      "SNR Ratio: 20, Epoch 556, Loss: 9.324533\n",
      "SNR Ratio: 20, Epoch 557, Loss: 8.622655\n",
      "SNR Ratio: 20, Epoch 558, Loss: 7.474258\n",
      "SNR Ratio: 20, Epoch 559, Loss: 8.851829\n",
      "SNR Ratio: 20, Epoch 560, Loss: 9.457458\n",
      "SNR Ratio: 20, Epoch 561, Loss: 11.827257\n",
      "SNR Ratio: 20, Epoch 562, Loss: 7.268608\n",
      "SNR Ratio: 20, Epoch 563, Loss: 7.184527\n",
      "SNR Ratio: 20, Epoch 564, Loss: 7.356675\n",
      "SNR Ratio: 20, Epoch 565, Loss: 6.797004\n",
      "SNR Ratio: 20, Epoch 566, Loss: 6.393110\n",
      "SNR Ratio: 20, Epoch 567, Loss: 6.648364\n",
      "SNR Ratio: 20, Epoch 568, Loss: 6.297410\n",
      "SNR Ratio: 20, Epoch 569, Loss: 7.755747\n",
      "SNR Ratio: 20, Epoch 570, Loss: 7.094420\n",
      "SNR Ratio: 20, Epoch 571, Loss: 5.499803\n",
      "SNR Ratio: 20, Epoch 572, Loss: 5.995502\n",
      "SNR Ratio: 20, Epoch 573, Loss: 6.977884\n",
      "SNR Ratio: 20, Epoch 574, Loss: 6.916068\n",
      "SNR Ratio: 20, Epoch 575, Loss: 7.731629\n",
      "SNR Ratio: 20, Epoch 576, Loss: 10.591323\n",
      "SNR Ratio: 20, Epoch 577, Loss: 6.784278\n",
      "SNR Ratio: 20, Epoch 578, Loss: 6.750640\n",
      "SNR Ratio: 20, Epoch 579, Loss: 7.217229\n",
      "SNR Ratio: 20, Epoch 580, Loss: 5.649281\n",
      "SNR Ratio: 20, Epoch 581, Loss: 6.190378\n",
      "SNR Ratio: 20, Epoch 582, Loss: 7.763903\n",
      "SNR Ratio: 20, Epoch 583, Loss: 8.763051\n",
      "SNR Ratio: 20, Epoch 584, Loss: 7.680205\n",
      "SNR Ratio: 20, Epoch 585, Loss: 8.646572\n",
      "SNR Ratio: 20, Epoch 586, Loss: 6.679544\n",
      "SNR Ratio: 20, Epoch 587, Loss: 6.518780\n",
      "SNR Ratio: 20, Epoch 588, Loss: 5.074268\n",
      "SNR Ratio: 20, Epoch 589, Loss: 6.487061\n",
      "SNR Ratio: 20, Epoch 590, Loss: 7.323583\n",
      "SNR Ratio: 20, Epoch 591, Loss: 6.581167\n",
      "SNR Ratio: 20, Epoch 592, Loss: 6.713054\n",
      "SNR Ratio: 20, Epoch 593, Loss: 5.417488\n",
      "SNR Ratio: 20, Epoch 594, Loss: 6.935994\n",
      "SNR Ratio: 20, Epoch 595, Loss: 8.006976\n",
      "SNR Ratio: 20, Epoch 596, Loss: 6.135458\n",
      "SNR Ratio: 20, Epoch 597, Loss: 5.920544\n",
      "SNR Ratio: 20, Epoch 598, Loss: 6.632101\n",
      "SNR Ratio: 20, Epoch 599, Loss: 6.161051\n",
      "SNR Ratio: 20, Epoch 600, Loss: 7.519378\n",
      "SNR Ratio: 20, Epoch 601, Loss: 6.228646\n",
      "SNR Ratio: 20, Epoch 602, Loss: 6.583309\n",
      "SNR Ratio: 20, Epoch 603, Loss: 5.487739\n",
      "SNR Ratio: 20, Epoch 604, Loss: 5.144426\n",
      "SNR Ratio: 20, Epoch 605, Loss: 5.353065\n",
      "SNR Ratio: 20, Epoch 606, Loss: 6.948064\n",
      "SNR Ratio: 20, Epoch 607, Loss: 7.475390\n",
      "SNR Ratio: 20, Epoch 608, Loss: 6.592762\n",
      "SNR Ratio: 20, Epoch 609, Loss: 8.665704\n",
      "SNR Ratio: 20, Epoch 610, Loss: 6.895779\n",
      "SNR Ratio: 20, Epoch 611, Loss: 5.075380\n",
      "SNR Ratio: 20, Epoch 612, Loss: 5.539217\n",
      "SNR Ratio: 20, Epoch 613, Loss: 5.193757\n",
      "SNR Ratio: 20, Epoch 614, Loss: 5.549848\n",
      "SNR Ratio: 20, Epoch 615, Loss: 5.079051\n",
      "SNR Ratio: 20, Epoch 616, Loss: 5.510013\n",
      "SNR Ratio: 20, Epoch 617, Loss: 6.532685\n",
      "SNR Ratio: 20, Epoch 618, Loss: 4.546868\n",
      "SNR Ratio: 20, Epoch 619, Loss: 4.642609\n",
      "SNR Ratio: 20, Epoch 620, Loss: 5.395546\n",
      "SNR Ratio: 20, Epoch 621, Loss: 4.850773\n",
      "SNR Ratio: 20, Epoch 622, Loss: 5.726539\n",
      "SNR Ratio: 20, Epoch 623, Loss: 6.050128\n",
      "SNR Ratio: 20, Epoch 624, Loss: 8.256080\n",
      "SNR Ratio: 20, Epoch 625, Loss: 7.710240\n",
      "SNR Ratio: 20, Epoch 626, Loss: 6.257905\n",
      "SNR Ratio: 20, Epoch 627, Loss: 5.296081\n",
      "SNR Ratio: 20, Epoch 628, Loss: 4.242986\n",
      "SNR Ratio: 20, Epoch 629, Loss: 5.034158\n",
      "SNR Ratio: 20, Epoch 630, Loss: 5.441035\n",
      "SNR Ratio: 20, Epoch 631, Loss: 5.460748\n",
      "SNR Ratio: 20, Epoch 632, Loss: 5.082407\n",
      "SNR Ratio: 20, Epoch 633, Loss: 6.559845\n",
      "SNR Ratio: 20, Epoch 634, Loss: 5.499089\n",
      "SNR Ratio: 20, Epoch 635, Loss: 6.311366\n",
      "SNR Ratio: 20, Epoch 636, Loss: 6.625814\n",
      "SNR Ratio: 20, Epoch 637, Loss: 5.359405\n",
      "SNR Ratio: 20, Epoch 638, Loss: 5.924808\n",
      "SNR Ratio: 20, Epoch 639, Loss: 5.337956\n",
      "SNR Ratio: 20, Epoch 640, Loss: 5.597870\n",
      "SNR Ratio: 20, Epoch 641, Loss: 5.432933\n",
      "SNR Ratio: 20, Epoch 642, Loss: 6.201640\n",
      "SNR Ratio: 20, Epoch 643, Loss: 5.675387\n",
      "SNR Ratio: 20, Epoch 644, Loss: 5.885554\n",
      "SNR Ratio: 20, Epoch 645, Loss: 4.744003\n",
      "SNR Ratio: 20, Epoch 646, Loss: 5.921497\n",
      "SNR Ratio: 20, Epoch 647, Loss: 4.690594\n",
      "SNR Ratio: 20, Epoch 648, Loss: 9.887650\n",
      "SNR Ratio: 20, Epoch 649, Loss: 5.662343\n",
      "SNR Ratio: 20, Epoch 650, Loss: 5.635928\n",
      "SNR Ratio: 20, Epoch 651, Loss: 5.141844\n",
      "SNR Ratio: 20, Epoch 652, Loss: 5.082011\n",
      "SNR Ratio: 20, Epoch 653, Loss: 5.233379\n",
      "SNR Ratio: 20, Epoch 654, Loss: 4.538089\n",
      "SNR Ratio: 20, Epoch 655, Loss: 6.377036\n",
      "SNR Ratio: 20, Epoch 656, Loss: 5.135897\n",
      "SNR Ratio: 20, Epoch 657, Loss: 5.278479\n",
      "SNR Ratio: 20, Epoch 658, Loss: 5.049909\n",
      "SNR Ratio: 20, Epoch 659, Loss: 4.578465\n",
      "SNR Ratio: 20, Epoch 660, Loss: 7.139375\n",
      "SNR Ratio: 20, Epoch 661, Loss: 7.348985\n",
      "SNR Ratio: 20, Epoch 662, Loss: 6.754366\n",
      "SNR Ratio: 20, Epoch 663, Loss: 5.613997\n",
      "SNR Ratio: 20, Epoch 664, Loss: 5.811324\n",
      "SNR Ratio: 20, Epoch 665, Loss: 7.298423\n",
      "SNR Ratio: 20, Epoch 666, Loss: 6.623149\n",
      "SNR Ratio: 20, Epoch 667, Loss: 5.375564\n",
      "SNR Ratio: 20, Epoch 668, Loss: 4.899993\n",
      "SNR Ratio: 20, Epoch 669, Loss: 4.025577\n",
      "SNR Ratio: 20, Epoch 670, Loss: 4.754410\n",
      "SNR Ratio: 20, Epoch 671, Loss: 3.891338\n",
      "SNR Ratio: 20, Epoch 672, Loss: 5.134369\n",
      "SNR Ratio: 20, Epoch 673, Loss: 5.320302\n",
      "SNR Ratio: 20, Epoch 674, Loss: 4.187928\n",
      "SNR Ratio: 20, Epoch 675, Loss: 4.446354\n",
      "SNR Ratio: 20, Epoch 676, Loss: 4.057269\n",
      "SNR Ratio: 20, Epoch 677, Loss: 5.630769\n",
      "SNR Ratio: 20, Epoch 678, Loss: 5.696847\n",
      "SNR Ratio: 20, Epoch 679, Loss: 4.553469\n",
      "SNR Ratio: 20, Epoch 680, Loss: 4.807781\n",
      "SNR Ratio: 20, Epoch 681, Loss: 5.604143\n",
      "SNR Ratio: 20, Epoch 682, Loss: 5.475359\n",
      "SNR Ratio: 20, Epoch 683, Loss: 5.720921\n",
      "SNR Ratio: 20, Epoch 684, Loss: 4.820333\n",
      "SNR Ratio: 20, Epoch 685, Loss: 4.337183\n",
      "SNR Ratio: 20, Epoch 686, Loss: 4.613548\n",
      "SNR Ratio: 20, Epoch 687, Loss: 4.918620\n",
      "SNR Ratio: 20, Epoch 688, Loss: 4.130488\n",
      "SNR Ratio: 20, Epoch 689, Loss: 5.539499\n",
      "SNR Ratio: 20, Epoch 690, Loss: 4.612263\n",
      "SNR Ratio: 20, Epoch 691, Loss: 5.641683\n",
      "SNR Ratio: 20, Epoch 692, Loss: 6.432821\n",
      "SNR Ratio: 20, Epoch 693, Loss: 5.797930\n",
      "SNR Ratio: 20, Epoch 694, Loss: 4.535705\n",
      "SNR Ratio: 20, Epoch 695, Loss: 3.528048\n",
      "SNR Ratio: 20, Epoch 696, Loss: 4.256516\n",
      "SNR Ratio: 20, Epoch 697, Loss: 4.207252\n",
      "SNR Ratio: 20, Epoch 698, Loss: 3.466500\n",
      "SNR Ratio: 20, Epoch 699, Loss: 3.609632\n",
      "SNR Ratio: 20, Epoch 700, Loss: 4.198373\n",
      "SNR Ratio: 20, Epoch 701, Loss: 3.827238\n",
      "SNR Ratio: 20, Epoch 702, Loss: 3.529061\n",
      "SNR Ratio: 20, Epoch 703, Loss: 3.798154\n",
      "SNR Ratio: 20, Epoch 704, Loss: 4.866856\n",
      "SNR Ratio: 20, Epoch 705, Loss: 5.139029\n",
      "SNR Ratio: 20, Epoch 706, Loss: 7.975135\n",
      "SNR Ratio: 20, Epoch 707, Loss: 7.795918\n",
      "SNR Ratio: 20, Epoch 708, Loss: 6.449683\n",
      "SNR Ratio: 20, Epoch 709, Loss: 4.592096\n",
      "SNR Ratio: 20, Epoch 710, Loss: 5.196963\n",
      "SNR Ratio: 20, Epoch 711, Loss: 7.052358\n",
      "SNR Ratio: 20, Epoch 712, Loss: 4.349627\n",
      "SNR Ratio: 20, Epoch 713, Loss: 4.581183\n",
      "SNR Ratio: 20, Epoch 714, Loss: 4.295225\n",
      "SNR Ratio: 20, Epoch 715, Loss: 3.831374\n",
      "SNR Ratio: 20, Epoch 716, Loss: 4.267463\n",
      "SNR Ratio: 20, Epoch 717, Loss: 4.642635\n",
      "SNR Ratio: 20, Epoch 718, Loss: 3.924539\n",
      "SNR Ratio: 20, Epoch 719, Loss: 3.509643\n",
      "SNR Ratio: 20, Epoch 720, Loss: 4.471365\n",
      "SNR Ratio: 20, Epoch 721, Loss: 7.789680\n",
      "SNR Ratio: 20, Epoch 722, Loss: 4.446258\n",
      "SNR Ratio: 20, Epoch 723, Loss: 4.533161\n",
      "SNR Ratio: 20, Epoch 724, Loss: 4.083850\n",
      "SNR Ratio: 20, Epoch 725, Loss: 5.440221\n",
      "SNR Ratio: 20, Epoch 726, Loss: 6.337446\n",
      "SNR Ratio: 20, Epoch 727, Loss: 4.661057\n",
      "SNR Ratio: 20, Epoch 728, Loss: 4.236630\n",
      "SNR Ratio: 20, Epoch 729, Loss: 4.101152\n",
      "SNR Ratio: 20, Epoch 730, Loss: 4.917043\n",
      "SNR Ratio: 20, Epoch 731, Loss: 4.056528\n",
      "SNR Ratio: 20, Epoch 732, Loss: 3.622849\n",
      "SNR Ratio: 20, Epoch 733, Loss: 4.712935\n",
      "SNR Ratio: 20, Epoch 734, Loss: 4.399922\n",
      "SNR Ratio: 20, Epoch 735, Loss: 3.980028\n",
      "SNR Ratio: 20, Epoch 736, Loss: 3.547660\n",
      "SNR Ratio: 20, Epoch 737, Loss: 4.005120\n",
      "SNR Ratio: 20, Epoch 738, Loss: 3.935533\n",
      "SNR Ratio: 20, Epoch 739, Loss: 3.458266\n",
      "SNR Ratio: 20, Epoch 740, Loss: 4.008134\n",
      "SNR Ratio: 20, Epoch 741, Loss: 4.563128\n",
      "SNR Ratio: 20, Epoch 742, Loss: 4.220257\n",
      "SNR Ratio: 20, Epoch 743, Loss: 4.648426\n",
      "SNR Ratio: 20, Epoch 744, Loss: 4.254550\n",
      "SNR Ratio: 20, Epoch 745, Loss: 4.272608\n",
      "SNR Ratio: 20, Epoch 746, Loss: 6.009313\n",
      "SNR Ratio: 20, Epoch 747, Loss: 9.211824\n",
      "SNR Ratio: 20, Epoch 748, Loss: 6.120199\n",
      "SNR Ratio: 20, Epoch 749, Loss: 6.300303\n",
      "SNR Ratio: 20, Epoch 750, Loss: 5.437623\n",
      "SNR Ratio: 20, Epoch 751, Loss: 3.962136\n",
      "SNR Ratio: 20, Epoch 752, Loss: 4.755463\n",
      "SNR Ratio: 20, Epoch 753, Loss: 3.477215\n",
      "SNR Ratio: 20, Epoch 754, Loss: 3.396770\n",
      "SNR Ratio: 20, Epoch 755, Loss: 4.083099\n",
      "SNR Ratio: 20, Epoch 756, Loss: 3.962329\n",
      "SNR Ratio: 20, Epoch 757, Loss: 4.611495\n",
      "SNR Ratio: 20, Epoch 758, Loss: 4.331464\n",
      "SNR Ratio: 20, Epoch 759, Loss: 3.667139\n",
      "SNR Ratio: 20, Epoch 760, Loss: 4.897630\n",
      "SNR Ratio: 20, Epoch 761, Loss: 4.437503\n",
      "SNR Ratio: 20, Epoch 762, Loss: 4.868134\n",
      "SNR Ratio: 20, Epoch 763, Loss: 3.888830\n",
      "SNR Ratio: 20, Epoch 764, Loss: 3.466307\n",
      "SNR Ratio: 20, Epoch 765, Loss: 4.749458\n",
      "SNR Ratio: 20, Epoch 766, Loss: 4.842017\n",
      "SNR Ratio: 20, Epoch 767, Loss: 4.135867\n",
      "SNR Ratio: 20, Epoch 768, Loss: 3.688032\n",
      "SNR Ratio: 20, Epoch 769, Loss: 3.813777\n",
      "SNR Ratio: 20, Epoch 770, Loss: 4.861909\n",
      "SNR Ratio: 20, Epoch 771, Loss: 3.320607\n",
      "SNR Ratio: 20, Epoch 772, Loss: 3.234573\n",
      "SNR Ratio: 20, Epoch 773, Loss: 3.354325\n",
      "SNR Ratio: 20, Epoch 774, Loss: 4.063181\n",
      "SNR Ratio: 20, Epoch 775, Loss: 3.650631\n",
      "SNR Ratio: 20, Epoch 776, Loss: 3.876416\n",
      "SNR Ratio: 20, Epoch 777, Loss: 4.084860\n",
      "SNR Ratio: 20, Epoch 778, Loss: 4.745682\n",
      "SNR Ratio: 20, Epoch 779, Loss: 6.244425\n",
      "SNR Ratio: 20, Epoch 780, Loss: 5.400753\n",
      "SNR Ratio: 20, Epoch 781, Loss: 4.997325\n",
      "SNR Ratio: 20, Epoch 782, Loss: 4.121515\n",
      "SNR Ratio: 20, Epoch 783, Loss: 4.460706\n",
      "SNR Ratio: 20, Epoch 784, Loss: 4.195113\n",
      "SNR Ratio: 20, Epoch 785, Loss: 8.931845\n",
      "SNR Ratio: 20, Epoch 786, Loss: 5.139834\n",
      "SNR Ratio: 20, Epoch 787, Loss: 4.238523\n",
      "SNR Ratio: 20, Epoch 788, Loss: 3.925771\n",
      "SNR Ratio: 20, Epoch 789, Loss: 4.063201\n",
      "SNR Ratio: 20, Epoch 790, Loss: 4.119514\n",
      "SNR Ratio: 20, Epoch 791, Loss: 3.260055\n",
      "SNR Ratio: 20, Epoch 792, Loss: 3.902701\n",
      "SNR Ratio: 20, Epoch 793, Loss: 3.892372\n",
      "SNR Ratio: 20, Epoch 794, Loss: 3.655550\n",
      "SNR Ratio: 20, Epoch 795, Loss: 3.614182\n",
      "SNR Ratio: 20, Epoch 796, Loss: 3.671360\n",
      "SNR Ratio: 20, Epoch 797, Loss: 3.840417\n",
      "SNR Ratio: 20, Epoch 798, Loss: 4.147696\n",
      "SNR Ratio: 20, Epoch 799, Loss: 4.514470\n",
      "SNR Ratio: 20, Epoch 800, Loss: 6.567345\n",
      "SNR Ratio: 20, Epoch 801, Loss: 4.513000\n",
      "SNR Ratio: 20, Epoch 802, Loss: 4.843946\n",
      "SNR Ratio: 20, Epoch 803, Loss: 4.282920\n",
      "SNR Ratio: 20, Epoch 804, Loss: 3.689281\n",
      "SNR Ratio: 20, Epoch 805, Loss: 3.553500\n",
      "SNR Ratio: 20, Epoch 806, Loss: 3.752797\n",
      "SNR Ratio: 20, Epoch 807, Loss: 4.813879\n",
      "SNR Ratio: 20, Epoch 808, Loss: 3.791951\n",
      "SNR Ratio: 20, Epoch 809, Loss: 3.526942\n",
      "SNR Ratio: 20, Epoch 810, Loss: 4.010464\n",
      "SNR Ratio: 20, Epoch 811, Loss: 4.331526\n",
      "SNR Ratio: 20, Epoch 812, Loss: 3.800411\n",
      "SNR Ratio: 20, Epoch 813, Loss: 3.410562\n",
      "SNR Ratio: 20, Epoch 814, Loss: 3.388245\n",
      "SNR Ratio: 20, Epoch 815, Loss: 4.051246\n",
      "SNR Ratio: 20, Epoch 816, Loss: 4.577232\n",
      "SNR Ratio: 20, Epoch 817, Loss: 3.894817\n",
      "SNR Ratio: 20, Epoch 818, Loss: 3.306364\n",
      "SNR Ratio: 20, Epoch 819, Loss: 4.424480\n",
      "SNR Ratio: 20, Epoch 820, Loss: 5.871878\n",
      "SNR Ratio: 20, Epoch 821, Loss: 3.302300\n",
      "SNR Ratio: 20, Epoch 822, Loss: 4.145465\n",
      "SNR Ratio: 20, Epoch 823, Loss: 4.837335\n",
      "SNR Ratio: 20, Epoch 824, Loss: 7.012985\n",
      "SNR Ratio: 20, Epoch 825, Loss: 5.197549\n",
      "SNR Ratio: 20, Epoch 826, Loss: 3.626144\n",
      "SNR Ratio: 20, Epoch 827, Loss: 4.297125\n",
      "SNR Ratio: 20, Epoch 828, Loss: 3.175528\n",
      "SNR Ratio: 20, Epoch 829, Loss: 4.414668\n",
      "SNR Ratio: 20, Epoch 830, Loss: 3.963493\n",
      "SNR Ratio: 20, Epoch 831, Loss: 3.696046\n",
      "SNR Ratio: 20, Epoch 832, Loss: 4.061283\n",
      "SNR Ratio: 20, Epoch 833, Loss: 3.264130\n",
      "SNR Ratio: 20, Epoch 834, Loss: 4.400087\n",
      "SNR Ratio: 20, Epoch 835, Loss: 3.947725\n",
      "SNR Ratio: 20, Epoch 836, Loss: 3.871647\n",
      "SNR Ratio: 20, Epoch 837, Loss: 3.933906\n",
      "SNR Ratio: 20, Epoch 838, Loss: 3.162447\n",
      "SNR Ratio: 20, Epoch 839, Loss: 3.129658\n",
      "SNR Ratio: 20, Epoch 840, Loss: 3.600969\n",
      "SNR Ratio: 20, Epoch 841, Loss: 10.271412\n",
      "SNR Ratio: 20, Epoch 842, Loss: 5.152824\n",
      "SNR Ratio: 20, Epoch 843, Loss: 3.359494\n",
      "SNR Ratio: 20, Epoch 844, Loss: 4.214478\n",
      "SNR Ratio: 20, Epoch 845, Loss: 2.958920\n",
      "SNR Ratio: 20, Epoch 846, Loss: 3.509636\n",
      "SNR Ratio: 20, Epoch 847, Loss: 3.946517\n",
      "SNR Ratio: 20, Epoch 848, Loss: 4.083966\n",
      "SNR Ratio: 20, Epoch 849, Loss: 4.108185\n",
      "SNR Ratio: 20, Epoch 850, Loss: 6.066564\n",
      "SNR Ratio: 20, Epoch 851, Loss: 7.036027\n",
      "SNR Ratio: 20, Epoch 852, Loss: 4.003291\n",
      "SNR Ratio: 20, Epoch 853, Loss: 3.434461\n",
      "SNR Ratio: 20, Epoch 854, Loss: 3.731221\n",
      "SNR Ratio: 20, Epoch 855, Loss: 4.517887\n",
      "SNR Ratio: 20, Epoch 856, Loss: 3.954983\n",
      "SNR Ratio: 20, Epoch 857, Loss: 3.153193\n",
      "SNR Ratio: 20, Epoch 858, Loss: 3.212123\n",
      "SNR Ratio: 20, Epoch 859, Loss: 3.278016\n",
      "SNR Ratio: 20, Epoch 860, Loss: 3.421047\n",
      "SNR Ratio: 20, Epoch 861, Loss: 3.568161\n",
      "SNR Ratio: 20, Epoch 862, Loss: 3.140833\n",
      "SNR Ratio: 20, Epoch 863, Loss: 2.998893\n",
      "SNR Ratio: 20, Epoch 864, Loss: 3.087185\n",
      "SNR Ratio: 20, Epoch 865, Loss: 3.398217\n",
      "SNR Ratio: 20, Epoch 866, Loss: 3.323914\n",
      "SNR Ratio: 20, Epoch 867, Loss: 2.898509\n",
      "SNR Ratio: 20, Epoch 868, Loss: 3.435816\n",
      "SNR Ratio: 20, Epoch 869, Loss: 3.633151\n",
      "SNR Ratio: 20, Epoch 870, Loss: 6.655310\n",
      "SNR Ratio: 20, Epoch 871, Loss: 4.430185\n",
      "SNR Ratio: 20, Epoch 872, Loss: 3.457968\n",
      "SNR Ratio: 20, Epoch 873, Loss: 2.948374\n",
      "SNR Ratio: 20, Epoch 874, Loss: 3.286897\n",
      "SNR Ratio: 20, Epoch 875, Loss: 3.432693\n",
      "SNR Ratio: 20, Epoch 876, Loss: 2.467086\n",
      "SNR Ratio: 20, Epoch 877, Loss: 3.040063\n",
      "SNR Ratio: 20, Epoch 878, Loss: 3.470070\n",
      "SNR Ratio: 20, Epoch 879, Loss: 3.495473\n",
      "SNR Ratio: 20, Epoch 880, Loss: 3.483778\n",
      "SNR Ratio: 20, Epoch 881, Loss: 3.474251\n",
      "SNR Ratio: 20, Epoch 882, Loss: 3.497866\n",
      "SNR Ratio: 20, Epoch 883, Loss: 3.329417\n",
      "SNR Ratio: 20, Epoch 884, Loss: 9.452952\n",
      "SNR Ratio: 20, Epoch 885, Loss: 6.002921\n",
      "SNR Ratio: 20, Epoch 886, Loss: 4.982869\n",
      "SNR Ratio: 20, Epoch 887, Loss: 4.206232\n",
      "SNR Ratio: 20, Epoch 888, Loss: 4.059948\n",
      "SNR Ratio: 20, Epoch 889, Loss: 3.674964\n",
      "SNR Ratio: 20, Epoch 890, Loss: 3.990415\n",
      "SNR Ratio: 20, Epoch 891, Loss: 3.809289\n",
      "SNR Ratio: 20, Epoch 892, Loss: 3.071123\n",
      "SNR Ratio: 20, Epoch 893, Loss: 3.322148\n",
      "SNR Ratio: 20, Epoch 894, Loss: 4.332285\n",
      "SNR Ratio: 20, Epoch 895, Loss: 3.440174\n",
      "SNR Ratio: 20, Epoch 896, Loss: 2.904785\n",
      "SNR Ratio: 20, Epoch 897, Loss: 2.984786\n",
      "SNR Ratio: 20, Epoch 898, Loss: 3.299390\n",
      "SNR Ratio: 20, Epoch 899, Loss: 2.754875\n",
      "SNR Ratio: 20, Epoch 900, Loss: 3.346465\n",
      "SNR Ratio: 20, Epoch 901, Loss: 4.154606\n",
      "SNR Ratio: 20, Epoch 902, Loss: 3.456846\n",
      "SNR Ratio: 20, Epoch 903, Loss: 4.141552\n",
      "SNR Ratio: 20, Epoch 904, Loss: 3.505989\n",
      "SNR Ratio: 20, Epoch 905, Loss: 3.139866\n",
      "SNR Ratio: 20, Epoch 906, Loss: 14.395325\n",
      "SNR Ratio: 20, Epoch 907, Loss: 4.309894\n",
      "SNR Ratio: 20, Epoch 908, Loss: 5.369494\n",
      "SNR Ratio: 20, Epoch 909, Loss: 4.154325\n",
      "SNR Ratio: 20, Epoch 910, Loss: 3.463119\n",
      "SNR Ratio: 20, Epoch 911, Loss: 4.084894\n",
      "SNR Ratio: 20, Epoch 912, Loss: 5.658931\n",
      "SNR Ratio: 20, Epoch 913, Loss: 3.637702\n",
      "SNR Ratio: 20, Epoch 914, Loss: 3.598510\n",
      "SNR Ratio: 20, Epoch 915, Loss: 3.254596\n",
      "SNR Ratio: 20, Epoch 916, Loss: 3.716400\n",
      "SNR Ratio: 20, Epoch 917, Loss: 5.113427\n",
      "SNR Ratio: 20, Epoch 918, Loss: 4.896084\n",
      "SNR Ratio: 20, Epoch 919, Loss: 3.174869\n",
      "SNR Ratio: 20, Epoch 920, Loss: 2.829221\n",
      "SNR Ratio: 20, Epoch 921, Loss: 5.333189\n",
      "SNR Ratio: 20, Epoch 922, Loss: 3.198552\n",
      "SNR Ratio: 20, Epoch 923, Loss: 2.991814\n",
      "SNR Ratio: 20, Epoch 924, Loss: 4.410528\n",
      "SNR Ratio: 20, Epoch 925, Loss: 3.417914\n",
      "SNR Ratio: 20, Epoch 926, Loss: 3.202013\n",
      "SNR Ratio: 20, Epoch 927, Loss: 3.472522\n",
      "SNR Ratio: 20, Epoch 928, Loss: 2.675773\n",
      "SNR Ratio: 20, Epoch 929, Loss: 3.189827\n",
      "SNR Ratio: 20, Epoch 930, Loss: 2.679344\n",
      "SNR Ratio: 20, Epoch 931, Loss: 10.422680\n",
      "SNR Ratio: 20, Epoch 932, Loss: 4.085338\n",
      "SNR Ratio: 20, Epoch 933, Loss: 4.359179\n",
      "SNR Ratio: 20, Epoch 934, Loss: 2.979365\n",
      "SNR Ratio: 20, Epoch 935, Loss: 3.078017\n",
      "SNR Ratio: 20, Epoch 936, Loss: 3.263912\n",
      "SNR Ratio: 20, Epoch 937, Loss: 2.963183\n",
      "SNR Ratio: 20, Epoch 938, Loss: 2.793287\n",
      "SNR Ratio: 20, Epoch 939, Loss: 2.854846\n",
      "SNR Ratio: 20, Epoch 940, Loss: 3.060504\n",
      "SNR Ratio: 20, Epoch 941, Loss: 2.757761\n",
      "SNR Ratio: 20, Epoch 942, Loss: 3.318984\n",
      "SNR Ratio: 20, Epoch 943, Loss: 3.131060\n",
      "SNR Ratio: 20, Epoch 944, Loss: 3.258151\n",
      "SNR Ratio: 20, Epoch 945, Loss: 2.736235\n",
      "SNR Ratio: 20, Epoch 946, Loss: 3.009358\n",
      "SNR Ratio: 20, Epoch 947, Loss: 2.945911\n",
      "SNR Ratio: 20, Epoch 948, Loss: 3.167599\n",
      "SNR Ratio: 20, Epoch 949, Loss: 3.092007\n",
      "SNR Ratio: 20, Epoch 950, Loss: 4.168980\n",
      "SNR Ratio: 20, Epoch 951, Loss: 8.355350\n",
      "SNR Ratio: 20, Epoch 952, Loss: 5.109794\n",
      "SNR Ratio: 20, Epoch 953, Loss: 7.806179\n",
      "SNR Ratio: 20, Epoch 954, Loss: 4.697006\n",
      "SNR Ratio: 20, Epoch 955, Loss: 3.566716\n",
      "SNR Ratio: 20, Epoch 956, Loss: 2.968337\n",
      "SNR Ratio: 20, Epoch 957, Loss: 2.542931\n",
      "SNR Ratio: 20, Epoch 958, Loss: 2.924094\n",
      "SNR Ratio: 20, Epoch 959, Loss: 9.225351\n",
      "SNR Ratio: 20, Epoch 960, Loss: 3.586192\n",
      "SNR Ratio: 20, Epoch 961, Loss: 3.212940\n",
      "SNR Ratio: 20, Epoch 962, Loss: 2.852769\n",
      "SNR Ratio: 20, Epoch 963, Loss: 2.589601\n",
      "SNR Ratio: 20, Epoch 964, Loss: 2.084491\n",
      "SNR Ratio: 20, Epoch 965, Loss: 2.682075\n",
      "SNR Ratio: 20, Epoch 966, Loss: 2.849965\n",
      "SNR Ratio: 20, Epoch 967, Loss: 2.715639\n",
      "SNR Ratio: 20, Epoch 968, Loss: 2.752466\n",
      "SNR Ratio: 20, Epoch 969, Loss: 3.169898\n",
      "SNR Ratio: 20, Epoch 970, Loss: 3.021645\n",
      "SNR Ratio: 20, Epoch 971, Loss: 2.652589\n",
      "SNR Ratio: 20, Epoch 972, Loss: 2.671263\n",
      "SNR Ratio: 20, Epoch 973, Loss: 2.944754\n",
      "SNR Ratio: 20, Epoch 974, Loss: 3.411373\n",
      "SNR Ratio: 20, Epoch 975, Loss: 3.609366\n",
      "SNR Ratio: 20, Epoch 976, Loss: 5.761291\n",
      "SNR Ratio: 20, Epoch 977, Loss: 4.134459\n",
      "SNR Ratio: 20, Epoch 978, Loss: 4.737109\n",
      "SNR Ratio: 20, Epoch 979, Loss: 6.292407\n",
      "SNR Ratio: 20, Epoch 980, Loss: 5.735419\n",
      "SNR Ratio: 20, Epoch 981, Loss: 5.291738\n",
      "SNR Ratio: 20, Epoch 982, Loss: 4.523760\n",
      "SNR Ratio: 20, Epoch 983, Loss: 3.082831\n",
      "SNR Ratio: 20, Epoch 984, Loss: 2.843650\n",
      "SNR Ratio: 20, Epoch 985, Loss: 2.703553\n",
      "SNR Ratio: 20, Epoch 986, Loss: 2.569823\n",
      "SNR Ratio: 20, Epoch 987, Loss: 2.730333\n",
      "SNR Ratio: 20, Epoch 988, Loss: 3.664713\n",
      "SNR Ratio: 20, Epoch 989, Loss: 3.330524\n",
      "SNR Ratio: 20, Epoch 990, Loss: 2.297823\n",
      "SNR Ratio: 20, Epoch 991, Loss: 3.148145\n",
      "SNR Ratio: 20, Epoch 992, Loss: 3.363949\n",
      "SNR Ratio: 20, Epoch 993, Loss: 2.845698\n",
      "SNR Ratio: 20, Epoch 994, Loss: 2.409512\n",
      "SNR Ratio: 20, Epoch 995, Loss: 2.508396\n",
      "SNR Ratio: 20, Epoch 996, Loss: 2.336394\n",
      "SNR Ratio: 20, Epoch 997, Loss: 2.278669\n",
      "SNR Ratio: 20, Epoch 998, Loss: 4.214072\n",
      "SNR Ratio: 20, Epoch 999, Loss: 3.776192\n",
      "SNR Ratio: 20, Epoch 1000, Loss: 2.905099\n",
      "SNR Ratio: 20, Epoch 1001, Loss: 3.001604\n",
      "SNR Ratio: 20, Epoch 1002, Loss: 3.028074\n",
      "SNR Ratio: 20, Epoch 1003, Loss: 2.507106\n",
      "SNR Ratio: 20, Epoch 1004, Loss: 3.130361\n",
      "SNR Ratio: 20, Epoch 1005, Loss: 3.440196\n",
      "SNR Ratio: 20, Epoch 1006, Loss: 2.967519\n",
      "SNR Ratio: 20, Epoch 1007, Loss: 3.808749\n",
      "SNR Ratio: 20, Epoch 1008, Loss: 3.711554\n",
      "SNR Ratio: 20, Epoch 1009, Loss: 2.949792\n",
      "SNR Ratio: 20, Epoch 1010, Loss: 2.857572\n",
      "SNR Ratio: 20, Epoch 1011, Loss: 3.291385\n",
      "SNR Ratio: 20, Epoch 1012, Loss: 5.327575\n",
      "SNR Ratio: 20, Epoch 1013, Loss: 4.746997\n",
      "SNR Ratio: 20, Epoch 1014, Loss: 4.226134\n",
      "SNR Ratio: 20, Epoch 1015, Loss: 4.886816\n",
      "SNR Ratio: 20, Epoch 1016, Loss: 3.871177\n",
      "SNR Ratio: 20, Epoch 1017, Loss: 2.992420\n",
      "SNR Ratio: 20, Epoch 1018, Loss: 2.786905\n",
      "SNR Ratio: 20, Epoch 1019, Loss: 2.558868\n",
      "SNR Ratio: 20, Epoch 1020, Loss: 2.356752\n",
      "SNR Ratio: 20, Epoch 1021, Loss: 2.659528\n",
      "SNR Ratio: 20, Epoch 1022, Loss: 2.717514\n",
      "SNR Ratio: 20, Epoch 1023, Loss: 3.578173\n",
      "SNR Ratio: 20, Epoch 1024, Loss: 3.465317\n",
      "SNR Ratio: 20, Epoch 1025, Loss: 2.973229\n",
      "SNR Ratio: 20, Epoch 1026, Loss: 2.831000\n",
      "SNR Ratio: 20, Epoch 1027, Loss: 3.370942\n",
      "SNR Ratio: 20, Epoch 1028, Loss: 2.654542\n",
      "SNR Ratio: 20, Epoch 1029, Loss: 2.829116\n",
      "SNR Ratio: 20, Epoch 1030, Loss: 2.531452\n",
      "SNR Ratio: 20, Epoch 1031, Loss: 2.736970\n",
      "SNR Ratio: 20, Epoch 1032, Loss: 2.967948\n",
      "SNR Ratio: 20, Epoch 1033, Loss: 2.736202\n",
      "SNR Ratio: 20, Epoch 1034, Loss: 2.809751\n",
      "SNR Ratio: 20, Epoch 1035, Loss: 3.102302\n",
      "SNR Ratio: 20, Epoch 1036, Loss: 2.736416\n",
      "SNR Ratio: 20, Epoch 1037, Loss: 2.949110\n",
      "SNR Ratio: 20, Epoch 1038, Loss: 2.730515\n",
      "SNR Ratio: 20, Epoch 1039, Loss: 4.303305\n",
      "SNR Ratio: 20, Epoch 1040, Loss: 3.503475\n",
      "SNR Ratio: 20, Epoch 1041, Loss: 4.242708\n",
      "SNR Ratio: 20, Epoch 1042, Loss: 3.311017\n",
      "SNR Ratio: 20, Epoch 1043, Loss: 3.535187\n",
      "SNR Ratio: 20, Epoch 1044, Loss: 2.865342\n",
      "SNR Ratio: 20, Epoch 1045, Loss: 2.691399\n",
      "SNR Ratio: 20, Epoch 1046, Loss: 3.342235\n",
      "SNR Ratio: 20, Epoch 1047, Loss: 3.214429\n",
      "SNR Ratio: 20, Epoch 1048, Loss: 3.683707\n",
      "SNR Ratio: 20, Epoch 1049, Loss: 2.781846\n",
      "SNR Ratio: 20, Epoch 1050, Loss: 3.307794\n",
      "SNR Ratio: 20, Epoch 1051, Loss: 3.402733\n",
      "SNR Ratio: 20, Epoch 1052, Loss: 3.711632\n",
      "SNR Ratio: 20, Epoch 1053, Loss: 3.248363\n",
      "SNR Ratio: 20, Epoch 1054, Loss: 2.878692\n",
      "SNR Ratio: 20, Epoch 1055, Loss: 3.806333\n",
      "SNR Ratio: 20, Epoch 1056, Loss: 3.024896\n",
      "SNR Ratio: 20, Epoch 1057, Loss: 3.218957\n",
      "SNR Ratio: 20, Epoch 1058, Loss: 3.557399\n",
      "SNR Ratio: 20, Epoch 1059, Loss: 5.217943\n",
      "SNR Ratio: 20, Epoch 1060, Loss: 3.420267\n",
      "SNR Ratio: 20, Epoch 1061, Loss: 3.843537\n",
      "SNR Ratio: 20, Epoch 1062, Loss: 2.934033\n",
      "SNR Ratio: 20, Epoch 1063, Loss: 2.401396\n",
      "SNR Ratio: 20, Epoch 1064, Loss: 3.284992\n",
      "Stopped early after 1065 epochs, with loss 2.084491\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save the Noisy Models"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:55:38.000883Z",
     "start_time": "2025-04-10T14:55:37.987388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for indx, (db, value) in enumerate(SNR.items()):\n",
    "    torch.save(noisy_models[indx].state_dict(), f\"Models/noisy_models/sparsity_{min_sparsity}-{max_sparsity}/noisy_model_{db}_{min_sparsity}-{max_sparsity}.pt\")"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize pre-trained noiseless model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Instantiate your model architecture first\n",
    "encoding_dim = 50\n",
    "vector_size = 100\n",
    "hidden_dims = np.array([50,70])\n",
    "pretrained_model = LearnedAutoencoder(vector_size,encoding_dim,hidden_dims)\n",
    "# Load the state dictionary\n",
    "pretrained_model.load_state_dict(torch.load(\"model_state_hidden_layers_50_70.pt\"))\n",
    "\n",
    "pretrained_model.eval()  # Set the model to evaluation mode if needed"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Show the output for a given sparse input vector\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Here we generate a test vector from our buildDataSet function, put it through the model and look at the output\n",
    "h, x = buildDataSet(max_amplitude,min_sparsity,max_sparsity,vector_size,1)\n",
    "\n",
    "H = np.concatenate((h.real,h.imag)).T\n",
    "\n",
    "H_tensor = torch.tensor(H,dtype=torch.float)\n",
    "\n",
    "H_hat = pretrained_model(H_tensor)\n",
    "\n",
    "h_hat = np.array(H_hat.detach())\n",
    "\n",
    "h_real,h_imag = np.split(h_hat,2,1)\n",
    "h_hat = h_real + 1j*h_imag\n",
    "h_hat = h_hat.reshape(-1,1)\n",
    "DFT = sp.linalg.dft(vector_size)/np.sqrt(vector_size)\n",
    "iDFT = DFT.conj().T\n",
    "\n",
    "\n",
    "x_hat = iDFT@h_hat\n",
    "indices = range(len(x_hat))\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.vlines(indices,0,x,linewidth=3)\n",
    "plt.vlines(indices,0,x_hat,colors=\"orange\")\n",
    "\n",
    "plt.legend((\"$x$\",\"$\\hat{x}$\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract the encoding matrix, generate a (noisy) y and use the decoder to find $\\hat{h}$, then plot $\\hat{x}$"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the autoencoder\n",
    "\n",
    "encoding_dim = 50\n",
    "vector_size = 100\n",
    "hidden_dims = np.array([60,80])\n",
    "variance = 10\n",
    "noisy_autoencoder = LearnedAutoencoderWithNoise(vector_size,encoding_dim,hidden_dims,variance)\n",
    "noisy_autoencoder.load_state_dict(torch.load(\"noisy_autoencoder_10var_60_80.pt\",))\n",
    "noisy_autoencoder.eval()\n",
    "\n",
    "# Build the W matrix\n",
    "q_values = noisy_autoencoder.encoder.q_values\n",
    "\n",
    "W_real = torch.cos(q_values)\n",
    "W_imag = torch.sin(q_values)\n",
    "W_top = torch.cat([W_real, -W_imag], dim=1)  # [W_real, -W_imag]\n",
    "W_bottom = torch.cat([W_imag, W_real], dim=1)  # [W_imag, W_real]\n",
    "W_total = torch.cat([W_top, W_bottom], dim=0)  # Stack rows to form the full matrix \n",
    "\n",
    "# Build the input vector\n",
    "\n",
    "h, x = buildDataSet(max_amplitude,min_sparsity,max_sparsity,vector_size,1)\n",
    "\n",
    "H = np.concatenate((h.real,h.imag)).T\n",
    "\n",
    "H_tensor = torch.tensor(H,dtype=torch.float)\n",
    "\n",
    "y = torch.matmul(H_tensor,W_total.T)\n",
    "\n",
    "# Make the noise\n",
    "\n",
    "variance = 10\n",
    "\n",
    "noise_np = np.random.normal(0,variance,size=100)\n",
    "noise = torch.tensor(noise_np,dtype=torch.float)\n",
    "noisy_y = y + noise\n",
    "\n",
    "# Rebuild h, and x from the noisy y using the decoder\n",
    "\n",
    "H_hat = noisy_autoencoder.decoder(noisy_y)\n",
    "\n",
    "h_hat = np.array(H_hat.detach())\n",
    "\n",
    "h_real,h_imag = np.split(h_hat,2,1)\n",
    "h_hat = h_real + 1j*h_imag\n",
    "h_hat = h_hat.reshape(-1,1)\n",
    "DFT = sp.linalg.dft(vector_size)/np.sqrt(vector_size)\n",
    "iDFT = DFT.conj().T\n",
    "\n",
    "x_hat = iDFT@h_hat\n",
    "indices = range(len(x_hat))\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plotting"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "plt.vlines(indices,0,x,linewidth=3)\n",
    "plt.vlines(indices,0,x_hat,colors=\"orange\")\n",
    "\n",
    "plt.legend((r\"$x$\",r\"$\\hat{x}$\"))\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Show the weights"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# THIS DOESN'T WORK. TO BE FIXED\n",
    "\n",
    "for idx, layer in enumerate(pretrained_model.decoder):\n",
    "    # Check if the layer is an instance of ComplexLinear\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        print(f\"Decoder layer {idx} (ComplexLinear) W_real:\")\n",
    "        print(layer.weight)\n",
    "        print(f\"Decoder layer {idx} (ComplexLinear) W_imag:\")\n",
    "        print(layer.weight)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "imbalance_levels = [0, 0.04, 0.1, 0.3, 0.6, 1]\n",
    "IRR_ratios = {}\n",
    "db_IRR_ratios = []\n",
    "\n",
    "for level in imbalance_levels:\n",
    "    b = 1 - (0.2 * level)\n",
    "    d = level * np.pi/8\n",
    "    r = 0.5*(1+b*np.exp(1j*d))\n",
    "    IRR_ratio = (np.abs(r)**2)/(np.abs(1-r)**2)\n",
    "    IRR_ratios[level] = (10*np.log10(IRR_ratio))\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "imbalanced_models = []\n",
    "imbalanced_losses = []\n",
    "\n",
    "# Looping over \n",
    "for level, db_ratio in IRR_ratios.items():\n",
    "    encoding_dim = 50\n",
    "    b = 1 - (0.2 * level)\n",
    "    d = level * np.pi/8\n",
    "    variance = 0\n",
    "    # Initialize model\n",
    "    hidden_dims = np.array([60,80])\n",
    "    imbalanced_autoencoder_model = LearnedAutoencoderWithIQImbalance(vector_size,encoding_dim,hidden_dims,b,d,variance)\n",
    "    optimizer = torch.optim.Adam(imbalanced_autoencoder_model.parameters(), lr=1E-3, betas=(0.9,0.999))\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    # def complex_mse_loss(input, target):\n",
    "    #     return F.mse_loss(input, target)\n",
    "\n",
    "    # Training loop\n",
    "    losses = []\n",
    "    lowest_loss = float(\"inf\")\n",
    "    for epoch in range(10000):\n",
    "        for batch in dataloader:\n",
    "            inputs, targets = batch  # Unpack the tuple\n",
    "            optimizer.zero_grad()\n",
    "            output = imbalanced_autoencoder_model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        if loss< lowest_loss:\n",
    "            lowest_loss = loss\n",
    "            early_stopping_counter = 0\n",
    "            best_model = imbalanced_autoencoder_model\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter > 100:\n",
    "                imbalanced_autoencoder_model = best_model\n",
    "                print(f\"Stopped early after {epoch+1} epochs, with loss of {lowest_loss:.6f}\")\n",
    "                break\n",
    "        print(f\"IRR Ratio:{db_ratio}, Epoch {epoch+1}, Loss: {loss.item():.6f}\")\n",
    "    imbalanced_models.append(best_model)\n",
    "    imbalanced_losses.append(lowest_loss)\n",
    "\n",
    "# plt.plot(losses)\n",
    "# plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train the IQ Imbalance model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "imbalance_levels = [0, 0.04, 0.1, 0.3, 0.6, 1]\n",
    "IRR_ratios = {}\n",
    "\n",
    "# Calculate the dB imbalance levels, we store them in the dictionary IRR_ratios such that we can extract it with the corresponding level imbalance\n",
    "for level in imbalance_levels:\n",
    "    b = 1 - (0.2 * level)\n",
    "    d = level * np.pi/8\n",
    "    r = 0.5*(1+b*np.exp(1j*d))\n",
    "    IRR_ratio = (np.abs(r)**2)/(np.abs(1-r)**2)\n",
    "    IRR_ratios[level] = 10*np.log10(IRR_ratio)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save the IQ-Imbalance Models\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for indx, items in enumerate(IRR_ratios):\n",
    "    torch.save(imbalanced_models[indx].state_dict(), f\"imbalanced_model_{items:.3f}_{min_sparsity}-{max_sparsity}.pt\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train various measurement matrix size"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "measurement_sizes = [5, 10, 20, 30, 40, 50]\n",
    "measurement_models = []\n",
    "measurement_losses = []\n",
    "\n",
    "for encoding_dim in measurement_sizes:\n",
    "    level = 0.6 # Set the IQ imbalance level to around 33 dB IRR\n",
    "    b = 1 - (0.2 * level)\n",
    "    d = level * np.pi/8\n",
    "    variance = signal_variance/SNR[17] # Set the SNR to 17 dB\n",
    "    # Initialize model\n",
    "    hidden_dims = np.array([60,80])\n",
    "    measurement_autoencoder_model = LearnedAutoencoderWithIQImbalance(vector_size,encoding_dim,hidden_dims,b,d,variance)\n",
    "    optimizer = torch.optim.Adam(measurement_autoencoder_model.parameters(), lr=1E-3, betas=(0.9,0.999))\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    # def complex_mse_loss(input, target):\n",
    "    #     return F.mse_loss(input, target)\n",
    "\n",
    "    # Training loop\n",
    "    losses = []\n",
    "    lowest_loss = float(\"inf\")\n",
    "    for epoch in range(10000):\n",
    "        for batch in dataloader:\n",
    "            inputs, targets = batch  # Unpack the tuple\n",
    "            optimizer.zero_grad()\n",
    "            output = measurement_autoencoder_model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        if loss< lowest_loss:\n",
    "            lowest_loss = loss\n",
    "            early_stopping_counter = 0\n",
    "            best_model = measurement_autoencoder_model\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter > 100:\n",
    "                measurement_autoencoder_model = best_model\n",
    "                print(f\"Stopped early after {epoch+1} epochs, with loss of {lowest_loss:.6f}\")\n",
    "                break\n",
    "        print(f\"Encoding dimension:{encoding_dim}, Epoch {epoch+1}, Loss: {loss.item():.6f}\")\n",
    "    measurement_models.append(best_model)\n",
    "    measurement_losses.append(lowest_loss)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save the measurement models"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "measurement_sizes = [5, 10, 20, 30, 40, 50]\n",
    "for indx, encoding_dim in enumerate(measurement_sizes):\n",
    "    torch.save(measurement_models[indx].state_dict(), f\"measurement_model_{encoding_dim}_{min_sparsity}-{max_sparsity}.pt\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plotting"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.rcParams['text.usetex'] = False\n",
    "SNRkeys = SNR.keys()\n",
    "plt.plot(SNRkeys, noisy_losses)\n",
    "plt.title(\"Noisy Autoencoder Loss vs SNR\")\n",
    "plt.xlabel(\"SNR\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "imbalanced_losses_np = []\n",
    "for loss in imbalanced_losses:\n",
    "    imbalanced_losses_np.append(torch.Tensor.detach(loss))\n",
    "\n",
    "db_IRR_ratios = []\n",
    "\n",
    "for level in imbalance_levels:\n",
    "    b = 1 - (0.2 * level)\n",
    "    d = level * np.pi/8\n",
    "    r = 0.5*(1+b*np.exp(1j*d))\n",
    "    IRR_ratio = (np.abs(r)**2)/(np.abs(1-r)**2)\n",
    "    IRR_ratios[level] = 10*np.log10(IRR_ratio)\n",
    "    db_IRR_ratios.append(10*np.log10(IRR_ratio))\n",
    "\n",
    "print(db_IRR_ratios)\n",
    "print(imbalanced_losses_np)\n",
    "print(len(db_IRR_ratios))\n",
    "plt.figure()\n",
    "plt.plot(db_IRR_ratios, imbalanced_losses_np)\n",
    "plt.title(\"Imbalanced Autoencoder\")\n",
    "plt.xlabel(\"IRR Ratio ($dB$)\")\n",
    "plt.ylabel(\"RMSE Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Test IQ Imbalance model\n",
    "\n",
    "# Generate a vector\n",
    "h, x = buildDataSet(max_amplitude,min_sparsity,max_sparsity,vector_size,1)\n",
    "\n",
    "H = np.concatenate((h.real,h.imag)).T\n",
    "\n",
    "H_tensor = torch.tensor(H,dtype=torch.float)\n",
    "\n",
    "imbalanced_autoencoder_model(H_tensor)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generate new dataset, initialize pretrained models, evaluate the loss and plot"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "noisy_pretrained_models = {}\n",
    "imbalanced_pretrained_models = {}\n",
    "measurement_pretrained_models = {}\n",
    "\n",
    "# Define the SNR dictionary for use\n",
    "db_list = [2,5,8,11,14,17,20]\n",
    "signal_variance = 133 # Found by measuring empirically what the variance of the signal is once transformed from sparse signal\n",
    "SNR = {}\n",
    "\n",
    "# Then define the absolute values of the SNR ratio\n",
    "for db_ratio in db_list:\n",
    "    SNR[db_ratio] = 10**(db_ratio/10)\n",
    "\n",
    "#Initialize pretrained noisy models\n",
    "for db,abs in SNR.items():\n",
    "    encoding_dim = 50\n",
    "    variance = signal_variance/abs\n",
    "    # Initialize model\n",
    "    hidden_dims = np.array([60,80])\n",
    "    noisy_pretrained_models[db] = LearnedAutoencoderWithNoise(vector_size,encoding_dim,hidden_dims,variance)\n",
    "    noisy_pretrained_models[db].load_state_dict(torch.load(f\"noisy_model_{db}.pt\", weights_only=True))\n",
    "\n",
    "# Initialize pretrained imbalanced_models\n",
    "for level, db  in IRR_ratios.items():\n",
    "    encoding_dim = 50\n",
    "    variance = 0\n",
    "    b = 1 - (0.2 * level)\n",
    "    d = level * np.pi/8\n",
    "    # Initialize model\n",
    "    hidden_dims = np.array([60,80])\n",
    "    imbalanced_pretrained_models[level] = LearnedAutoencoderWithIQImbalance(vector_size,encoding_dim,hidden_dims,b,d,variance)\n",
    "    imbalanced_pretrained_models[level].load_state_dict(torch.load(f\"imbalanced_model_{db:.3f}.pt\", weights_only=True))\n",
    "\n",
    "# Initialize pretrained imbalanced_models\n",
    "for encoding_dim  in measurement_sizes:\n",
    "    variance = signal_variance/SNR[17]\n",
    "    level = 0.6\n",
    "    b = 1 - (0.2 * level)\n",
    "    d = level * np.pi/8\n",
    "    # Initialize model\n",
    "    hidden_dims = np.array([60,80])\n",
    "    measurement_pretrained_models[encoding_dim] = LearnedAutoencoderWithIQImbalance(vector_size,encoding_dim,hidden_dims,b,d,variance)\n",
    "    measurement_pretrained_models[encoding_dim].load_state_dict(torch.load(f\"measurement_model_{encoding_dim}.pt\", weights_only=True))\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate dataset\n",
    "max_amplitude = 100\n",
    "min_sparsity = 7\n",
    "max_sparsity = 9\n",
    "vector_size = 100\n",
    "data_set_size = 10000\n",
    "val_dense_data, val_sparse_data = buildDataSet(max_amplitude,min_sparsity,max_sparsity,vector_size,data_set_size)\n",
    "\n",
    "print(val_sparse_data[0,:])\n",
    "\n",
    "X_val = np.concatenate((val_dense_data.real,val_dense_data.imag)).T\n",
    "Y_val = np.concatenate((val_dense_data.real,val_dense_data.imag)).T\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val,dtype=torch.float)\n",
    "Y_val_tensor = torch.tensor(Y_val,dtype=torch.float)\n",
    "val_dataset = TensorDataset(X_val_tensor,Y_val_tensor)\n",
    "\n",
    "dataloader_val = DataLoader(val_dataset,batch_size = 500,shuffle = True, )\n",
    "\n",
    "loss_fn = nn.MSELoss()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Validating the noisy models\n",
    "noisy_val_losses = []\n",
    "noisy_model_losses = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for db, noisy_model in noisy_pretrained_models.items():\n",
    "        noisy_model.eval()\n",
    "        for batch in dataloader_val:\n",
    "            inputs, targets = batch  # Unpack the tuple\n",
    "            output = noisy_model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            noisy_model_losses.append(loss.item())\n",
    "        noisy_val_losses.append(np.average(noisy_model_losses))\n",
    "        noisy_model_losses = []\n",
    "\n",
    "noisy_val_losses = np.array(noisy_val_losses)\n",
    "normalized_noisy_val_losses = noisy_val_losses/signal_variance\n",
    "print(noisy_val_losses)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Validating the IQ imbalance models\n",
    "imbalance_model_losses = []\n",
    "imbalance_val_losses = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for level, imbalance_model in imbalanced_pretrained_models.items():\n",
    "        imbalance_model.eval()\n",
    "        for batch in dataloader_val:\n",
    "            inputs, targets = batch  # Unpack the tuple\n",
    "            output = noisy_model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            imbalance_model_losses.append(loss.item())\n",
    "        imbalance_val_losses.append(np.average(imbalance_model_losses))\n",
    "        imbalance_model_losses = []\n",
    "\n",
    "imbalance_val_losses = np.array(imbalance_val_losses)\n",
    "normalized_imbalance_val_losses = imbalance_val_losses/signal_variance\n",
    "print(imbalance_val_losses)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Validating the varying measurement dimensions models\n",
    "measurement_model_losses = []\n",
    "measurement_val_losses = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for encoding_dim, measurement_model in measurement_pretrained_models.items():\n",
    "        measurement_model.eval()\n",
    "        for batch in dataloader_val:\n",
    "            inputs, targets = batch  # Unpack the tuple\n",
    "            output = measurement_model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            measurement_model_losses.append(loss.item())\n",
    "        measurement_val_losses.append(np.average(measurement_model_losses))\n",
    "        print(f\"Encoding dimenson:{encoding_dim} Losses:{measurement_model_losses}\")\n",
    "        measurement_model_losses = []\n",
    "\n",
    "measurement_val_losses = np.array(measurement_val_losses)\n",
    "normalized_measurement_val_losses = measurement_val_losses/signal_variance\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "noiseless_loss = normalized_imbalance_val_losses[0]\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "fig1, (ax1, ax2, ax3) = plt.subplots(ncols=3,nrows = 1,figsize=(18, 6))\n",
    "ax1.plot(SNR.keys(),normalized_noisy_val_losses,color= \"blue\", marker=\"o\")\n",
    "ax1.plot(SNR.keys(), [noiseless_loss for i in SNR.keys()])\n",
    "ax1.set_xlabel(\"SNR $(dB)$\")\n",
    "ax1.set_ylabel(\"NMSE\")\n",
    "ax1.set_title(\"Noisy Model Performance\")\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(IRR_ratios.values(),normalized_imbalance_val_losses,color= 'red',marker='s')\n",
    "ax2.plot(IRR_ratios.values(), [noiseless_loss for i in IRR_ratios.values()])\n",
    "ax2.set_xlabel(\"IRR $(dB)$\")\n",
    "ax2.set_title(\"IQ Imbalanced Model Performance\")\n",
    "\n",
    "ax1.plot(SNR.keys(), [noiseless_loss for i in SNR.keys()])\n",
    "ax2.grid(True)\n",
    "\n",
    "ax3.plot(measurement_sizes,normalized_measurement_val_losses,color= 'green',marker='^')\n",
    "ax3.plot(measurement_sizes, [noiseless_loss for i in measurement_sizes], color='green')\n",
    "ax3.set_xlabel(\"Measurement Dimension\")\n",
    "ax3.set_title(\"Measurement Model Performance\")\n",
    "ax3.grid(True)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a new loss function to drive the values of the measurement matrix to discrete values $\\{-\\pi,-\\frac{1}{2}\\pi,0,\\frac{1}{2}\\pi,\\pi\\}$"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def discreteLossPoly(qweights,scaleFactor):\n",
    "    loss = 0\n",
    "    pi = torch.tensor(math.pi)\n",
    "    # Note that we need to flatten the weights so that our iteration does not result in us iterating over the rows instead of the weights\n",
    "    qVec = qweights.flatten()\n",
    "    # Efficient implementation of the loss function, by doing vector operations, saves a lot of time in training\n",
    "    loss += torch.linalg.vector_norm(qVec*(qVec-1/2*pi)*(qVec-1*pi)*(qVec+pi)*(qVec+1/2*pi),1)\n",
    "    loss = loss*scaleFactor # Scale the resulting loss\n",
    "    return loss"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sparsity_ranges = [(3, 5), (5, 7), (7, 9), (10, 30)]\n",
    "measurement_sizes = [5, 10, 20, 30, 40, 50]\n",
    "# Define the SNR dictionary for use\n",
    "db_list = [2,5,8,11,14,17,20]\n",
    "signal_variance = 133 # Found by measuring empirically what the variance of the signal is once transformed from sparse signal\n",
    "SNR = {}\n",
    "\n",
    "# Then define the absolute values of the SNR ratio\n",
    "for db_ratio in db_list:\n",
    "    SNR[db_ratio] = 10**(db_ratio/10)\n",
    "\n",
    "#empty dicts to store models in\n",
    "noisy_pretrained_models = {}\n",
    "imbalanced_pretrained_models = {}\n",
    "measurement_pretrained_models = {}\n",
    "\n",
    "for i, (min_spars, max_spars) in enumerate(sparsity_ranges):\n",
    "\n",
    "    #Initialize pretrained noisy models\n",
    "    for db,abs in SNR.items():\n",
    "        encoding_dim = 50\n",
    "        variance = signal_variance/abs\n",
    "        # Initialize model\n",
    "        hidden_dims = np.array([60,80])\n",
    "        noisy_pretrained_models[(i, db)] = LearnedAutoencoderWithNoise(vector_size,encoding_dim,hidden_dims,variance)\n",
    "        noisy_pretrained_models[(i, db)].load_state_dict(torch.load(f\"noisy_model_{db}_{min_spars}-{max_spars}.pt\", weights_only=True))\n",
    "\n",
    "    # Initialize pretrained imbalanced_models\n",
    "    for level, db  in IRR_ratios.items():\n",
    "        encoding_dim = 50\n",
    "        variance = 0\n",
    "        b = 1 - (0.2 * level)\n",
    "        d = level * np.pi/8\n",
    "        # Initialize model\n",
    "        hidden_dims = np.array([60,80])\n",
    "        imbalanced_pretrained_models[(i, level)] = LearnedAutoencoderWithIQImbalance(vector_size,encoding_dim,hidden_dims,b,d,variance)\n",
    "        imbalanced_pretrained_models[(i, level)].load_state_dict(torch.load(f\"imbalanced_model_{level:.3f}_{min_spars}-{max_spars}.pt\", weights_only=True))\n",
    "\n",
    "    # Initialize pretrained measurement models\n",
    "    for encoding_dim  in measurement_sizes:\n",
    "        variance = signal_variance/SNR[17]\n",
    "        level = 0.6\n",
    "        b = 1 - (0.2 * level)\n",
    "        d = level * np.pi/8\n",
    "        # Initialize model\n",
    "        hidden_dims = np.array([60,80])\n",
    "        measurement_pretrained_models[(i, encoding_dim)] = LearnedAutoencoderWithIQImbalance(vector_size,encoding_dim,hidden_dims,b,d,variance)\n",
    "        measurement_pretrained_models[(i, encoding_dim)].load_state_dict(torch.load(f\"measurement_model_{encoding_dim}_{min_spars}-{max_spars}.pt\", weights_only=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:35:28.749572Z",
     "start_time": "2025-04-10T14:35:28.744525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Generate dataset\n",
    "def Generate_Dataloader(max_amplitude,min_sparsity,max_sparsity,vector_size,data_set_size):\n",
    "    val_dense_data, val_sparse_data = buildDataSet(max_amplitude,min_sparsity,max_sparsity,vector_size,data_set_size)\n",
    "\n",
    "    X_val = np.concatenate((val_dense_data.real,val_dense_data.imag)).T\n",
    "    Y_val = np.concatenate((val_dense_data.real,val_dense_data.imag)).T\n",
    "\n",
    "    X_val_tensor = torch.tensor(X_val,dtype=torch.float)\n",
    "    Y_val_tensor = torch.tensor(Y_val,dtype=torch.float)\n",
    "    val_dataset = TensorDataset(X_val_tensor,Y_val_tensor)\n",
    "\n",
    "    dataloader_val = DataLoader(val_dataset,batch_size = 500,shuffle = True, )\n",
    "    variance = np.var(Y_val)\n",
    "    return dataloader_val, variance\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "all_noisy_losses = []\n",
    "all_imbalanced_losses = []\n",
    "all_measurement_losses = []\n",
    "\n",
    "\n",
    "for i, (min_spars, max_spars) in enumerate(sparsity_ranges):\n",
    "    dataloader_val, signal_variance = Generate_Dataloader(max_amplitude, min_spars, max_spars, vector_size, data_set_size)\n",
    "    # Evaluate noisy models\n",
    "    noisy_val_losses = []\n",
    "    noisy_model_losses = []\n",
    "    with torch.no_grad():\n",
    "        for db, abs in SNR.items():\n",
    "            noisy_model = noisy_pretrained_models[(i, db)]\n",
    "            noisy_model.eval()\n",
    "            for batch in dataloader_val:\n",
    "                inputs, targets = batch  # Unpack the tuple\n",
    "                output = noisy_model(inputs)\n",
    "                loss = loss_fn(output, targets)\n",
    "                noisy_model_losses.append(loss.item())\n",
    "            noisy_val_losses.append(np.average(noisy_model_losses))\n",
    "            noisy_model_losses = []\n",
    "\n",
    "    noisy_val_losses = np.array(noisy_val_losses)\n",
    "    normalized_noisy_val_losses = noisy_val_losses/signal_variance\n",
    "    all_noisy_losses.append(normalized_noisy_val_losses)\n",
    "\n",
    "    # Evaluate Imbalanced models\n",
    "    imbalance_model_losses = []\n",
    "    imbalance_val_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for level, db in IRR_ratios.items():\n",
    "            imbalance_model = imbalanced_pretrained_models[(i, level)]\n",
    "            imbalance_model.eval()\n",
    "            for batch in dataloader_val:\n",
    "                inputs, targets = batch  # Unpack the tuple\n",
    "                output = imbalance_model(inputs)\n",
    "                loss = loss_fn(output, targets)\n",
    "                imbalance_model_losses.append(loss.item())\n",
    "            imbalance_val_losses.append(np.average(imbalance_model_losses))\n",
    "            imbalance_model_losses = []\n",
    "\n",
    "    imbalance_val_losses = np.array(imbalance_val_losses)\n",
    "    normalized_imbalance_val_losses = imbalance_val_losses/signal_variance\n",
    "    all_imbalanced_losses.append(normalized_imbalance_val_losses)\n",
    "\n",
    "    # Evaluate models with varying measurement sizes\n",
    "    measurement_model_losses = []\n",
    "    measurement_val_losses = []\n",
    "\n",
    "    with (torch.no_grad()):\n",
    "        for encoding_dim in measurement_sizes:\n",
    "            measurement_model = measurement_pretrained_models[(i, encoding_dim)]\n",
    "            measurement_model.eval()\n",
    "            for batch in dataloader_val:\n",
    "                inputs, targets = batch  # Unpack the tuple\n",
    "                output = measurement_model(inputs)\n",
    "                loss = loss_fn(output, targets)\n",
    "                measurement_model_losses.append(loss.item())\n",
    "            measurement_val_losses.append(np.average(measurement_model_losses))\n",
    "            measurement_model_losses = []\n",
    "\n",
    "    measurement_val_losses = np.array(measurement_val_losses)\n",
    "    normalized_measurement_val_losses = measurement_val_losses/signal_variance\n",
    "    all_measurement_losses.append(normalized_measurement_val_losses)\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.style.use('ggplot')\n",
    "fig1, (ax1, ax2, ax3) = plt.subplots(ncols=3,nrows = 1,figsize=(18, 6))\n",
    "\n",
    "for i in range(4):\n",
    "    if i==0:\n",
    "        noiseless_loss = all_imbalanced_losses[0][0]\n",
    "        ax1.plot(SNR.keys(), [noiseless_loss for i in SNR.keys()])\n",
    "        ax2.plot(IRR_ratios.values(), [noiseless_loss for i in IRR_ratios.values()])\n",
    "        ax3.plot(measurement_sizes, [noiseless_loss for i in measurement_sizes])\n",
    "\n",
    "    ax1.plot(SNR.keys(), all_noisy_losses[i], marker=\"o\")\n",
    "    ax1.set_xlabel(\"SNR $(dB)$\")\n",
    "    ax1.set_ylabel(\"NMSE\")\n",
    "    ax1.set_title(\"Noisy Model Performance\")\n",
    "    ax1.grid(True)\n",
    "    ax1.legend([\"baseline model\", \"sparsity 3-5\", \"sparsity 5-7\",\"sparsity 7-9\", \"sparsity 10-30\"])\n",
    "\n",
    "    ax2.plot(IRR_ratios.values(),all_imbalanced_losses[i],marker='s')\n",
    "    ax2.set_xlabel(\"IRR $(dB)$\")\n",
    "    ax2.set_title(\"IQ Imbalanced Model Performance\")\n",
    "    ax2.legend([\"baseline model\", \"sparsity 3-5\",\"sparsity 5-7\",\"sparsity 7-9\", \"sparsity 10-30\"])\n",
    "    ax2.grid(True)\n",
    "\n",
    "    ax3.plot(measurement_sizes, all_measurement_losses[i],marker='^')\n",
    "    ax3.set_xlabel(\"Measurement Dimension\")\n",
    "    ax3.set_title(\"Measurement Model Performance\")\n",
    "    ax3.legend([\"baseline model\", \"sparsity 3-5\",\"sparsity 5-7\",\"sparsity 7-9\", \"sparsity 10-30\"])\n",
    "    ax3.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train neural network using new loss function"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "vector_size = 100\n",
    "encoding_dim = 50\n",
    "hidden_dims = np.array([60,80])\n",
    "discrete_autoencoder_model = LearnedAutoencoder(vector_size,encoding_dim,hidden_dims)\n",
    "optimizer = torch.optim.Adam(discrete_autoencoder_model.parameters(), lr=1E-3, betas=(0.9,0.999))\n",
    "MSELossfn = nn.MSELoss()\n",
    "scaleFactor = 0.05 # Hyperparameter, setting this too high causes the problem to not converge to low loss, due to the problem converging to discrete values too early, setting too low causes the\n",
    "# values to not converge to discrete values. Empirical testing showed that scaleFactor of 0.05 was nice\n",
    "\n",
    "# Training loop\n",
    "losses = []\n",
    "lowest_loss = float(\"inf\")\n",
    "for epoch in range(5000):\n",
    "    for batch in dataloader:\n",
    "        inputs, targets = batch  # Unpack the tuple\n",
    "        optimizer.zero_grad()\n",
    "        output = discrete_autoencoder_model(inputs)\n",
    "        qweights = discrete_autoencoder_model.encoder.q_values\n",
    "        loss = discreteLossPoly(qweights,scaleFactor) + MSELossfn(output,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    if loss < lowest_loss:\n",
    "        lowest_loss = loss.item()\n",
    "        early_stopping_counter = 0\n",
    "        best_model = discrete_autoencoder_model\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter > 100:\n",
    "            discrete_autoencoder_model = best_model\n",
    "            print(f\"stopped early after {epoch+1} epochs, with a loss of: {lowest_loss}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {lowest_loss:.6f}\")\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Show the values of the weights, they should be $\\{0,\\pm1.57079,\\pm3.14159\\}$"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(discrete_autoencoder_model.encoder.q_values[0:20,0:20])\n",
    "discreteLossPoly(X_tensor[0,:],X_tensor[0,:],qweights,MSELossfn,scaleFactor)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Now we map all the values to actual discrete values"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def mapToDiscreteValues(weights,discrete_values):\n",
    "    # Input is a tensor (possibly a matrix) of weights, and a np array of discrete values\n",
    "    discrete_values = discrete_values.flatten()\n",
    "    weights_np = weights.detach().cpu().numpy() # Convert to numpy array\n",
    "    shape = weights_np.shape\n",
    "    weights_vector = np.reshape(weights_np,(-1,1)) # flatten the matrix to a vector such that subtracting from the discrete values results in a matrix!\n",
    "    \n",
    "    # Create a matrix of distances, then make a vector of indices from this matrix. Each value of the vector is the index of the closest discrete value\n",
    "    distances = np.abs(weights_vector - discrete_values)\n",
    "    indices = np.argmin(distances,1)\n",
    "\n",
    "    # Map the weights to the closest discrete values and reshape into original matrix, and turn into a nn.Parameter object\n",
    "    mappedWeights = discrete_values[indices]\n",
    "    mappedWeights = np.reshape(mappedWeights,shape)\n",
    "    mappedWeights = np.float32(mappedWeights) # Notice we map it to a float because that is what is used for our model\n",
    "    mappedWeights = nn.Parameter(torch.from_numpy(mappedWeights))\n",
    "    return mappedWeights\n",
    "\n",
    "# Testing\n",
    "\n",
    "qweights = discrete_autoencoder_model.encoder.q_values\n",
    "discrete_values = np.array([-np.pi, -0.5*np.pi,0,0.5*np.pi,np.pi])\n",
    "mapped_q_weights = mapToDiscreteValues(qweights,discrete_values)\n",
    "\n",
    "\n",
    "mapped_discrete_autoencoder_model = discrete_autoencoder_model\n",
    "mapped_discrete_autoencoder_model.encoder.q_values = mapped_q_weights\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save the model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.save(mapped_discrete_autoencoder_model.state_dict(), f\"discrete_model.pt\")"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load discrete model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "discrete_model = LearnedAutoencoder(vector_size,encoding_dim,hidden_dims)\n",
    "# Load the state dictionary\n",
    "discrete_model.load_state_dict(torch.load(\"discrete_model.pt\"))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Finally we test on a single data point and map the result!"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Here we generate a test vector from our buildDataSet function, put it through the model and look at the output\n",
    "h, x = buildDataSet(max_amplitude,min_sparsity,max_sparsity,vector_size,1)\n",
    "\n",
    "H = np.concatenate((h.real,h.imag)).T\n",
    "\n",
    "H_tensor = torch.tensor(H,dtype=torch.float)\n",
    "\n",
    "H_hat = discrete_model(H_tensor)\n",
    "\n",
    "h_hat = np.array(H_hat.detach())\n",
    "\n",
    "h_real,h_imag = np.split(h_hat,2,1)\n",
    "h_hat = h_real + 1j*h_imag\n",
    "h_hat = h_hat.reshape(-1,1)\n",
    "DFT = sp.linalg.dft(vector_size)/np.sqrt(vector_size)\n",
    "iDFT = DFT.conj().T\n",
    "\n",
    "\n",
    "x_hat = iDFT@h_hat\n",
    "indices = range(len(x_hat))\n",
    "\n",
    "plt.vlines(indices,0,x,linewidth=3)\n",
    "plt.vlines(indices,0,x_hat,colors=\"orange\")\n",
    "\n",
    "plt.legend((\"$x$\",\"$\\hat{x}$\"))\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## And then we test on the validation data set!"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "discrete_model_losses = []\n",
    "with torch.no_grad():\n",
    "    discrete_model.eval()\n",
    "    for batch in dataloader_val:\n",
    "        inputs, targets = batch  # Unpack the tuple\n",
    "        output = discrete_model(inputs)\n",
    "        loss = loss_fn(output, targets)\n",
    "        discrete_model_losses.append(loss.item())\n",
    "    discrete_loss = np.average(discrete_model_losses)\n",
    "signal_variance = 133\n",
    "normalized_discrete_val_loss = discrete_loss/signal_variance\n",
    "print(normalized_discrete_val_loss)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Code works, so we train the model for the two best case scenario's since at a certain point the model does not work anymore."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def trainModelsForDiscreteSet(dataloader,SNR_values,imb_percentages,encoding_dims,signal_variance = 133,hidden_dims=[60,80],scale_factor=0.05):\n",
    "    # Function takes as inputs:\n",
    "    # dataloader: The dataloader object of the training data set\n",
    "    # SNR_values: Signal to noise ratios\n",
    "    # imb_percentages: imbalance percentages\n",
    "    # encoding_dims: Encoding dimensions\n",
    "    # signal_variance: The variance of the original signal\n",
    "    # hidden_dims: Hidden dimensions for the neural network\n",
    "    # scale_factor: Hyperparameter for the discretization step\n",
    "    models = []\n",
    "    discrete_values = np.array([-np.pi, -0.5*np.pi,0,0.5*np.pi,np.pi])\n",
    "    for model_num,(SNR,imb_percentage,encoding_dim) in enumerate(zip(SNR_values,imb_percentages,encoding_dims)):\n",
    "        abs_noise_ratio = 10**(SNR/10)\n",
    "        variance = signal_variance/abs_noise_ratio\n",
    "        b = 1 - (0.2 * imb_percentage)\n",
    "        d = imb_percentage * np.pi/8\n",
    "        hidden_dims = np.array([60,80])\n",
    "        current_training_model = LearnedAutoencoderWithIQImbalance(vector_size,encoding_dim,hidden_dims,b,d,variance)\n",
    "        optimizer = torch.optim.Adam(current_training_model.parameters(), lr=1E-3, betas=(0.9,0.999))\n",
    "        MSEloss_fn = nn.MSELoss()\n",
    "\n",
    "        # Training loop\n",
    "        losses = []\n",
    "        lowest_loss = float(\"inf\")\n",
    "        for epoch in range(10000):\n",
    "            for batch in dataloader:\n",
    "                inputs, targets = batch  # Unpack the tuple\n",
    "                optimizer.zero_grad()\n",
    "                output = current_training_model(inputs)\n",
    "                qweights = current_training_model.encoder.q_values\n",
    "                loss = discreteLossPoly(qweights,scale_factor) + MSEloss_fn(output, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses.append(loss.item())\n",
    "            if loss< lowest_loss:\n",
    "                lowest_loss = loss\n",
    "                early_stopping_counter = 0\n",
    "                best_model = current_training_model\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                if early_stopping_counter > 100:\n",
    "                    current_training_model = best_model\n",
    "                    print(f\"Stopped early after {epoch+1} epochs, with loss of {lowest_loss:.6f}\")\n",
    "                    break\n",
    "            print(f\"SNR:{SNR}, Imbalance Percentage:{imb_percentage}, Encoding dimension:{encoding_dim}, Epoch {epoch+1}, Loss: {loss.item():.6f}\")\n",
    "        best_qvalues = best_model.encoder.q_values\n",
    "        mapped_best_qvalues = mapToDiscreteValues(best_qvalues,discrete_values)\n",
    "        best_model.encoder.q_values = mapped_best_qvalues\n",
    "        models.append(best_model)\n",
    "        losses.append(lowest_loss)\n",
    "    return models\n",
    "\n",
    "def validateModels(dataloader,models,signal_variance=133):\n",
    "    models_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for model in models:\n",
    "            current_model_losses = []\n",
    "            model.eval()\n",
    "            for batch in dataloader:\n",
    "                inputs, targets = batch  # Unpack the tuple\n",
    "                output = model(inputs)\n",
    "                loss = loss_fn(output, targets)\n",
    "                current_model_losses.append(loss.item())\n",
    "            models_losses.append(np.average(current_model_losses))\n",
    "\n",
    "    models_losses = np.array(models_losses)\n",
    "    normalized_models_losses = models_losses/signal_variance\n",
    "    return normalized_models_losses,models_losses\n",
    "\n",
    "def visualizeReconstruction(model,max_amplitude=100,min_sparsity=3,max_sparsity=5,vector_size=100):\n",
    "    h, x = buildDataSet(max_amplitude,min_sparsity,max_sparsity,vector_size,1)\n",
    "\n",
    "    H = np.concatenate((h.real,h.imag)).T\n",
    "\n",
    "    H_tensor = torch.tensor(H,dtype=torch.float)\n",
    "\n",
    "    H_hat = model(H_tensor)\n",
    "\n",
    "    h_hat = np.array(H_hat.detach())\n",
    "\n",
    "    h_real,h_imag = np.split(h_hat,2,1)\n",
    "    h_hat = h_real + 1j*h_imag\n",
    "    h_hat = h_hat.reshape(-1,1)\n",
    "    DFT = sp.linalg.dft(vector_size)/np.sqrt(vector_size)\n",
    "    iDFT = DFT.conj().T\n",
    "\n",
    "\n",
    "    x_hat = iDFT@h_hat\n",
    "    indices = range(len(x_hat))\n",
    "\n",
    "    plt.vlines(indices,0,x,linewidth=3)\n",
    "    plt.vlines(indices,0,x_hat,colors=\"orange\")\n",
    "\n",
    "    plt.legend((\"x\",\"x_hat\"))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# We train six models\n",
    "encoding_dims_list = [50, 40, 30, 20, 10, 5, 50, 50, 50, 50,50,50,50,50,50,50,50,50,50]\n",
    "SNR_list = [np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, 20, 17, 14, 11, 8, 5, 2, np.inf, np.inf,np.inf, np.inf,np.inf, np.inf]\n",
    "imb_percentage_list = [0,0,0,0,0,0,0,0,0,0,0,0,0,0, 0.04, 0.1, 0.3, 0.6, 1]\n",
    "\n",
    "print(len(encoding_dims_list))\n",
    "print(len(SNR_list))\n",
    "print(len(imb_percentage_list))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "discrete_models = trainModelsForDiscreteSet(dataloader,SNR_list,imb_percentage_list,encoding_dims_list,scale_factor=0.01)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "normalized_losses, unnormalized_losses = validateModels(dataloader_val,discrete_models)\n",
    "print(normalized_losses)\n",
    "\n",
    "visualizeReconstruction(discrete_models[0])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for iter,model in enumerate(discrete_models):\n",
    "    torch.save(model.state_dict(),\n",
    "               f'Models/discrete_models/discrete_model_SNR{SNR_list[iter]}_IRR{imb_percentage_list[iter]}_enc{encoding_dims_list[iter]}.pt')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "imb_db_list = []\n",
    "r_list = []\n",
    "\n",
    "for perc in imb_percentage_list[13:19]:\n",
    "    b = 1-0.2*perc\n",
    "    d = np.pi/8*perc\n",
    "    r = 0.5*(1+b*np.exp(1j*d))\n",
    "    IRR_abs = np.abs(r)**2/np.abs(1-r)**2\n",
    "    imb_db_list.append(10*np.log10(IRR_abs))\n",
    "\n",
    "\n",
    "print(imb_db_list)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plotting!"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.style.use('ggplot')\n",
    "fig1, (ax1, ax2, ax3) = plt.subplots(ncols=3,nrows = 1,figsize=(18, 6))\n",
    "\n",
    "\n",
    "ax1.plot(SNR_list[6:13], normalized_losses[6:13],marker=\"o\",color=\"g\")\n",
    "ax2.plot(imb_db_list, normalized_losses[13:20],marker='s',color='b')\n",
    "ax3.plot(encoding_dims_list[0:6], normalized_losses[0:6],marker='^',color='r')\n",
    "\n",
    "ax1.set_xlabel(\"SNR $(dB)$\")\n",
    "ax1.set_ylabel(\"NMSE\")\n",
    "ax1.set_title(\"Noisy Model Performance\")\n",
    "ax1.grid(True)\n",
    "ax1.legend([\"Discrete Model\"])\n",
    "\n",
    "ax2.set_xlabel(\"IRR $(dB)$\")\n",
    "ax2.set_title(\"IQ Imbalanced Model Performance\")\n",
    "ax2.legend([\"Discrete Model\"])\n",
    "ax2.grid(True)\n",
    "\n",
    "ax3.set_xlabel(\"Measurement Dimension\")\n",
    "ax3.set_title(\"Measurement Model Performance\")\n",
    "ax3.legend([\"Discrete Model\"])\n",
    "ax3.grid(True)\n",
    "plt.savefig(\"Images/discrete_model_performance.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Find RIP from Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import itertools\n",
    "\n",
    "# Create an array of 100 numbers (0 to 99)\n",
    "numbers = list(range(100))\n",
    "RIC = {}\n",
    "\n",
    "# Generate all possible 3-length combinations\n",
    "for model in discrete_models:\n",
    "    max_RIC = 0\n",
    "    print(model)\n",
    "    # Get q-values and create the complex matrix W\n",
    "    qvalues = model.encoder.q_values.data.numpy()\n",
    "    W = np.e**(1j * qvalues)\n",
    "    \n",
    "    # Normalize each column so they have unit norm\n",
    "    col_norms = np.linalg.norm(W, axis=0)\n",
    "    diag_norm_matrix = np.diag(col_norms)\n",
    "    W_normalized = W @ np.linalg.inv(diag_norm_matrix)\n",
    "    \n",
    "    for combo in itertools.combinations(numbers, 3):\n",
    "        # Select the columns specified by the combination\n",
    "        W_cols = W_normalized[:, combo]\n",
    "        mod_mat = W_cols.T @ W_cols\n",
    "\n",
    "        # Compute eigenvalues of the Gram matrix\n",
    "        eig_vals, _ = np.linalg.eig(mod_mat)\n",
    "        eigenvalues = np.abs(eig_vals)  # They should be real and close to 1\n",
    "        \n",
    "        # Compute deviations from 1\n",
    "        lower_deviation = 1 - np.min(eigenvalues)\n",
    "        upper_deviation = np.max(eigenvalues) - 1\n",
    "        temp_RIC = max(lower_deviation, upper_deviation)\n",
    "        \n",
    "        if temp_RIC > max_RIC:\n",
    "            max_RIC = temp_RIC\n",
    "\n",
    "    RIC[model] = max_RIC"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(RIC.values())"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate coherences"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "models = discrete_models\n",
    "\n",
    "mu = {}\n",
    "for model in discrete_models:\n",
    "    qvalues = model.encoder.q_values.data.numpy()\n",
    "    W = np.e**(1j * qvalues)\n",
    "    \n",
    "    # Normalize each column so they have unit norm\n",
    "    col_norms = np.linalg.norm(W, axis=0)\n",
    "    diag_norm_matrix = np.diag(col_norms)\n",
    "    W_normalized = W @ np.linalg.inv(diag_norm_matrix)\n",
    "    W_dotprod = np.abs(W_normalized.T@W_normalized)\n",
    "    W_no_diag = W_dotprod - np.diag(np.diag(W_dotprod))\n",
    "    mu[model] = np.max(W_no_diag)\n",
    "\n",
    "\n",
    "print(mu.values())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
